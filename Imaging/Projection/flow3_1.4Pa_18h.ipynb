{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPxQV23ri3BLrUjubhLt898"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# Import required libraries\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import os\n","import numpy as np\n","from skimage import io, filters, exposure, morphology, measure, segmentation, img_as_float, img_as_uint\n","from scipy import ndimage\n","import glob\n","import tifffile\n","from pathlib import Path\n","import matplotlib.pyplot as plt\n","from tqdm.notebook import tqdm\n","from skimage.feature import peak_local_max\n","\n","# ======= CONFIGURATION =======\n","# Set paths specifically for your Google Colab environment\n","INPUT_DIR = '/content/drive/MyDrive/knowledge/University/Master/Thesis/denoised_ordered/flow3_1.4Pa_18h'\n","OUTPUT_DIR = '/content/drive/MyDrive/knowledge/University/Master/Thesis/Projected/flow3_1.4Pa_18h'\n","\n","# Default EDF parameters\n","DEFAULT_MAX_Z_DIFF = 1      # Maximum allowed z-difference between adjacent pixels\n","DEFAULT_SIGMA = 1.0         # Sigma for Laplacian operator smoothing\n","DEFAULT_GAUSS_DENOISE = 0.5 # Sigma for Gaussian denoising\n","\n","# Define channel names (customize these based on your data)\n","CHANNEL_NAMES = ['Cadherins', 'Nuclei', 'Golgi']\n","\n","# ======= UTILITY FUNCTIONS =======\n","\n","def create_dirs():\n","    \"\"\"Create necessary directories for the new output structure\"\"\"\n","    os.makedirs(INPUT_DIR, exist_ok=True)\n","    os.makedirs(OUTPUT_DIR, exist_ok=True)\n","\n","    # Create the new directory structure for all channels with both background and tophat\n","    for channel in CHANNEL_NAMES:\n","        os.makedirs(os.path.join(OUTPUT_DIR, channel, 'tophat'), exist_ok=True)\n","        os.makedirs(os.path.join(OUTPUT_DIR, channel, 'background'), exist_ok=True)\n","\n","def normalize_image(img):\n","    \"\"\"Normalize image to 0-1 range\"\"\"\n","    img_min = np.min(img)\n","    img_max = np.max(img)\n","    if img_max > img_min:\n","        return (img - img_min) / (img_max - img_min)\n","    return img\n","\n","# ======= BACKGROUND REMOVAL =======\n","\n","def tophat_filter_background(image, radius=15):\n","    \"\"\"Remove background using white top-hat filter\"\"\"\n","    # Normalize input to 0-1 range\n","    img = normalize_image(img_as_float(image))\n","\n","    # Create structuring element (disk)\n","    selem = morphology.disk(radius)\n","\n","    # Apply white top-hat filter (removes background while preserving foreground)\n","    tophat = morphology.white_tophat(img, selem)\n","\n","    # Enhance contrast and ensure 0-1 range\n","    tophat = exposure.rescale_intensity(tophat)\n","\n","    # Double-check normalization\n","    tophat = normalize_image(tophat)\n","\n","    return tophat\n","\n","# ======= REGIONAL GUIDED EDF METHOD =======\n","\n","def edf_regional_guided(image_stack, region_size=15, overlap=5, sigma=1.0, gauss_denoise=0.5, max_z_diff=1):\n","    \"\"\"\n","    Regional guided EDF with spatial consistency\n","    Processes image in overlapping regions to better handle local depth variations\n","    \"\"\"\n","    # Convert to float and ensure 0-1 range\n","    stack = img_as_float(image_stack)\n","    stack = normalize_image(stack)\n","    z_size, height, width = stack.shape\n","\n","    # Calculate focus measures\n","    focus_measures = np.zeros((z_size, height, width))\n","\n","    for z in range(z_size):\n","        # Apply Gaussian filter to reduce noise\n","        if gauss_denoise > 0:\n","            blurred = filters.gaussian(stack[z], sigma=gauss_denoise)\n","        else:\n","            blurred = stack[z]\n","\n","        # Apply Laplacian filter (detects edges/details)\n","        laplacian = np.abs(filters.laplace(blurred, ksize=3))\n","\n","        # Apply small Gaussian to make the decision more robust\n","        if sigma > 0:\n","            focus_measures[z] = filters.gaussian(laplacian, sigma=sigma)\n","        else:\n","            focus_measures[z] = laplacian\n","\n","    # Create output arrays\n","    # Changed from int32 to float64 to avoid casting error\n","    best_z = np.zeros((height, width), dtype=np.float64)\n","    weights = np.zeros((height, width), dtype=np.float32)\n","\n","    # Process image in overlapping regions\n","    for y_start in range(0, height, region_size - overlap):\n","        for x_start in range(0, width, region_size - overlap):\n","            # Define region bounds\n","            y_end = min(y_start + region_size, height)\n","            x_end = min(x_start + region_size, width)\n","\n","            # Extract region\n","            region_focus = focus_measures[:, y_start:y_end, x_start:x_end]\n","\n","            # Process region with spatial continuity\n","            region_best_z = edf_with_spatial_continuity_region(\n","                region_focus,\n","                max_z_diff=max_z_diff\n","            )\n","\n","            # Create weight mask (higher weights in center, lower at edges)\n","            y_grid, x_grid = np.mgrid[y_start:y_end, x_start:x_end]\n","            y_center = (y_start + y_end) / 2\n","            x_center = (x_start + x_end) / 2\n","\n","            # Calculate distance from center (normalized to 0-1)\n","            y_dist = np.abs(y_grid - y_center) / (region_size / 2)\n","            x_dist = np.abs(x_grid - x_center) / (region_size / 2)\n","            dist = np.maximum(y_dist, x_dist)\n","            region_weights = np.clip(1.0 - dist, 0.1, 1.0)\n","\n","            # Convert region_best_z to float64 before multiplying\n","            region_best_z_float = region_best_z.astype(np.float64)\n","\n","            # Add weighted contribution to output\n","            best_z[y_start:y_end, x_start:x_end] += region_best_z_float * region_weights\n","            weights[y_start:y_end, x_start:x_end] += region_weights\n","\n","    # Normalize by weights and round to nearest integer\n","    best_z = np.round(best_z / np.maximum(weights, 1e-6)).astype(np.int32)\n","\n","    # Ensure best_z values are within valid range\n","    best_z = np.clip(best_z, 0, z_size - 1)\n","\n","    # Create output by taking pixels from best z-slices\n","    result = np.zeros((height, width), dtype=np.float32)\n","    for z in range(z_size):\n","        mask = best_z == z\n","        result[mask] = stack[z][mask]\n","\n","    # Create a visualization of the focus map (normalized to 0-1)\n","    focus_map = best_z / (z_size - 1)\n","\n","    return result, focus_map, best_z\n","\n","def edf_with_spatial_continuity_region(focus_measures, max_z_diff=1):\n","    \"\"\"\n","    Helper function for regional guided EDF\n","    Applies spatial continuity to a region's focus measures\n","    \"\"\"\n","    z_size, height, width = focus_measures.shape\n","\n","    # Find initial z-slice with maximum focus for each pixel\n","    initial_best_z = np.argmax(focus_measures, axis=0)\n","\n","    # Create a processed mask to track pixels that have been assigned a final z-value\n","    processed = np.zeros((height, width), dtype=bool)\n","\n","    # Create the output z-map that will be filled with spatially consistent z-values\n","    final_best_z = np.copy(initial_best_z)\n","\n","    # Function to get valid 4-connected neighbors\n","    def get_neighbors(y, x):\n","        neighbors = []\n","        for ny, nx in [(y-1, x), (y+1, x), (y, x-1), (y, x+1)]:\n","            if 0 <= ny < height and 0 <= nx < width:\n","                neighbors.append((ny, nx))\n","        return neighbors\n","\n","    # Find seed points - we'll start from pixels with highest confidence\n","    confidence = np.zeros((height, width))\n","    for y in range(height):\n","        for x in range(width):\n","            z = initial_best_z[y, x]\n","            confidence[y, x] = focus_measures[z, y, x]\n","\n","    # Sort pixels by confidence (highest first)\n","    confidence_threshold = np.percentile(confidence, 95)  # Use top 5% as seeds\n","    seed_indices = np.where(confidence > confidence_threshold)\n","    seed_points = list(zip(seed_indices[0], seed_indices[1]))\n","\n","    # Sort seed points by confidence (highest first)\n","    seed_points.sort(key=lambda idx: confidence[idx[0], idx[1]], reverse=True)\n","\n","    # Initialize frontier with seed points\n","    frontier = seed_points.copy()\n","    for y, x in frontier:\n","        processed[y, x] = True\n","\n","    # Process each point and its neighbors using a breadth-first approach\n","    while frontier:\n","        y, x = frontier.pop(0)\n","        current_z = final_best_z[y, x]\n","\n","        # Check neighbors\n","        for ny, nx in get_neighbors(y, x):\n","            if processed[ny, nx]:\n","                continue\n","\n","            # Find best z within allowed range from current pixel\n","            z_min = max(0, current_z - max_z_diff)\n","            z_max = min(z_size - 1, current_z + max_z_diff)\n","\n","            # Extract the relevant slice of focus measures and find best z\n","            z_slice = focus_measures[z_min:z_max+1, ny, nx]\n","            relative_best_z = np.argmax(z_slice)\n","            final_best_z[ny, nx] = z_min + relative_best_z\n","\n","            processed[ny, nx] = True\n","            frontier.append((ny, nx))\n","\n","    # Check if there are any unprocessed pixels left (should be rare)\n","    unprocessed = ~processed\n","    if np.any(unprocessed):\n","        # Assign them the value of nearest processed neighbor\n","        dist, indices = ndimage.distance_transform_edt(\n","            unprocessed, return_indices=True)\n","\n","        # Assign z-values from nearest processed pixel\n","        for y, x in zip(*np.where(unprocessed)):\n","            idx_y, idx_x = indices[0, y, x], indices[1, y, x]\n","            final_best_z[y, x] = final_best_z[idx_y, idx_x]\n","\n","    return final_best_z\n","\n","# ======= MAIN PROCESSING FUNCTIONS =======\n","\n","def process_single_stack(stack, apply_tophat=False, max_z_diff=DEFAULT_MAX_Z_DIFF):\n","    \"\"\"\n","    Process a single z-stack with the regional EDF method\n","    \"\"\"\n","    print(f\"Processing stack with shape {stack.shape}...\")\n","\n","    # Convert to float and ensure valid range (0-1)\n","    stack = img_as_float(stack)\n","\n","    # Ensure stack values are in 0-1 range\n","    min_val = np.min(stack)\n","    max_val = np.max(stack)\n","    if min_val < 0 or max_val > 1:\n","        print(f\"Normalizing stack from range [{min_val}, {max_val}] to [0, 1]\")\n","        stack = normalize_image(stack)\n","\n","    # Apply background removal if requested\n","    if apply_tophat:\n","        print(\"Applying tophat background removal...\")\n","        processed_stack = np.zeros_like(stack, dtype=np.float32)\n","        for z in range(stack.shape[0]):\n","            processed_stack[z] = tophat_filter_background(stack[z])\n","        working_stack = processed_stack\n","    else:\n","        working_stack = stack\n","\n","    # Store original slices for comparison\n","    mid_z_idx = stack.shape[0] // 2\n","\n","    # Prepare results dictionary\n","    results = {\n","        'original_middle': stack[mid_z_idx],\n","        'original_max': np.max(stack, axis=0)\n","    }\n","\n","    # Apply regional method\n","    print(\"Applying regional guided EDF...\")\n","    proj, focus_map, _ = edf_regional_guided(\n","        working_stack, max_z_diff=max_z_diff)\n","    results['regional_edf'] = proj\n","    results['focus_map_regional'] = focus_map\n","\n","    return results\n","\n","def save_results_to_disk(results, filename, channel_name, apply_tophat):\n","    \"\"\"Save results to disk with updated directory structure and naming\"\"\"\n","    base_name = os.path.splitext(filename)[0]\n","\n","    # Get only the projection result (not focus map)\n","    key = \"regional_edf\"\n","    if key in results:\n","        # Determine processing type folder\n","        process_type = \"tophat\" if apply_tophat else \"background\"\n","\n","        # Create appropriate directory path\n","        output_dir = os.path.join(OUTPUT_DIR, channel_name, process_type)\n","        os.makedirs(output_dir, exist_ok=True)\n","\n","        # Create output filename - using just the base name as requested\n","        output_filename = f\"{base_name}_{channel_name}_regional\"\n","        if apply_tophat:\n","            output_filename += \"_tophat\"\n","        output_filename += \".tif\"\n","\n","        output_path = os.path.join(output_dir, output_filename)\n","\n","        # Normalize to 0-1 range and convert to uint16\n","        projection = results[key]\n","        projection_normalized = normalize_image(projection)\n","        projection_uint = img_as_uint(projection_normalized)\n","\n","        # Save\n","        tifffile.imwrite(output_path, projection_uint)\n","        print(f\"Saved {output_path}\")\n","\n","def process_directory(input_dir=INPUT_DIR, max_z_diff=DEFAULT_MAX_Z_DIFF,\n","                     file_pattern='*.tif*', save_results=True):\n","    \"\"\"\n","    Process all files in a directory with channel-specific settings\n","    \"\"\"\n","    # Get all matching files\n","    all_files = glob.glob(os.path.join(input_dir, file_pattern), recursive=True)\n","    all_files.sort()\n","\n","    if not all_files:\n","        print(f\"No files matching '{file_pattern}' found in {input_dir}\")\n","        return []\n","\n","    print(f\"Found {len(all_files)} files to process\")\n","\n","    # Create output directories\n","    create_dirs()\n","\n","    # Process each file\n","    processed_files = []\n","\n","    for file_idx, file_path in enumerate(all_files):\n","        print(f\"\\nProcessing file {file_idx+1}/{len(all_files)}: {os.path.basename(file_path)}\")\n","\n","        try:\n","            results = process_file(\n","                file_path, max_z_diff=max_z_diff,\n","                save_results=save_results\n","            )\n","\n","            if results:\n","                processed_files.append(file_path)\n","                print(f\"Successfully processed {os.path.basename(file_path)}\")\n","\n","        except Exception as e:\n","            print(f\"Error processing file {os.path.basename(file_path)}: {e}\")\n","            import traceback\n","            traceback.print_exc()\n","\n","    print(f\"\\nSuccessfully processed {len(processed_files)}/{len(all_files)} files\")\n","    return processed_files\n","\n","def process_file(file_path, max_z_diff=DEFAULT_MAX_Z_DIFF, save_results=True):\n","    \"\"\"\n","    Process a single file with channel-specific processing:\n","    - Create both tophat and background projections for all channels\n","    \"\"\"\n","    filename = os.path.basename(file_path)\n","    print(f\"Processing file: {filename}\")\n","\n","    # Load image\n","    try:\n","        image = tifffile.imread(file_path)\n","        print(f\"Image shape: {image.shape}, dtype: {image.dtype}\")\n","    except Exception as e:\n","        print(f\"Error loading image: {e}\")\n","        return None\n","\n","    # Handle different dimensionalities\n","    if len(image.shape) == 3:\n","        # Single channel z-stack - process with and without tophat\n","        results_no_tophat = process_single_stack(\n","            image, apply_tophat=False, max_z_diff=max_z_diff)\n","\n","        results_tophat = process_single_stack(\n","            image, apply_tophat=True, max_z_diff=max_z_diff)\n","\n","        if save_results:\n","            save_results_to_disk(results_no_tophat, filename, \"default\", False)\n","            save_results_to_disk(results_tophat, filename, \"default\", True)\n","\n","        return {\"default_no_tophat\": results_no_tophat, \"default_tophat\": results_tophat}\n","\n","    elif len(image.shape) == 4:\n","        # Multi-channel z-stack with channel-specific processing\n","        all_results = {}\n","\n","        # Process each channel with appropriate settings\n","        for ch_idx in range(image.shape[0]):\n","            # Extract channel\n","            channel_data = image[ch_idx]\n","            ch_name = CHANNEL_NAMES[ch_idx] if ch_idx < len(CHANNEL_NAMES) else f\"channel_{ch_idx}\"\n","\n","            # Process each channel with both background and tophat\n","            print(f\"Processing {ch_name} without tophat (background)...\")\n","            results_no_tophat = process_single_stack(\n","                channel_data, apply_tophat=False, max_z_diff=max_z_diff)\n","\n","            print(f\"Processing {ch_name} with tophat...\")\n","            results_tophat = process_single_stack(\n","                channel_data, apply_tophat=True, max_z_diff=max_z_diff)\n","\n","            all_results[f\"{ch_name}_no_tophat\"] = results_no_tophat\n","            all_results[f\"{ch_name}_tophat\"] = results_tophat\n","\n","            if save_results:\n","                save_results_to_disk(results_no_tophat, filename, ch_name, False)\n","                save_results_to_disk(results_tophat, filename, ch_name, True)\n","\n","        return all_results\n","\n","    else:\n","        print(f\"Unsupported image dimensions: {len(image.shape)}\")\n","        return None\n","\n","# Main execution - just call process_directory with your parameters\n","def main():\n","    create_dirs()\n","    processed_files = process_directory(\n","        input_dir=INPUT_DIR,\n","        max_z_diff=DEFAULT_MAX_Z_DIFF,\n","        file_pattern='*.tif*',\n","        save_results=True\n","    )\n","    print(f\"Processed {len(processed_files)} files\")\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"id":"VcyOEHAoO-Re"},"execution_count":null,"outputs":[]}]}