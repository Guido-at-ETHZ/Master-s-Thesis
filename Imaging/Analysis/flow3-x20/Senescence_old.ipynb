{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1s50EtQ0mJNbpwLX5PBOpD0GD8Z_GAw0L","authorship_tag":"ABX9TyOWIzCgSUW3ViSifiqmulGW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import os\n","import numpy as np\n","import pandas as pd\n","import cv2\n","import re\n","from scipy import ndimage\n","from skimage import io, measure\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.cluster import KMeans\n","import umap\n","from tqdm import tqdm\n","\n","# Use the functions you provided\n","def extract_sample_id(filename):\n","    \"\"\"\n","    Extract the sample ID from a filename based on the specific naming pattern.\n","\n","    Examples:\n","    - '1.4Pa_U_05mar19_20x_L2R_Flat_seq005_cell_mask_merged_conservative.tif' → '1.4Pa_U_05mar19_20x_L2R_Flat_seq005'\n","    - 'denoised_1.4Pa_U_05mar19_20x_L2R_Flat_seq005_Cadherins_filtered_mask.tif' → '1.4Pa_U_05mar19_20x_L2R_Flat_seq005'\n","    \"\"\"\n","    # Remove file extension\n","    base_name = os.path.splitext(filename)[0]\n","\n","    # Handle special prefixes like \"denoised_\"\n","    if base_name.startswith('denoised_'):\n","        base_name = base_name[len('denoised_'):]\n","\n","    # Find the pattern that includes Pa (pressure), followed by identifiers and sequence number\n","    # Looking for patterns like \"1.4Pa_U_05mar19_20x_L2R_Flat_seq005\"\n","    pattern = re.compile(r'([\\d\\.]+Pa_[^_]+_[^_]+_[^_]+_[^_]+_[^_]+_seq\\d+)')\n","    match = pattern.search(base_name)\n","\n","    if match:\n","        # Use only the first match to avoid concatenating multiple matches\n","        return match.group(1)\n","\n","    # If the regex didn't work, try a simpler approach with string splitting\n","    parts = base_name.split('_')\n","\n","    # Look for the \"seq\" pattern which is common in your filenames\n","    for i, part in enumerate(parts):\n","        if part.startswith('seq') and i >= 2:  # Need at least 3 parts for a meaningful ID\n","            # Include parts up to and including the seq part (but limit length)\n","            # Limiting to maximum of 6 parts to avoid overly long IDs\n","            max_parts = min(i+1, 6)\n","            return '_'.join(parts[:max_parts])\n","\n","    # Fallback: truncate to avoid excessively long IDs\n","    if len(parts) > 3:\n","        return '_'.join(parts[:min(len(parts)-2, 6)])  # Skip last 2 parts, max 6 parts\n","\n","    # Last resort: use a shortened version of the filename (max 50 chars)\n","    shortened_name = os.path.basename(filename)[:50]\n","    return shortened_name\n","\n","def find_mask_files(cell_dir, nuclei_dir):\n","    \"\"\"Finds and pairs cell and nuclei mask files based on extracted sample ID.\"\"\"\n","    print(\"\\n--- Finding and Pairing Mask Files ---\")\n","\n","    # Get all relevant mask files\n","    cell_files = [f for f in os.listdir(cell_dir) if f.endswith(('.tif', '.tiff')) and not f.startswith('.')]\n","    nuclei_files = [f for f in os.listdir(nuclei_dir) if f.endswith(('.tif', '.tiff')) and not f.startswith('.')]\n","\n","    print(f\"Found {len(cell_files)} cell mask files and {len(nuclei_files)} nuclei mask files\")\n","\n","    # Create lookup dictionary for nuclei files with extracted sample IDs\n","    nuclei_lookup = {}\n","    for nuclei_file in nuclei_files:\n","        sample_id = extract_sample_id(nuclei_file)\n","        if sample_id:\n","            nuclei_lookup[sample_id] = nuclei_file\n","            print(f\"Nuclei file: '{nuclei_file}' → Sample ID: '{sample_id}'\")\n","\n","    # Match cell files to nuclei files\n","    file_pairs = []\n","    pairs_found = 0\n","\n","    for cell_file in cell_files:\n","        sample_id = extract_sample_id(cell_file)\n","        print(f\"Cell file: '{cell_file}' → Sample ID: '{sample_id}'\")\n","\n","        if sample_id and sample_id in nuclei_lookup:\n","            print(f\"Match found: {sample_id}\")\n","            nuclei_file = nuclei_lookup[sample_id]\n","            file_pair = {\n","                'cell_file': os.path.join(cell_dir, cell_file),\n","                'nuclei_file': os.path.join(nuclei_dir, nuclei_file),\n","                'sample_id': sample_id\n","            }\n","            file_pairs.append(file_pair)\n","            pairs_found += 1\n","\n","    print(f\"Total matching cell-nuclei file pairs found: {pairs_found}\")\n","\n","    return file_pairs\n","\n","def load_mask_image(filepath):\n","    \"\"\"Loads a mask image, ensuring it's binary (0 or 1).\"\"\"\n","    try:\n","        img = io.imread(filepath)\n","        # Convert to binary uint8\n","        if img.dtype == bool:\n","            img = img.astype(np.uint8)\n","        elif np.max(img) > 1:\n","            # If it's a labeled mask, keep the labels\n","            if np.max(img) <= 255:\n","                img = img.astype(np.uint8)\n","            else:\n","                img = img.astype(np.uint16)\n","        else:\n","            img = img.astype(np.uint8)\n","\n","        # Handle multi-channel images\n","        if img.ndim > 2:\n","            if img.shape[2] == 3:  # RGB\n","                img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n","            elif img.shape[2] == 4:  # RGBA\n","                img = cv2.cvtColor(img, cv2.COLOR_RGBA2GRAY)\n","            else:\n","                img = img[:,:,0]\n","            # If it's a labeled mask with multiple channels, threshold to get binary\n","            img = (img > 0).astype(np.uint8)\n","\n","        return img\n","    except Exception as e:\n","        print(f\"Error loading image {filepath}: {str(e)}\")\n","        return None\n","\n","def accurately_track_nuclei_in_cells(cell_mask, nuclei_mask):\n","    \"\"\"\n","    Accurately identifies which nuclei are inside which cells.\n","\n","    Algorithm:\n","    1. Label individual cells and nuclei\n","    2. For each nucleus, find its centroid\n","    3. Check which cell contains this centroid\n","    4. If >50% of nucleus area is inside a cell, assign it to that cell\n","    \"\"\"\n","    # Ensure masks are properly labeled\n","    # For cell_mask, each cell should have a unique ID\n","    if np.max(cell_mask) <= 1:\n","        labeled_cells, num_cells = ndimage.label(cell_mask)\n","    else:\n","        labeled_cells = cell_mask\n","        num_cells = np.max(labeled_cells)\n","\n","    # For nuclei_mask, each nucleus should have a unique ID\n","    if np.max(nuclei_mask) <= 1:\n","        labeled_nuclei, num_nuclei = ndimage.label(nuclei_mask)\n","    else:\n","        labeled_nuclei = nuclei_mask\n","        num_nuclei = np.max(labeled_nuclei)\n","\n","    print(f\"Found {num_cells} cells and {num_nuclei} nuclei\")\n","\n","    # Extract properties for cells and nuclei\n","    cell_props = measure.regionprops(labeled_cells)\n","    nuclei_props = measure.regionprops(labeled_nuclei)\n","\n","    # Create a results structure\n","    results = {\n","        'cell_data': [],\n","        'nuclei_data': [],\n","        'cell_nuclei_mapping': {}\n","    }\n","\n","    # Process each cell\n","    for cell in cell_props:\n","        cell_id = cell.label\n","        cell_mask_binary = (labeled_cells == cell_id)\n","\n","        # Basic cell properties\n","        cell_data = {\n","            'cell_id': cell_id,\n","            'area': cell.area,\n","            'perimeter': cell.perimeter,\n","            'eccentricity': cell.eccentricity,\n","            'orientation': np.degrees(cell.orientation) % 180 if hasattr(cell, 'orientation') else None,\n","            'major_axis_length': cell.major_axis_length if hasattr(cell, 'major_axis_length') else None,\n","            'minor_axis_length': cell.minor_axis_length if hasattr(cell, 'minor_axis_length') else None,\n","            'centroid_y': cell.centroid[0],\n","            'centroid_x': cell.centroid[1],\n","            'nuclei_count': 0\n","        }\n","\n","        results['cell_data'].append(cell_data)\n","        results['cell_nuclei_mapping'][cell_id] = []\n","\n","    # Find which nuclei belong to which cells\n","    for nucleus in nuclei_props:\n","        nucleus_id = nucleus.label\n","        nucleus_mask_binary = (labeled_nuclei == nucleus_id)\n","        nucleus_area = nucleus.area\n","\n","        # Find which cell contains this nucleus\n","        contained_in_cell = None\n","        max_overlap_ratio = 0\n","\n","        for cell in cell_props:\n","            cell_id = cell.label\n","            cell_mask_binary = (labeled_cells == cell_id)\n","\n","            # Calculate overlap\n","            overlap = np.logical_and(cell_mask_binary, nucleus_mask_binary)\n","            overlap_area = np.sum(overlap)\n","\n","            # Calculate what percentage of the nucleus is in this cell\n","            overlap_ratio = overlap_area / nucleus_area\n","\n","            # If most of the nucleus is in this cell, assign it to this cell\n","            if overlap_ratio > max_overlap_ratio:\n","                max_overlap_ratio = overlap_ratio\n","                contained_in_cell = cell_id\n","\n","        # Only count the nucleus if a significant portion is inside the cell (>50%)\n","        if contained_in_cell is not None and max_overlap_ratio > 0.5:\n","            # Store nucleus data\n","            nucleus_data = {\n","                'nucleus_id': nucleus_id,\n","                'cell_id': contained_in_cell,\n","                'area': nucleus.area,\n","                'eccentricity': nucleus.eccentricity if hasattr(nucleus, 'eccentricity') else None,\n","                'centroid_y': nucleus.centroid[0],\n","                'centroid_x': nucleus.centroid[1],\n","                'overlap_ratio': max_overlap_ratio\n","            }\n","\n","            results['nuclei_data'].append(nucleus_data)\n","\n","            # Update cell's nuclei count\n","            for cell_data in results['cell_data']:\n","                if cell_data['cell_id'] == contained_in_cell:\n","                    cell_data['nuclei_count'] += 1\n","                    break\n","\n","            # Update cell-nuclei mapping\n","            results['cell_nuclei_mapping'][contained_in_cell].append(nucleus_id)\n","\n","    # Count nuclei per cell\n","    cells_with_nuclei = sum(1 for cell_data in results['cell_data'] if cell_data['nuclei_count'] > 0)\n","    cells_with_multiple_nuclei = sum(1 for cell_data in results['cell_data'] if cell_data['nuclei_count'] > 1)\n","\n","    print(f\"Cells with nuclei: {cells_with_nuclei}/{num_cells} ({100*cells_with_nuclei/num_cells:.1f}% of cells)\")\n","    print(f\"Cells with multiple nuclei: {cells_with_multiple_nuclei}/{num_cells} ({100*cells_with_multiple_nuclei/num_cells:.1f}% of cells)\")\n","\n","    # Create summary of nuclei per cell\n","    nuclei_counts = [cell_data['nuclei_count'] for cell_data in results['cell_data']]\n","    unique_counts = sorted(set(nuclei_counts))\n","    for count in unique_counts:\n","        cells_with_count = sum(1 for n in nuclei_counts if n == count)\n","        print(f\"  Cells with {count} nuclei: {cells_with_count} ({100*cells_with_count/num_cells:.1f}%)\")\n","\n","    return results\n","\n","def extract_features_for_cell(cell_data, cell_nuclei_map, nuclei_data_list):\n","    \"\"\"\n","    Extract comprehensive morphometric features for a cell and its associated nuclei.\n","    These features will be used for clustering.\n","    \"\"\"\n","    features = {}\n","\n","    # Basic cell features - directly from cell_data\n","    features['cell_area'] = cell_data['area']\n","    features['cell_perimeter'] = cell_data['perimeter']\n","    features['cell_eccentricity'] = cell_data['eccentricity'] if cell_data['eccentricity'] is not None else 0\n","\n","    # Calculate additional cell shape features\n","    if cell_data['perimeter'] > 0:\n","        features['cell_circularity'] = 4 * np.pi * cell_data['area'] / (cell_data['perimeter'] ** 2)\n","    else:\n","        features['cell_circularity'] = 0\n","\n","    if cell_data['major_axis_length'] is not None and cell_data['minor_axis_length'] is not None:\n","        if cell_data['minor_axis_length'] > 0:\n","            features['cell_aspect_ratio'] = cell_data['major_axis_length'] / cell_data['minor_axis_length']\n","        else:\n","            features['cell_aspect_ratio'] = 1.0\n","    else:\n","        features['cell_aspect_ratio'] = 1.0\n","\n","    # Nuclear features\n","    cell_id = cell_data['cell_id']\n","    nucleus_ids = cell_nuclei_map.get(cell_id, [])\n","    features['nuclei_count'] = len(nucleus_ids)\n","\n","    # Initialize nuclear features with defaults\n","    features['avg_nucleus_area'] = 0\n","    features['total_nuclear_area'] = 0\n","    features['max_nucleus_area'] = 0\n","    features['avg_nucleus_eccentricity'] = 0\n","    features['nucleus_area_std'] = 0\n","    features['nucleus_displacement'] = 0  # Distance between nucleus centroid and cell centroid\n","\n","    if features['nuclei_count'] > 0:\n","        # Get nuclei associated with this cell\n","        cell_nuclei = [n for n in nuclei_data_list if n['cell_id'] == cell_id]\n","\n","        # Calculate nuclear features\n","        nuclear_areas = [n['area'] for n in cell_nuclei]\n","        nuclear_eccentricities = [n['eccentricity'] if n['eccentricity'] is not None else 0 for n in cell_nuclei]\n","\n","        features['avg_nucleus_area'] = np.mean(nuclear_areas) if nuclear_areas else 0\n","        features['total_nuclear_area'] = sum(nuclear_areas)\n","        features['max_nucleus_area'] = max(nuclear_areas) if nuclear_areas else 0\n","        features['avg_nucleus_eccentricity'] = np.mean(nuclear_eccentricities) if nuclear_eccentricities else 0\n","        features['nucleus_area_std'] = np.std(nuclear_areas) if len(nuclear_areas) > 1 else 0\n","\n","        # Calculate nucleus-to-cell metrics\n","        features['nucleus_to_cell_area_ratio'] = features['total_nuclear_area'] / features['cell_area'] if features['cell_area'] > 0 else 0\n","\n","        # Calculate average displacement of nuclei from cell center\n","        displacements = []\n","        for nucleus in cell_nuclei:\n","            dx = nucleus['centroid_x'] - cell_data['centroid_x']\n","            dy = nucleus['centroid_y'] - cell_data['centroid_y']\n","            displacement = np.sqrt(dx**2 + dy**2)\n","            displacements.append(displacement)\n","\n","        features['nucleus_displacement'] = np.mean(displacements) if displacements else 0\n","\n","    # Derived features specifically useful for senescence\n","    # 1. Polynucleation indicator (more likely to be senescent)\n","    features['is_polynucleated'] = 1 if features['nuclei_count'] > 1 else 0\n","\n","    # 2. Nuclear enlargement (common in senescent cells)\n","    # We'll compare to typical nuclear size - this is a placeholder value\n","    avg_normal_nucleus_area = 500  # This should be determined from data\n","    features['nuclear_enlargement'] = features['avg_nucleus_area'] / avg_normal_nucleus_area if avg_normal_nucleus_area > 0 else 1\n","\n","    # 3. Cell spreading (senescent cells are typically larger)\n","    avg_normal_cell_area = 2000  # This should be determined from data\n","    features['cell_enlargement'] = features['cell_area'] / avg_normal_cell_area if avg_normal_cell_area > 0 else 1\n","\n","    return features\n","\n","import numpy as np\n","import pandas as pd\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.cluster import KMeans\n","import umap\n","\n","def perform_clustering(all_features_df, umap_n_neighbors=30, umap_min_dist=0.1, umap_random_state=42, kmeans_random_state=42):\n","    \"\"\"\n","    Performs UMAP dimensionality reduction and k-Means clustering on the features,\n","    then assigns cell types based on a nuanced senescent score and a multinucleation rule.\n","\n","    Args:\n","        all_features_df (pd.DataFrame): DataFrame containing all extracted features for cells.\n","        umap_n_neighbors (int): UMAP n_neighbors parameter.\n","        umap_min_dist (float): UMAP min_dist parameter.\n","        umap_random_state (int): Random state for UMAP.\n","        kmeans_random_state (int): Random state for k-Means.\n","\n","    Returns:\n","        pd.DataFrame: The input DataFrame with added columns for UMAP coordinates,\n","                      cluster labels, and final cell_type.\n","    \"\"\"\n","    print(\"Starting clustering process...\")\n","    if all_features_df.empty:\n","        print(\"Input DataFrame is empty. Cannot perform clustering.\")\n","        return pd.DataFrame()\n","\n","    # Define feature columns (ensure 'cell_id' and 'sample_id' are excluded if they were part of all_features_df)\n","    # Also exclude columns that will be added by this function like 'umap_x', 'umap_y', 'cluster', 'cell_type'\n","    potential_id_cols = ['cell_id', 'sample_id', 'original_index'] # Add any other ID columns\n","    feature_columns = [col for col in all_features_df.columns if col not in potential_id_cols and col not in ['umap_x', 'umap_y', 'cluster', 'cell_type']]\n","\n","    # Ensure all feature columns are numeric, if not, attempt conversion or drop\n","    numeric_feature_columns = []\n","    for col in feature_columns:\n","        if pd.api.types.is_numeric_dtype(all_features_df[col]):\n","            numeric_feature_columns.append(col)\n","        else:\n","            try:\n","                all_features_df[col] = pd.to_numeric(all_features_df[col])\n","                numeric_feature_columns.append(col)\n","                print(f\"Column {col} converted to numeric.\")\n","            except ValueError:\n","                print(f\"Warning: Column {col} is not numeric and could not be converted. It will be excluded from clustering features.\")\n","\n","    feature_columns = numeric_feature_columns\n","    if not feature_columns:\n","        print(\"No valid numeric feature columns found for clustering.\")\n","        return all_features_df # Or an empty DataFrame\n","\n","    features_df = all_features_df[feature_columns].copy()\n","\n","    # --- 1. (NEW) Log Transform Area-based Features (before scaling) ---\n","    # This helps normalize skewed distributions for size-related features.\n","    area_features_to_log = ['cell_area', 'avg_nucleus_area', 'total_nuclear_area', 'max_nucleus_area', 'cell_perimeter']\n","    # Add other features like 'cell_enlargement', 'nuclear_enlargement' if their distributions are also highly skewed.\n","    # However, for derived ratios/enlargement factors, assess if log transform is appropriate or if they are better used as is in the heuristic.\n","    # For now, let's log primary area/perimeter measures.\n","\n","    print(\"\\nApplying log transformation to selected area/perimeter features...\")\n","    for col in area_features_to_log:\n","        if col in features_df.columns:\n","            features_df[col] = np.log1p(features_df[col]) # log1p handles zeros if any\n","            print(f\"  Log-transformed: {col}\")\n","        else:\n","            print(f\"  Warning: Column {col} not found for log transformation.\")\n","\n","    # --- 2. Standardize Features ---\n","    print(\"\\nStandardizing features...\")\n","    scaler = StandardScaler()\n","    features_standardized = scaler.fit_transform(features_df)\n","    features_standardized_df = pd.DataFrame(features_standardized, columns=feature_columns, index=features_df.index)\n","\n","    # --- 3. UMAP Dimensionality Reduction ---\n","    print(\"\\nPerforming UMAP reduction...\")\n","    reducer = umap.UMAP(n_neighbors=umap_n_neighbors, min_dist=umap_min_dist, random_state=umap_random_state, n_components=2)\n","    embedding = reducer.fit_transform(features_standardized_df)\n","\n","    clustered_df = all_features_df.copy() # Start with the original df to add new columns\n","    clustered_df['umap_x'] = embedding[:, 0]\n","    clustered_df['umap_y'] = embedding[:, 1]\n","\n","    # --- 4. k-Means Clustering ---\n","    print(\"\\nPerforming k-Means clustering (k=2)...\")\n","    kmeans = KMeans(n_clusters=2, random_state=kmeans_random_state, n_init='auto')\n","    clustered_df['cluster'] = kmeans.fit_predict(embedding) # Cluster on UMAP embedding\n","\n","    # --- 5. (NEW) Identify Senescent Cluster using a More Extensive Score ---\n","    print(\"\\nIdentifying senescent cluster using a weighted score...\")\n","\n","    # Calculate cluster statistics (mean feature values for each cluster)\n","    # Use the original feature values (or log-transformed if you want the score to reflect that scale)\n","    # for interpretability of the score. Here, we'll use the features_df which includes log-transformed values.\n","    # If you prefer original scale for scoring features that were log-transformed for UMAP,\n","    # you would calculate means from all_features_df[feature_columns]\n","    # but be careful with consistency if some are logged and some are not in the score.\n","\n","    # For calculating cluster_stats, add the 'cluster' column to the dataframe that has the features used for scoring\n","    # If using log-transformed features for scoring (as in features_df):\n","    scoring_features_df = features_df.copy()\n","    scoring_features_df['cluster'] = clustered_df['cluster']\n","    cluster_stats = scoring_features_df.groupby('cluster').mean()\n","\n","    # If you want to score based on *original* feature values (before log transform and scaling):\n","    # temp_df_for_stats = all_features_df[feature_columns].copy()\n","    # temp_df_for_stats['cluster'] = clustered_df['cluster']\n","    # cluster_stats = temp_df_for_stats.groupby('cluster').mean()\n","    # Ensure features in `weights` below exist in this `cluster_stats`\n","\n","    # --- Define weights for each feature ---\n","    # Positive weight if a higher value indicates senescence, negative if a lower value does.\n","    # **TUNE THESE WEIGHTS BASED ON YOUR KNOWLEDGE AND OBSERVATIONS!**\n","    # Note: 'cell_area', 'avg_nucleus_area' etc. in cluster_stats will be log-scaled if 'features_df' was used above.\n","    # 'cell_enlargement' and 'nuclear_enlargement' from all_features_df are on original scale.\n","    # This mixing of scales means weights need careful thought.\n","    # For simplicity, let's assume cluster_stats are from 'features_df' (so some are log-scaled).\n","    # If you added 'cell_enlargement' etc. to features_df and log-transformed them, this is consistent.\n","    # If not, and they are part of `all_features_df` but not `features_df` for UMAP,\n","    # you'd need to get their means separately or ensure they are in `scoring_features_df`.\n","\n","    # For a robust score, it's best if all features contributing to it are on a somewhat comparable scale OR\n","    # weights strongly reflect their differing scales and importance.\n","    # Let's ensure all features used in weights are actually present in cluster_stats.\n","    # We will use the `all_features_df` to get means for `cell_enlargement` and `nuclear_enlargement`\n","    # as they might not have been log-transformed or included in the UMAP features.\n","\n","    cluster_stats_original_scale = all_features_df.copy()\n","    cluster_stats_original_scale['cluster'] = clustered_df['cluster']\n","    cluster_stats_original_scale_means = cluster_stats_original_scale.groupby('cluster')[feature_columns].mean()\n","\n","\n","    weights = {\n","        # Features assumed to be log-transformed if coming from 'features_df' based cluster_stats\n","        'cell_area': 1.0,        # Larger is more senescent (log-scale)\n","        'avg_nucleus_area': 0.7, # Larger nuclei often seen (log-scale)\n","        'total_nuclear_area': 0.5, # (log-scale)\n","        'cell_perimeter': 0.5,   # (log-scale)\n","\n","        # Features from original scale (using cluster_stats_original_scale_means)\n","        # Or ensure these are in your `feature_columns` for UMAP if you want them processed that way\n","        'cell_enlargement': 1.5,    # More enlargement is more senescent (original scale from all_features_df)\n","        'nuclear_enlargement': 1.0, # More enlargement is more senescent (original scale from all_features_df)\n","        'nuclei_count': 0.8,        # Higher count is indicative (original scale)\n","        'cell_circularity': -0.5,   # Often less circular (original scale)\n","        'nucleus_to_cell_area_ratio': -1.0 # Often decreases (original scale)\n","        # Add/remove/tune features and weights as needed.\n","        # 'cell_aspect_ratio': -0.3, # Example, if relevant\n","    }\n","\n","    senescent_score_0 = 0\n","    senescent_score_1 = 0\n","\n","    print(\"Calculating senescent scores for clusters using weights:\")\n","    for feature, weight in weights.items():\n","        if feature in cluster_stats.columns: # From log-transformed features_df\n","            senescent_score_0 += cluster_stats.loc[0, feature] * weight\n","            senescent_score_1 += cluster_stats.loc[1, feature] * weight\n","            print(f\"  Using {feature} (log-transformed potentially) from features_df based stats: w={weight}\")\n","        elif feature in cluster_stats_original_scale_means.columns: # From original scale all_features_df\n","            senescent_score_0 += cluster_stats_original_scale_means.loc[0, feature] * weight\n","            senescent_score_1 += cluster_stats_original_scale_means.loc[1, feature] * weight\n","            print(f\"  Using {feature} (original scale) from all_features_df based stats: w={weight}\")\n","        else:\n","            print(f\"  Warning: Feature '{feature}' for scoring not found in available cluster stats. Skipping.\")\n","\n","    print(f\"Senescent score for cluster 0: {senescent_score_0:.4f}\")\n","    print(f\"Senescent score for cluster 1: {senescent_score_1:.4f}\")\n","\n","    senescent_cluster_label = 0 if senescent_score_0 > senescent_score_1 else 1\n","    non_senescent_cluster_label = 1 - senescent_cluster_label\n","    print(f\"Cluster {senescent_cluster_label} initially identified as 'Senescent'.\")\n","\n","    # --- 6. Initial Cell Type Assignment ---\n","    clustered_df['cell_type'] = clustered_df['cluster'].apply(\n","        lambda x: 'Senescent' if x == senescent_cluster_label else 'Non-senescent'\n","    )\n","\n","    # --- 7. (NEW) Post-processing: Multinucleation Rule ---\n","    # Force classify cells with nuclei_count > 2 as Senescent.\n","    # Ensure 'nuclei_count' is present in clustered_df (it should be from all_features_df).\n","    if 'nuclei_count' in clustered_df.columns:\n","        print(f\"\\nApplying multinucleation rule (nuclei_count > 2)...\")\n","        highly_multinucleated_mask = clustered_df['nuclei_count'] > 2\n","\n","        # Count how many were Non-senescent before this rule and will be changed\n","        num_reclassified = clustered_df.loc[highly_multinucleated_mask & (clustered_df['cell_type'] == 'Non-senescent')].shape[0]\n","\n","        clustered_df.loc[highly_multinucleated_mask, 'cell_type'] = 'Senescent'\n","        # Optional: use a distinct label like 'Senescent (Rule)' or 'Senescent (Multinucleated)'\n","        # if you want to track these specifically. If so, you'll need to update visualization palettes.\n","        print(f\"{highly_multinucleated_mask.sum()} cells have >2 nuclei.\")\n","        print(f\"{num_reclassified} cells re-classified from 'Non-senescent' to 'Senescent' by this rule.\")\n","    else:\n","        print(\"\\nWarning: 'nuclei_count' column not found. Cannot apply multinucleation rule.\")\n","\n","    print(\"\\nClustering process complete.\")\n","    return clustered_df\n","\n","def visualize_clustering_results(clustered_df):\n","    \"\"\"\n","    Create visualizations of the clustering results.\n","    \"\"\"\n","    print(\"\\n--- Creating Visualizations ---\")\n","\n","    # UMAP plot colored by cluster\n","    plt.figure(figsize=(12, 10))\n","\n","    # Scatter plot with UMAP results\n","    scatter = plt.scatter(\n","        clustered_df['umap_x'],\n","        clustered_df['umap_y'],\n","        c=clustered_df['cluster'],\n","        cmap='viridis',\n","        s=30,\n","        alpha=0.8\n","    )\n","\n","    # Add legend\n","    legend_labels = clustered_df['cell_type'].unique()\n","    handles = [plt.Line2D([0], [0], marker='o', color='w',\n","                        markerfacecolor=scatter.cmap(scatter.norm(i)),\n","                        markersize=10)\n","               for i in range(len(legend_labels))]\n","    plt.legend(handles, legend_labels, title='Cell Type', loc='upper right')\n","\n","    plt.title('UMAP Projection of Endothelial Cells', fontsize=14)\n","    plt.xlabel('UMAP Dimension 1', fontsize=12)\n","    plt.ylabel('UMAP Dimension 2', fontsize=12)\n","    plt.grid(True, linestyle='--', alpha=0.7)\n","\n","    # Save the UMAP visualization\n","    plt.savefig('umap_clustering_results.png', dpi=300, bbox_inches='tight')\n","    plt.close()\n","\n","    # Create a pair plot for key features\n","    key_features = ['cell_area', 'nuclei_count', 'avg_nucleus_area',\n","                   'nucleus_to_cell_area_ratio', 'cell_circularity']\n","\n","    plt.figure(figsize=(15, 12))\n","\n","    # Create custom pair plot\n","    fig, axes = plt.subplots(len(key_features), len(key_features), figsize=(15, 15))\n","\n","    for i, feature_x in enumerate(key_features):\n","        for j, feature_y in enumerate(key_features):\n","            ax = axes[i, j]\n","\n","            if i == j:  # Diagonal - histogram\n","                for cell_type, color in zip(['Non-senescent', 'Senescent'], ['blue', 'red']):\n","                    subset = clustered_df[clustered_df['cell_type'] == cell_type]\n","                    ax.hist(subset[feature_x], alpha=0.5, color=color, bins=20)\n","                ax.set_title(feature_x.replace('_', ' ').title(), fontsize=9)\n","\n","            else:  # Off-diagonal - scatter plot\n","                for cell_type, color in zip(['Non-senescent', 'Senescent'], ['blue', 'red']):\n","                    subset = clustered_df[clustered_df['cell_type'] == cell_type]\n","                    ax.scatter(subset[feature_x], subset[feature_y], s=10, alpha=0.5, color=color)\n","\n","                if j == 0:  # First column\n","                    ax.set_ylabel(feature_y.replace('_', ' ').title(), fontsize=9)\n","                if i == len(key_features) - 1:  # Last row\n","                    ax.set_xlabel(feature_x.replace('_', ' ').title(), fontsize=9)\n","\n","    # Add a common legend\n","    handles = [plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=c, markersize=10)\n","              for c in ['blue', 'red']]\n","    fig.legend(handles, ['Non-senescent', 'Senescent'],\n","               loc='upper center', bbox_to_anchor=(0.5, 0.98), ncol=2, fontsize=12)\n","\n","    plt.tight_layout(rect=[0, 0, 1, 0.97])\n","    plt.savefig('feature_relationships.png', dpi=300, bbox_inches='tight')\n","    plt.close()\n","\n","    # Feature distributions by cell type\n","    plt.figure(figsize=(15, 15))\n","\n","    # Create boxplots for key features\n","    fig, axes = plt.subplots(3, 2, figsize=(15, 15))\n","    axes = axes.flatten()\n","\n","    top_features = sorted(\n","        [(feature, abs(\n","            clustered_df[clustered_df['cell_type'] == 'Senescent'][feature].mean() -\n","            clustered_df[clustered_df['cell_type'] == 'Non-senescent'][feature].mean()\n","        )) for feature in key_features],\n","        key=lambda x: x[1],\n","        reverse=True\n","    )\n","\n","    for i, (feature, _) in enumerate(top_features[:6]):\n","        ax = axes[i]\n","        sns.boxplot(x='cell_type', y=feature, data=clustered_df, ax=ax, palette=['blue', 'red'])\n","        ax.set_title(feature.replace('_', ' ').title(), fontsize=12)\n","        ax.set_xlabel('')\n","        ax.set_ylabel(feature.replace('_', ' ').title(), fontsize=10)\n","\n","    plt.tight_layout()\n","    plt.savefig('feature_distributions.png', dpi=300, bbox_inches='tight')\n","    plt.close()\n","\n","    print(\"Visualizations saved to disk: umap_clustering_results.png, feature_relationships.png, feature_distributions.png\")\n","\n","def save_results(clustered_df, output_directory='results'):\n","    \"\"\"\n","    Save the clustering results to CSV files and create additional visualizations.\n","    \"\"\"\n","    # Create output directory if it doesn't exist\n","    if not os.path.exists(output_directory):\n","        os.makedirs(output_directory)\n","\n","    # Save full results\n","    clustered_df.to_csv(os.path.join(output_directory, 'cell_classification_results.csv'), index=False)\n","\n","    # Create summary by sample\n","    sample_summary = clustered_df.groupby('sample_id')['cell_type'].value_counts().unstack(fill_value=0)\n","\n","    # Handle case where some samples might not have both cell types\n","    if 'Senescent' not in sample_summary.columns:\n","        sample_summary['Senescent'] = 0\n","    if 'Non-senescent' not in sample_summary.columns:\n","        sample_summary['Non-senescent'] = 0\n","\n","    sample_summary['total_cells'] = sample_summary.sum(axis=1)\n","    sample_summary['percent_senescent'] = sample_summary['Senescent'] / sample_summary['total_cells'] * 100\n","\n","    sample_summary.to_csv(os.path.join(output_directory, 'sample_summary.csv'))\n","\n","    # Create and save additional visualizations\n","\n","    # 1. Senescent percentage by sample\n","    plt.figure(figsize=(12, 6))\n","    sns.barplot(x=sample_summary.index, y=sample_summary['percent_senescent'])\n","    plt.title('Percentage of Senescent Cells by Sample')\n","    plt.xlabel('Sample ID')\n","    plt.ylabel('Senescent Cells (%)')\n","    plt.xticks(rotation=90)\n","    plt.tight_layout()\n","    plt.savefig(os.path.join(output_directory, 'senescent_percentage_by_sample.png'), dpi=300)\n","    plt.close()\n","\n","    # 2. Scatter plot of key senescence indicators\n","    plt.figure(figsize=(10, 8))\n","    scatter = plt.scatter(\n","        clustered_df['cell_area'],\n","        clustered_df['avg_nucleus_area'],\n","        c=clustered_df['cell_type'].map({'Senescent': 1, 'Non-senescent': 0}),\n","        cmap='coolwarm',\n","        alpha=0.7,\n","        s=30\n","    )\n","    plt.xlabel('Cell Area')\n","    plt.ylabel('Average Nucleus Area')\n","    plt.title('Cell Area vs. Nuclear Area by Cell Type')\n","    plt.colorbar(scatter, label='Cell Type', ticks=[0, 1],\n","                format=plt.FuncFormatter(lambda x, pos: 'Non-senescent' if x < 0.5 else 'Senescent'))\n","    plt.tight_layout()\n","    plt.savefig(os.path.join(output_directory, 'area_relationship.png'), dpi=300)\n","    plt.close()\n","\n","    # 3. Nuclei count distribution\n","    plt.figure(figsize=(10, 6))\n","    nuclei_counts = clustered_df.groupby('cell_type')['nuclei_count'].value_counts(normalize=True).unstack(fill_value=0) * 100\n","    nuclei_counts.plot(kind='bar')\n","    plt.title('Distribution of Nuclei Count by Cell Type')\n","    plt.xlabel('Number of Nuclei')\n","    plt.ylabel('Percentage of Cells (%)')\n","    plt.legend(title='Cell Type')\n","    plt.tight_layout()\n","    plt.savefig(os.path.join(output_directory, 'nuclei_count_distribution.png'), dpi=300)\n","    plt.close()\n","\n","    print(f\"\\nResults saved to {output_directory}/\")\n","    print(f\"  - Full cell classification: cell_classification_results.csv\")\n","    print(f\"  - Sample summary: sample_summary.csv\")\n","    print(f\"  - Additional visualizations: senescent_percentage_by_sample.png, area_relationship.png, nuclei_count_distribution.png\")\n","\n","def main(cell_dir, nuclei_dir, output_dir=None):\n","    \"\"\"\n","    Main function to perform the analysis.\n","    \"\"\"\n","    print(\"=== Senescent Cell Classification Analysis ===\")\n","\n","    # Set default output directory if not provided\n","    if output_dir is None:\n","        output_dir = \"results\"\n","\n","    # Create output directory if it doesn't exist\n","    if not os.path.exists(output_dir):\n","        os.makedirs(output_dir)\n","\n","    # Find and pair mask files (without pressure classification)\n","    file_pairs = find_mask_files(cell_dir, nuclei_dir)\n","\n","    # Create a list to store all cell features\n","    all_cell_features = []\n","\n","    # Process all image pairs\n","    print(f\"\\nProcessing {len(file_pairs)} image pairs\")\n","\n","    # Process each image pair\n","    for file_pair in tqdm(file_pairs, desc=\"Processing images\"):\n","        try:\n","            # Load cell and nuclei masks\n","            cell_mask = load_mask_image(file_pair['cell_file'])\n","            nuclei_mask = load_mask_image(file_pair['nuclei_file'])\n","\n","            if cell_mask is None or nuclei_mask is None:\n","                print(f\"Error: Could not load masks for {file_pair['sample_id']}\")\n","                continue\n","\n","            # Track nuclei in cells\n","            results = accurately_track_nuclei_in_cells(cell_mask, nuclei_mask)\n","\n","            # Extract features for each cell\n","            for cell_data in results['cell_data']:\n","                features = extract_features_for_cell(\n","                    cell_data,\n","                    results['cell_nuclei_mapping'],\n","                    results['nuclei_data']\n","                )\n","\n","                # Add cell ID and sample ID\n","                features['cell_id'] = f\"{file_pair['sample_id']}_{cell_data['cell_id']}\"\n","                features['sample_id'] = file_pair['sample_id']\n","\n","                all_cell_features.append(features)\n","\n","        except Exception as e:\n","            print(f\"Error processing {file_pair['sample_id']}: {str(e)}\")\n","\n","    # Convert to DataFrame\n","    if all_cell_features:\n","        all_features_df = pd.DataFrame(all_cell_features)\n","        print(f\"\\nTotal cells extracted: {len(all_features_df)}\")\n","\n","        # Perform clustering\n","        clustered_df = perform_clustering(all_features_df)\n","\n","        # Visualize results\n","        visualize_clustering_results(clustered_df)\n","\n","        # Save results\n","        save_results(clustered_df, output_dir)\n","\n","        print(\"\\nAnalysis complete!\")\n","    else:\n","        print(\"No cell features were extracted. Please check your input files.\")\n","\n","if __name__ == \"__main__\":\n","    # Your specific directories\n","    cell_mask_dir = \"/content/drive/MyDrive/knowledge/University/Master/Thesis/Segmented/flow3-x20/Cell_merged_conservative\"\n","    nuclei_dir = \"/content/drive/MyDrive/knowledge/University/Master/Thesis/Segmented/flow3-x20/Nuclei\"\n","    output_dir = \"/content/drive/MyDrive/knowledge/University/Master/Thesis/Analysis/flow3-x20/Senescence\"\n","\n","    main(cell_mask_dir, nuclei_dir, output_dir)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gQOUqAj2aRSQ","executionInfo":{"status":"ok","timestamp":1746945114193,"user_tz":-120,"elapsed":1007652,"user":{"displayName":"Guido Putignano","userId":"13974663347531370398"}},"outputId":"cf9943de-4d6b-410c-d956-09faead5bd51"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["=== Senescent Cell Classification Analysis ===\n","\n","--- Finding and Pairing Mask Files ---\n","Found 8 cell mask files and 8 nuclei mask files\n","Nuclei file: 'denoised_0Pa_U_05mar19_20x_L2RA_Flat_seq001_Cadherins_filtered_mask.tif' → Sample ID: '0Pa_U_05mar19_20x_L2RA_Flat_seq001'\n","Nuclei file: 'denoised_0Pa_U_05mar19_20x_L2RA_Flat_seq002_Cadherins_filtered_mask.tif' → Sample ID: '0Pa_U_05mar19_20x_L2RA_Flat_seq002'\n","Nuclei file: 'denoised_0Pa_U_05mar19_20x_L2RA_Flat_seq003_Cadherins_filtered_mask.tif' → Sample ID: '0Pa_U_05mar19_20x_L2RA_Flat_seq003'\n","Nuclei file: 'denoised_1.4Pa_U_05mar19_20x_L2R_Flat_seq001_Cadherins_filtered_mask.tif' → Sample ID: '1.4Pa_U_05mar19_20x_L2R_Flat_seq001'\n","Nuclei file: 'denoised_1.4Pa_U_05mar19_20x_L2R_Flat_seq002_Cadherins_filtered_mask.tif' → Sample ID: '1.4Pa_U_05mar19_20x_L2R_Flat_seq002'\n","Nuclei file: 'denoised_1.4Pa_U_05mar19_20x_L2R_Flat_seq003_Cadherins_filtered_mask.tif' → Sample ID: '1.4Pa_U_05mar19_20x_L2R_Flat_seq003'\n","Nuclei file: 'denoised_1.4Pa_U_05mar19_20x_L2R_Flat_seq004_Cadherins_filtered_mask.tif' → Sample ID: '1.4Pa_U_05mar19_20x_L2R_Flat_seq004'\n","Nuclei file: 'denoised_1.4Pa_U_05mar19_20x_L2R_Flat_seq005_Cadherins_filtered_mask.tif' → Sample ID: '1.4Pa_U_05mar19_20x_L2R_Flat_seq005'\n","Cell file: '0Pa_U_05mar19_20x_L2RA_Flat_seq001_cell_mask_merged_conservative.tif' → Sample ID: '0Pa_U_05mar19_20x_L2RA_Flat_seq001'\n","Match found: 0Pa_U_05mar19_20x_L2RA_Flat_seq001\n","Cell file: '0Pa_U_05mar19_20x_L2RA_Flat_seq002_cell_mask_merged_conservative.tif' → Sample ID: '0Pa_U_05mar19_20x_L2RA_Flat_seq002'\n","Match found: 0Pa_U_05mar19_20x_L2RA_Flat_seq002\n","Cell file: '0Pa_U_05mar19_20x_L2RA_Flat_seq003_cell_mask_merged_conservative.tif' → Sample ID: '0Pa_U_05mar19_20x_L2RA_Flat_seq003'\n","Match found: 0Pa_U_05mar19_20x_L2RA_Flat_seq003\n","Cell file: '1.4Pa_U_05mar19_20x_L2R_Flat_seq001_cell_mask_merged_conservative.tif' → Sample ID: '1.4Pa_U_05mar19_20x_L2R_Flat_seq001'\n","Match found: 1.4Pa_U_05mar19_20x_L2R_Flat_seq001\n","Cell file: '1.4Pa_U_05mar19_20x_L2R_Flat_seq002_cell_mask_merged_conservative.tif' → Sample ID: '1.4Pa_U_05mar19_20x_L2R_Flat_seq002'\n","Match found: 1.4Pa_U_05mar19_20x_L2R_Flat_seq002\n","Cell file: '1.4Pa_U_05mar19_20x_L2R_Flat_seq003_cell_mask_merged_conservative.tif' → Sample ID: '1.4Pa_U_05mar19_20x_L2R_Flat_seq003'\n","Match found: 1.4Pa_U_05mar19_20x_L2R_Flat_seq003\n","Cell file: '1.4Pa_U_05mar19_20x_L2R_Flat_seq004_cell_mask_merged_conservative.tif' → Sample ID: '1.4Pa_U_05mar19_20x_L2R_Flat_seq004'\n","Match found: 1.4Pa_U_05mar19_20x_L2R_Flat_seq004\n","Cell file: '1.4Pa_U_05mar19_20x_L2R_Flat_seq005_cell_mask_merged_conservative.tif' → Sample ID: '1.4Pa_U_05mar19_20x_L2R_Flat_seq005'\n","Match found: 1.4Pa_U_05mar19_20x_L2R_Flat_seq005\n","Total matching cell-nuclei file pairs found: 8\n","\n","Processing 8 image pairs\n"]},{"output_type":"stream","name":"stderr","text":["\rProcessing images:   0%|          | 0/8 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["Found 329 cells and 367 nuclei\n"]},{"output_type":"stream","name":"stderr","text":["\rProcessing images:  12%|█▎        | 1/8 [02:13<15:33, 133.38s/it]"]},{"output_type":"stream","name":"stdout","text":["Cells with nuclei: 329/329 (100.0% of cells)\n","Cells with multiple nuclei: 31/329 (9.4% of cells)\n","  Cells with 1 nuclei: 298 (90.6%)\n","  Cells with 2 nuclei: 29 (8.8%)\n","  Cells with 3 nuclei: 2 (0.6%)\n","Found 368 cells and 431 nuclei\n"]},{"output_type":"stream","name":"stderr","text":["\rProcessing images:  25%|██▌       | 2/8 [05:13<16:04, 160.79s/it]"]},{"output_type":"stream","name":"stdout","text":["Cells with nuclei: 368/368 (100.0% of cells)\n","Cells with multiple nuclei: 55/368 (14.9% of cells)\n","  Cells with 1 nuclei: 313 (85.1%)\n","  Cells with 2 nuclei: 50 (13.6%)\n","  Cells with 3 nuclei: 5 (1.4%)\n","Found 385 cells and 450 nuclei\n"]},{"output_type":"stream","name":"stderr","text":["\rProcessing images:  38%|███▊      | 3/8 [08:29<14:44, 176.90s/it]"]},{"output_type":"stream","name":"stdout","text":["Cells with nuclei: 385/385 (100.0% of cells)\n","Cells with multiple nuclei: 54/385 (14.0% of cells)\n","  Cells with 1 nuclei: 331 (86.0%)\n","  Cells with 2 nuclei: 51 (13.2%)\n","  Cells with 3 nuclei: 1 (0.3%)\n","  Cells with 4 nuclei: 2 (0.5%)\n","Found 264 cells and 285 nuclei\n"]},{"output_type":"stream","name":"stderr","text":["\rProcessing images:  50%|█████     | 4/8 [09:57<09:27, 141.81s/it]"]},{"output_type":"stream","name":"stdout","text":["Cells with nuclei: 264/264 (100.0% of cells)\n","Cells with multiple nuclei: 20/264 (7.6% of cells)\n","  Cells with 1 nuclei: 244 (92.4%)\n","  Cells with 2 nuclei: 20 (7.6%)\n","Found 210 cells and 229 nuclei\n"]},{"output_type":"stream","name":"stderr","text":["\rProcessing images:  62%|██████▎   | 5/8 [10:48<05:27, 109.22s/it]"]},{"output_type":"stream","name":"stdout","text":["Cells with nuclei: 210/210 (100.0% of cells)\n","Cells with multiple nuclei: 15/210 (7.1% of cells)\n","  Cells with 1 nuclei: 195 (92.9%)\n","  Cells with 2 nuclei: 14 (6.7%)\n","  Cells with 3 nuclei: 1 (0.5%)\n","Found 294 cells and 315 nuclei\n"]},{"output_type":"stream","name":"stderr","text":["\rProcessing images:  75%|███████▌  | 6/8 [12:30<03:33, 106.73s/it]"]},{"output_type":"stream","name":"stdout","text":["Cells with nuclei: 294/294 (100.0% of cells)\n","Cells with multiple nuclei: 15/294 (5.1% of cells)\n","  Cells with 1 nuclei: 279 (94.9%)\n","  Cells with 2 nuclei: 14 (4.8%)\n","  Cells with 5 nuclei: 1 (0.3%)\n","Found 287 cells and 299 nuclei\n"]},{"output_type":"stream","name":"stderr","text":["\rProcessing images:  88%|████████▊ | 7/8 [14:06<01:43, 103.22s/it]"]},{"output_type":"stream","name":"stdout","text":["Cells with nuclei: 287/287 (100.0% of cells)\n","Cells with multiple nuclei: 9/287 (3.1% of cells)\n","  Cells with 1 nuclei: 278 (96.9%)\n","  Cells with 2 nuclei: 9 (3.1%)\n","Found 335 cells and 370 nuclei\n"]},{"output_type":"stream","name":"stderr","text":["Processing images: 100%|██████████| 8/8 [16:21<00:00, 122.72s/it]"]},{"output_type":"stream","name":"stdout","text":["Cells with nuclei: 335/335 (100.0% of cells)\n","Cells with multiple nuclei: 26/335 (7.8% of cells)\n","  Cells with 1 nuclei: 309 (92.2%)\n","  Cells with 2 nuclei: 24 (7.2%)\n","  Cells with 3 nuclei: 2 (0.6%)\n","\n","Total cells extracted: 2472\n","Starting clustering process...\n","\n","Applying log transformation to selected area/perimeter features...\n","  Log-transformed: cell_area\n","  Log-transformed: avg_nucleus_area\n","  Log-transformed: total_nuclear_area\n","  Log-transformed: max_nucleus_area\n","  Log-transformed: cell_perimeter\n","\n","Standardizing features...\n","\n","Performing UMAP reduction...\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n","  warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","Performing k-Means clustering (k=2)...\n","\n","Identifying senescent cluster using a weighted score...\n","Calculating senescent scores for clusters using weights:\n","  Using cell_area (log-transformed potentially) from features_df based stats: w=1.0\n","  Using avg_nucleus_area (log-transformed potentially) from features_df based stats: w=0.7\n","  Using total_nuclear_area (log-transformed potentially) from features_df based stats: w=0.5\n","  Using cell_perimeter (log-transformed potentially) from features_df based stats: w=0.5\n","  Using cell_enlargement (log-transformed potentially) from features_df based stats: w=1.5\n","  Using nuclear_enlargement (log-transformed potentially) from features_df based stats: w=1.0\n","  Using nuclei_count (log-transformed potentially) from features_df based stats: w=0.8\n","  Using cell_circularity (log-transformed potentially) from features_df based stats: w=-0.5\n","  Using nucleus_to_cell_area_ratio (log-transformed potentially) from features_df based stats: w=-1.0\n","Senescent score for cluster 0: 21.7833\n","Senescent score for cluster 1: 25.1540\n","Cluster 1 initially identified as 'Senescent'.\n","\n","Applying multinucleation rule (nuclei_count > 2)...\n","14 cells have >2 nuclei.\n","0 cells re-classified from 'Non-senescent' to 'Senescent' by this rule.\n","\n","Clustering process complete.\n","\n","--- Creating Visualizations ---\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-3-faf93a0c413f>:630: FutureWarning: \n","\n","Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n","\n","  sns.boxplot(x='cell_type', y=feature, data=clustered_df, ax=ax, palette=['blue', 'red'])\n","<ipython-input-3-faf93a0c413f>:630: FutureWarning: \n","\n","Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n","\n","  sns.boxplot(x='cell_type', y=feature, data=clustered_df, ax=ax, palette=['blue', 'red'])\n","<ipython-input-3-faf93a0c413f>:630: FutureWarning: \n","\n","Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n","\n","  sns.boxplot(x='cell_type', y=feature, data=clustered_df, ax=ax, palette=['blue', 'red'])\n","<ipython-input-3-faf93a0c413f>:630: FutureWarning: \n","\n","Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n","\n","  sns.boxplot(x='cell_type', y=feature, data=clustered_df, ax=ax, palette=['blue', 'red'])\n","<ipython-input-3-faf93a0c413f>:630: FutureWarning: \n","\n","Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n","\n","  sns.boxplot(x='cell_type', y=feature, data=clustered_df, ax=ax, palette=['blue', 'red'])\n"]},{"output_type":"stream","name":"stdout","text":["Visualizations saved to disk: umap_clustering_results.png, feature_relationships.png, feature_distributions.png\n","\n","Results saved to /content/drive/MyDrive/knowledge/University/Master/Thesis/Analysis/flow3-x20/Senescence/\n","  - Full cell classification: cell_classification_results.csv\n","  - Sample summary: sample_summary.csv\n","  - Additional visualizations: senescent_percentage_by_sample.png, area_relationship.png, nuclei_count_distribution.png\n","\n","Analysis complete!\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 1500x1200 with 0 Axes>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<Figure size 1500x1500 with 0 Axes>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<Figure size 1000x600 with 0 Axes>"]},"metadata":{}}]},{"cell_type":"markdown","source":["Make classifications"],"metadata":{"id":"3dkElWZhO6e_"}},{"cell_type":"code","source":["import os\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from matplotlib.colors import ListedColormap\n","import seaborn as sns\n","from skimage import io, measure, segmentation\n","from scipy import ndimage, spatial, stats\n","from sklearn.neighbors import NearestNeighbors\n","import cv2\n","import networkx as nx\n","from tqdm import tqdm\n","import re\n","\n","def analyze_spatial_distribution(cell_mask_dir, nuclei_dir, results_csv, output_dir=\"spatial_analysis\"):\n","    \"\"\"\n","    Analyze the spatial distribution of senescent vs non-senescent cells.\n","\n","    Parameters:\n","    -----------\n","    cell_mask_dir : str\n","        Directory containing the cell mask files\n","    nuclei_dir : str\n","        Directory containing the nuclei mask files\n","    results_csv : str\n","        Path to the cell_classification_results.csv file\n","    output_dir : str\n","        Directory to save the spatial analysis results\n","    \"\"\"\n","    print(\"=== Spatial Analysis of Senescent Cell Distribution ===\")\n","\n","    # Create output directory if it doesn't exist\n","    if not os.path.exists(output_dir):\n","        os.makedirs(output_dir)\n","\n","    # Load classification results\n","    results_df = pd.read_csv(results_csv)\n","    print(f\"Loaded {len(results_df)} classified cells\")\n","\n","    # Extract sample IDs and cell IDs from the results\n","    # Assuming cell_id format is \"sample_id_cell_id\"\n","    results_df['original_sample_id'] = results_df['cell_id'].apply(lambda x: '_'.join(x.split('_')[:-1]))\n","    results_df['original_cell_id'] = results_df['cell_id'].apply(lambda x: int(x.split('_')[-1]))\n","\n","    # Group by sample ID\n","    sample_groups = results_df.groupby('original_sample_id')\n","\n","    # Find and process mask files for each sample\n","    cell_files = [f for f in os.listdir(cell_mask_dir) if f.endswith(('.tif', '.tiff')) and not f.startswith('.')]\n","    nuclei_files = [f for f in os.listdir(nuclei_dir) if f.endswith(('.tif', '.tiff')) and not f.startswith('.')]\n","\n","    # Create DataFrames to store results\n","    spatial_stats = []\n","    neighbor_stats = []\n","\n","    # Process each sample in the results\n","    for sample_id, group in tqdm(sample_groups, desc=\"Analyzing spatial distribution\"):\n","        # Find the corresponding cell mask file\n","        cell_file = next((f for f in cell_files if sample_id in f), None)\n","\n","        if cell_file is None:\n","            print(f\"Warning: Could not find cell mask file for sample {sample_id}\")\n","            continue\n","\n","        # Load the cell mask\n","        cell_mask_path = os.path.join(cell_mask_dir, cell_file)\n","\n","        try:\n","            # Load mask\n","            cell_mask = load_mask_image(cell_mask_path)\n","\n","            if cell_mask is None:\n","                print(f\"Error: Could not load cell mask for {sample_id}\")\n","                continue\n","\n","            # Extract cell properties with centroids\n","            cell_props = extract_cell_properties(cell_mask)\n","\n","            # Map classification to cell properties\n","            cell_props = map_classification_to_cells(cell_props, group)\n","\n","            # Calculate nearest neighbor statistics\n","            nn_stats = calculate_nearest_neighbor_stats(cell_props, sample_id)\n","            neighbor_stats.append(nn_stats)\n","\n","            # Calculate spatial statistics (clustering, dispersion)\n","            spatial_result = calculate_spatial_statistics(cell_props, sample_id)\n","            spatial_stats.append(spatial_result)\n","\n","            # Visualize cell positions with color-coded classifications\n","            visualize_cell_positions(cell_props, sample_id, output_dir)\n","\n","            # Create neighborhood analysis visualization\n","            visualize_neighborhoods(cell_props, sample_id, output_dir)\n","\n","        except Exception as e:\n","            print(f\"Error processing {sample_id}: {str(e)}\")\n","\n","    # Combine results and save to CSV\n","    if spatial_stats:\n","        spatial_df = pd.DataFrame(spatial_stats)\n","        spatial_df.to_csv(os.path.join(output_dir, \"spatial_statistics.csv\"), index=False)\n","\n","    if neighbor_stats:\n","        neighbor_df = pd.DataFrame(neighbor_stats)\n","        neighbor_df.to_csv(os.path.join(output_dir, \"neighbor_statistics.csv\"), index=False)\n","\n","        # Create summary visualizations\n","        create_summary_visualizations(spatial_df, neighbor_df, output_dir)\n","\n","    print(f\"\\nSpatial analysis complete! Results saved to {output_dir}/\")\n","\n","def load_mask_image(filepath):\n","    \"\"\"Loads a mask image, ensuring it's properly formatted for analysis.\"\"\"\n","    try:\n","        img = io.imread(filepath)\n","\n","        # Handle multi-channel images\n","        if img.ndim > 2:\n","            if img.shape[2] == 3:  # RGB\n","                img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n","            elif img.shape[2] == 4:  # RGBA\n","                img = cv2.cvtColor(img, cv2.COLOR_RGBA2GRAY)\n","            else:\n","                img = img[:,:,0]\n","\n","        # If it's already a labeled mask (values > 1), use it directly\n","        if np.max(img) > 1:\n","            return img\n","\n","        # Otherwise, label the connected components\n","        labeled_img, num_features = ndimage.label(img > 0)\n","        return labeled_img\n","\n","    except Exception as e:\n","        print(f\"Error loading image {filepath}: {str(e)}\")\n","        return None\n","\n","def extract_cell_properties(cell_mask):\n","    \"\"\"\n","    Extract cell properties including centroids and boundaries.\n","\n","    Parameters:\n","    -----------\n","    cell_mask : ndarray\n","        Labeled cell mask\n","\n","    Returns:\n","    --------\n","    cell_props : list of dicts\n","        List of dictionaries containing cell properties\n","    \"\"\"\n","    # Extract region properties\n","    props = measure.regionprops(cell_mask)\n","\n","    cell_props = []\n","    for prop in props:\n","        cell_id = prop.label\n","\n","        # Skip background (label 0)\n","        if cell_id == 0:\n","            continue\n","\n","        cell_data = {\n","            'cell_id': cell_id,\n","            'centroid': prop.centroid,\n","            'area': prop.area,\n","            'perimeter': prop.perimeter,\n","            'eccentricity': prop.eccentricity if hasattr(prop, 'eccentricity') else 0,\n","            'classification': None,  # Will be filled later\n","            'neighbor_ids': [],  # Will be filled later\n","            'boundary_pixels': []  # Will be extracted below\n","        }\n","\n","        # Extract boundary pixels for this cell\n","        cell_mask_binary = (cell_mask == cell_id)\n","        boundary = segmentation.find_boundaries(cell_mask_binary, mode='outer')\n","        boundary_coords = np.where(boundary)\n","        cell_data['boundary_pixels'] = list(zip(boundary_coords[0], boundary_coords[1]))\n","\n","        cell_props.append(cell_data)\n","\n","    return cell_props\n","\n","def map_classification_to_cells(cell_props, classification_group):\n","    \"\"\"\n","    Map senescent/non-senescent classifications to cells.\n","\n","    Parameters:\n","    -----------\n","    cell_props : list of dicts\n","        List of cell properties\n","    classification_group : DataFrame\n","        DataFrame with classification results for this sample\n","\n","    Returns:\n","    --------\n","    cell_props : list of dicts\n","        Updated list with classifications added\n","    \"\"\"\n","    # Create mapping from cell ID to classification\n","    cell_classifications = dict(zip(\n","        classification_group['original_cell_id'],\n","        classification_group['cell_type']\n","    ))\n","\n","    # Map classifications to cell properties\n","    for cell in cell_props:\n","        cell_id = cell['cell_id']\n","        if cell_id in cell_classifications:\n","            cell['classification'] = cell_classifications[cell_id]\n","        else:\n","            cell['classification'] = 'Unknown'\n","\n","    return cell_props\n","\n","def calculate_nearest_neighbor_stats(cell_props, sample_id):\n","    \"\"\"\n","    Calculate nearest neighbor statistics for senescent vs non-senescent cells.\n","\n","    Parameters:\n","    -----------\n","    cell_props : list of dicts\n","        List of cell properties with classifications\n","    sample_id : str\n","        Sample identifier\n","\n","    Returns:\n","    --------\n","    stats : dict\n","        Dictionary of nearest neighbor statistics\n","    \"\"\"\n","    # Extract cell centroids and classifications\n","    centroids = np.array([cell['centroid'] for cell in cell_props])\n","    classifications = np.array([cell['classification'] for cell in cell_props])\n","\n","    # Skip if too few cells\n","    if len(centroids) < 5:\n","        return {\n","            'sample_id': sample_id,\n","            'senescent_nn_mean_distance': np.nan,\n","            'non_senescent_nn_mean_distance': np.nan,\n","            'senescent_to_senescent_ratio': np.nan,\n","            'mixed_neighbor_percentage': np.nan,\n","            'senescent_percentage': np.nan,\n","            'avg_senescent_per_neighborhood': np.nan\n","        }\n","\n","    # Find senescent and non-senescent cells\n","    senescent_mask = classifications == 'Senescent'\n","    non_senescent_mask = classifications == 'Non-senescent'\n","\n","    # Calculate percentage of senescent cells\n","    senescent_percentage = np.mean(senescent_mask) * 100\n","\n","    # Calculate nearest neighbors for each cell\n","    nn = NearestNeighbors(n_neighbors=min(6, len(centroids)))\n","    nn.fit(centroids)\n","    distances, indices = nn.kneighbors(centroids)\n","\n","    # First neighbor is the cell itself (distance=0), so use the second one\n","    nearest_dists = distances[:, 1]\n","    nearest_indices = indices[:, 1]\n","\n","    # Calculate mean nearest neighbor distance for each cell type\n","    sen_nn_dists = nearest_dists[senescent_mask]\n","    non_sen_nn_dists = nearest_dists[non_senescent_mask]\n","\n","    sen_nn_mean = np.mean(sen_nn_dists) if len(sen_nn_dists) > 0 else np.nan\n","    non_sen_nn_mean = np.mean(non_sen_nn_dists) if len(non_sen_nn_dists) > 0 else np.nan\n","\n","    # Calculate neighbor relationships\n","    # Check if senescent cells tend to have senescent neighbors\n","    sen_to_sen_neighbors = 0\n","    total_sen_neighbors = 0\n","\n","    for i, cell in enumerate(cell_props):\n","        if cell['classification'] == 'Senescent':\n","            neighbor_idx = nearest_indices[i]\n","            if classifications[neighbor_idx] == 'Senescent':\n","                sen_to_sen_neighbors += 1\n","            total_sen_neighbors += 1\n","\n","    # Calculate ratio of senescent-to-senescent neighbors\n","    sen_to_sen_ratio = sen_to_sen_neighbors / total_sen_neighbors if total_sen_neighbors > 0 else np.nan\n","\n","    # Calculate percentage of mixed neighborhoods\n","    # (neighborhoods with both senescent and non-senescent cells)\n","    mixed_neighborhoods = 0\n","    total_neighborhoods = len(centroids)\n","\n","    # Consider neighborhood as 5 nearest neighbors\n","    k = min(5, len(centroids) - 1)\n","    for i in range(len(centroids)):\n","        neighborhood = indices[i, 1:k+1]  # Skip first (self)\n","        neighbor_types = classifications[neighborhood]\n","        if np.any(neighbor_types == 'Senescent') and np.any(neighbor_types == 'Non-senescent'):\n","            mixed_neighborhoods += 1\n","\n","    mixed_percentage = (mixed_neighborhoods / total_neighborhoods) * 100 if total_neighborhoods > 0 else np.nan\n","\n","    # Calculate average number of senescent cells per neighborhood\n","    sen_per_neighborhood = []\n","    for i in range(len(centroids)):\n","        neighborhood = indices[i, :k+1]  # Include self\n","        neighbor_types = classifications[neighborhood]\n","        sen_per_neighborhood.append(np.sum(neighbor_types == 'Senescent'))\n","\n","    avg_sen_per_neighborhood = np.mean(sen_per_neighborhood)\n","\n","    # Return statistics\n","    return {\n","        'sample_id': sample_id,\n","        'senescent_nn_mean_distance': sen_nn_mean,\n","        'non_senescent_nn_mean_distance': non_sen_nn_mean,\n","        'senescent_to_senescent_ratio': sen_to_sen_ratio,\n","        'mixed_neighbor_percentage': mixed_percentage,\n","        'senescent_percentage': senescent_percentage,\n","        'avg_senescent_per_neighborhood': avg_sen_per_neighborhood\n","    }\n","\n","def calculate_spatial_statistics(cell_props, sample_id):\n","    \"\"\"\n","    Calculate spatial statistics for senescent vs non-senescent cells.\n","\n","    Parameters:\n","    -----------\n","    cell_props : list of dicts\n","        List of cell properties with classifications\n","    sample_id : str\n","        Sample identifier\n","\n","    Returns:\n","    --------\n","    stats : dict\n","        Dictionary of spatial statistics\n","    \"\"\"\n","    # Extract cell centroids and classifications\n","    centroids = np.array([cell['centroid'] for cell in cell_props])\n","    classifications = np.array([cell['classification'] for cell in cell_props])\n","\n","    # Skip if too few cells\n","    if len(centroids) < 5:\n","        return {\n","            'sample_id': sample_id,\n","            'nn_ratio': np.nan,\n","            'ripley_k_diff': np.nan,\n","            'sen_clustering_index': np.nan,\n","            'sen_dispersion_index': np.nan,\n","            'moran_i': np.nan,\n","            'geary_c': np.nan\n","        }\n","\n","    # Find senescent and non-senescent cells\n","    senescent_mask = classifications == 'Senescent'\n","    non_senescent_mask = classifications == 'Non-senescent'\n","\n","    senescent_centroids = centroids[senescent_mask]\n","    non_senescent_centroids = centroids[non_senescent_mask]\n","\n","    # Calculate nearest neighbor ratio (Clark-Evans R statistic)\n","    def calculate_clark_evans_r(points):\n","        if len(points) < 2:\n","            return np.nan\n","\n","        # Calculate mean nearest neighbor distance\n","        nn = NearestNeighbors(n_neighbors=2)  # 2 because first neighbor is self\n","        nn.fit(points)\n","        distances, _ = nn.kneighbors(points)\n","        mean_nn_dist = np.mean(distances[:, 1])\n","\n","        # Calculate point density using bounding box approximation\n","        min_x, min_y = np.min(points, axis=0)\n","        max_x, max_y = np.max(points, axis=0)\n","        area = (max_x - min_x) * (max_y - min_y)\n","\n","        if area == 0:  # Handle edge case\n","            return np.nan\n","\n","        density = len(points) / area\n","\n","        # Expected mean distance for random distribution\n","        expected_mean_dist = 0.5 / np.sqrt(density)\n","\n","        # Clark-Evans R statistic\n","        r = mean_nn_dist / expected_mean_dist if expected_mean_dist > 0 else np.nan\n","\n","        return r\n","\n","    # Calculate Clark-Evans R for senescent cells\n","    nn_ratio = calculate_clark_evans_r(senescent_centroids)\n","\n","    # Calculate a simplified Ripley's K function for detecting clustering\n","    def simplified_ripley_k(points, r_max, n_steps=10):\n","        if len(points) < 5:\n","            return np.zeros(n_steps)\n","\n","        n_points = len(points)\n","\n","        # Calculate bounding box area\n","        min_x, min_y = np.min(points, axis=0)\n","        max_x, max_y = np.max(points, axis=0)\n","        area = (max_x - min_x) * (max_y - min_y)\n","\n","        if area == 0:  # Handle edge case\n","            return np.zeros(n_steps)\n","\n","        # Calculate distances between all pairs of points\n","        distances = spatial.distance.pdist(points)\n","\n","        # Calculate K function for different radii\n","        r_values = np.linspace(0, r_max, n_steps)\n","        k_values = np.zeros(n_steps)\n","\n","        for i, r in enumerate(r_values):\n","            # Count pairs with distance <= r\n","            count = np.sum(distances <= r)\n","            # Ripley's K formula (simplified)\n","            k = (area * count) / (n_points * (n_points - 1)) if n_points > 1 else 0\n","            k_values[i] = k\n","\n","        return k_values\n","\n","    # Calculate max radius as half the maximum dimension of the bounding box\n","    if len(centroids) > 0:\n","        min_x, min_y = np.min(centroids, axis=0)\n","        max_x, max_y = np.max(centroids, axis=0)\n","        r_max = max(max_x - min_x, max_y - min_y) / 2\n","    else:\n","        r_max = 100  # Default value\n","\n","    # Calculate Ripley's K for senescent and non-senescent cells\n","    k_sen = simplified_ripley_k(senescent_centroids, r_max)\n","    k_non_sen = simplified_ripley_k(non_senescent_centroids, r_max)\n","\n","    # Calculate difference in K functions (positive indicates more clustering in senescent)\n","    ripley_k_diff = np.mean(k_sen - k_non_sen) if len(k_sen) > 0 and len(k_non_sen) > 0 else np.nan\n","\n","    # Create binary indicator for senescent cells (1 = senescent, 0 = non-senescent)\n","    values = np.where(classifications == 'Senescent', 1, 0)\n","\n","    # Calculate spatial autocorrelation (simplified)\n","    moran_i = np.nan\n","    geary_c = np.nan\n","\n","    # Find neighbors for each cell\n","    k = min(5, len(centroids) - 1)\n","    if k > 0:\n","        nn = NearestNeighbors(n_neighbors=k+1)  # +1 to include self\n","        nn.fit(centroids)\n","        _, indices = nn.kneighbors(centroids)\n","\n","        # Calculate senescent clustering index\n","        observed_sen_neighbors = 0\n","        total_neighbors = 0\n","        sen_ratio = np.mean(values)\n","\n","        for i, cell_type in enumerate(values):\n","            if cell_type == 1:  # If senescent\n","                # Get neighbors excluding self\n","                neighbors = indices[i, 1:]\n","                observed_sen_neighbors += np.sum(values[neighbors])\n","                total_neighbors += len(neighbors)\n","\n","        # Expected number of senescent neighbors based on random distribution\n","        expected_sen_neighbors = total_neighbors * sen_ratio if sen_ratio > 0 else 0\n","\n","        # Clustering index: ratio of observed to expected\n","        sen_clustering_index = observed_sen_neighbors / expected_sen_neighbors if expected_sen_neighbors > 0 else np.nan\n","\n","        # Dispersion index - coefficient of variation of nearest neighbor distances\n","        if len(senescent_centroids) >= 2:\n","            nn_sen = NearestNeighbors(n_neighbors=2)\n","            nn_sen.fit(senescent_centroids)\n","            sen_dists, _ = nn_sen.kneighbors(senescent_centroids)\n","            sen_dists = sen_dists[:, 1]  # Exclude self\n","\n","            sen_dispersion_index = np.std(sen_dists) / np.mean(sen_dists) if np.mean(sen_dists) > 0 else np.nan\n","        else:\n","            sen_dispersion_index = np.nan\n","    else:\n","        sen_clustering_index = np.nan\n","        sen_dispersion_index = np.nan\n","\n","    # Return results\n","    return {\n","        'sample_id': sample_id,\n","        'nn_ratio': nn_ratio,\n","        'ripley_k_diff': ripley_k_diff,\n","        'sen_clustering_index': sen_clustering_index,\n","        'sen_dispersion_index': sen_dispersion_index,\n","        'moran_i': moran_i,\n","        'geary_c': geary_c\n","    }\n","\n","def visualize_cell_positions(cell_props, sample_id, output_dir):\n","    \"\"\"\n","    Create a visualization of cell positions with senescent/non-senescent color coding.\n","\n","    Parameters:\n","    -----------\n","    cell_props : list of dicts\n","        List of cell properties with classifications\n","    sample_id : str\n","        Sample identifier\n","    output_dir : str\n","        Directory to save visualization\n","    \"\"\"\n","    # Extract cell centroids and classifications\n","    centroids = np.array([cell['centroid'] for cell in cell_props])\n","    classifications = np.array([cell['classification'] for cell in cell_props])\n","    areas = np.array([cell['area'] for cell in cell_props])\n","\n","    # Skip if too few cells\n","    if len(centroids) < 2:\n","        return\n","\n","    # Create scatter plot of cell positions\n","    plt.figure(figsize=(10, 10))\n","\n","    # Create color map for classification\n","    color_map = {'Senescent': 'red', 'Non-senescent': 'blue', 'Unknown': 'gray'}\n","    colors = [color_map[c] for c in classifications]\n","\n","    # Scale point sizes based on cell area\n","    min_area = np.min(areas)\n","    max_area = np.max(areas)\n","    normalized_areas = 50 * (areas - min_area) / (max_area - min_area) + 20\n","\n","    # Plot cell positions with colors indicating classification\n","    scatter = plt.scatter(\n","        centroids[:, 1],  # x coordinate (column 1)\n","        centroids[:, 0],  # y coordinate (column 0)\n","        c=colors,\n","        s=normalized_areas,\n","        alpha=0.7,\n","        edgecolor='black',\n","        linewidth=0.5\n","    )\n","\n","    # Invert y-axis to match image coordinates\n","    plt.gca().invert_yaxis()\n","\n","    # Add legend\n","    legend_elements = [\n","        plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='red',\n","                  markersize=10, label='Senescent'),\n","        plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='blue',\n","                  markersize=10, label='Non-senescent')\n","    ]\n","    plt.legend(handles=legend_elements, loc='upper right')\n","\n","    plt.title(f'Cell Positions - {sample_id}', fontsize=14)\n","    plt.xlabel('X Position', fontsize=12)\n","    plt.ylabel('Y Position', fontsize=12)\n","    plt.grid(True, alpha=0.3)\n","\n","    # Save the visualization\n","    plt.tight_layout()\n","    plt.savefig(os.path.join(output_dir, f'{sample_id}_cell_positions.png'), dpi=300, bbox_inches='tight')\n","    plt.close()\n","\n","    # Create additional visualization showing nearest neighbor connections\n","    plt.figure(figsize=(12, 12))\n","\n","    # Plot cell positions again\n","    plt.scatter(\n","        centroids[:, 1],  # x coordinate\n","        centroids[:, 0],  # y coordinate\n","        c=colors,\n","        s=normalized_areas,\n","        alpha=0.7,\n","        edgecolor='black',\n","        linewidth=0.5\n","    )\n","\n","    # Connect nearest neighbors with lines\n","    k = min(3, len(centroids) - 1)\n","    if k > 0:\n","        nn = NearestNeighbors(n_neighbors=k+1)  # +1 to include self\n","        nn.fit(centroids)\n","        distances, indices = nn.kneighbors(centroids)\n","\n","        # Draw lines between neighbors\n","        for i, neighbors in enumerate(indices):\n","            # Skip first neighbor (self)\n","            for j in neighbors[1:]:\n","                # Draw line with alpha based on distance\n","                plt.plot(\n","                    [centroids[i, 1], centroids[j, 1]],  # x coordinates\n","                    [centroids[i, 0], centroids[j, 0]],  # y coordinates\n","                    color='gray',\n","                    alpha=0.3,\n","                    linewidth=0.5\n","                )\n","\n","    # Invert y-axis\n","    plt.gca().invert_yaxis()\n","\n","    # Add legend\n","    plt.legend(handles=legend_elements, loc='upper right')\n","\n","    plt.title(f'Cell Neighborhoods - {sample_id}', fontsize=14)\n","    plt.xlabel('X Position', fontsize=12)\n","    plt.ylabel('Y Position', fontsize=12)\n","    plt.grid(True, alpha=0.3)\n","\n","    # Save the visualization\n","    plt.tight_layout()\n","    plt.savefig(os.path.join(output_dir, f'{sample_id}_cell_neighborhoods.png'), dpi=300, bbox_inches='tight')\n","    plt.close()\n","\n","def visualize_neighborhoods(cell_props, sample_id, output_dir):\n","    \"\"\"\n","    Create a network visualization showing relationships between cells.\n","\n","    Parameters:\n","    -----------\n","    cell_props : list of dicts\n","        List of cell properties with classifications\n","    sample_id : str\n","        Sample identifier\n","    output_dir : str\n","        Directory to save visualization\n","    \"\"\"\n","    # Extract cell centroids and classifications\n","    centroids = np.array([cell['centroid'] for cell in cell_props])\n","    classifications = np.array([cell['classification'] for cell in cell_props])\n","\n","    # Skip if too few cells\n","    if len(centroids) < 5:\n","        return\n","\n","    # Build a graph to represent cell neighborhoods\n","    G = nx.Graph()\n","\n","    # Add nodes with positions and classifications\n","    for i, (pos, classification) in enumerate(zip(centroids, classifications)):\n","        G.add_node(i, pos=(pos[1], -pos[0]), classification=classification)\n","\n","    # Connect nearest neighbors\n","    k = min(5, len(centroids) - 1)\n","    if k > 0:\n","        nn = NearestNeighbors(n_neighbors=k+1)  # +1 to include self\n","        nn.fit(centroids)\n","        distances, indices = nn.kneighbors(centroids)\n","\n","        # Add edges\n","        for i, neighbors in enumerate(indices):\n","            # Skip first neighbor (self)\n","            for j, d in zip(neighbors[1:], distances[i, 1:]):\n","                G.add_edge(i, j, weight=1.0/d if d > 0 else 1.0)\n","\n","    # Create figure\n","    plt.figure(figsize=(14, 12))\n","\n","    # Get node positions\n","    pos = nx.get_node_attributes(G, 'pos')\n","\n","    # Get node colors based on classification\n","    node_colors = []\n","    for node in G.nodes():\n","        if G.nodes[node]['classification'] == 'Senescent':\n","            node_colors.append('red')\n","        elif G.nodes[node]['classification'] == 'Non-senescent':\n","            node_colors.append('blue')\n","        else:\n","            node_colors.append('gray')\n","\n","    # Draw the graph\n","    nx.draw_networkx_nodes(\n","        G, pos,\n","        node_color=node_colors,\n","        node_size=80,\n","        alpha=0.8,\n","        edgecolors='black',\n","        linewidths=0.5\n","    )\n","\n","    # Categorize edges based on node classifications\n","    sen_to_sen_edges = []\n","    non_sen_to_non_sen_edges = []\n","    mixed_edges = []\n","\n","    for u, v in G.edges():\n","        u_class = G.nodes[u]['classification']\n","        v_class = G.nodes[v]['classification']\n","\n","        if u_class == 'Senescent' and v_class == 'Senescent':\n","            sen_to_sen_edges.append((u, v))\n","        elif u_class == 'Non-senescent' and v_class == 'Non-senescent':\n","            non_sen_to_non_sen_edges.append((u, v))\n","        else:\n","            mixed_edges.append((u, v))\n","\n","    # Draw edges with different colors\n","    nx.draw_networkx_edges(\n","        G, pos,\n","        edgelist=sen_to_sen_edges,\n","        width=1.0,\n","        alpha=0.7,\n","        edge_color='red'\n","    )\n","\n","    nx.draw_networkx_edges(\n","        G, pos,\n","        edgelist=non_sen_to_non_sen_edges,\n","        width=1.0,\n","        alpha=0.7,\n","        edge_color='blue'\n","    )\n","\n","    nx.draw_networkx_edges(\n","        G, pos,\n","        edgelist=mixed_edges,\n","        width=0.5,\n","        alpha=0.3,\n","        edge_color='purple',\n","        style='dashed'\n","    )\n","\n","    # Add legend\n","    legend_elements = [\n","        plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='red',\n","                  markersize=10, label='Senescent Cell'),\n","        plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='blue',\n","                  markersize=10, label='Non-senescent Cell'),\n","        plt.Line2D([0], [0], color='red', lw=2, label='Senescent-Senescent Connection'),\n","        plt.Line2D([0], [0], color='blue', lw=2, label='Non-senescent-Non-senescent Connection'),\n","        plt.Line2D([0], [0], color='purple', lw=2, linestyle='--', label='Mixed Connection')\n","    ]\n","    plt.legend(handles=legend_elements, loc='upper right')\n","\n","    plt.title(f'Cell Interaction Network - {sample_id}', fontsize=14)\n","    plt.axis('off')\n","\n","    # Save the visualization\n","    plt.tight_layout()\n","    plt.savefig(os.path.join(output_dir, f'{sample_id}_cell_network.png'), dpi=300, bbox_inches='tight')\n","    plt.close()\n","\n","    # Create a density visualization showing clustering of senescent cells\n","    plt.figure(figsize=(12, 10))\n","\n","    # Get just the senescent cell positions\n","    senescent_positions = [pos[i] for i, c in enumerate(classifications) if c == 'Senescent']\n","    non_senescent_positions = [pos[i] for i, c in enumerate(classifications) if c == 'Non-senescent']\n","\n","    if senescent_positions and len(senescent_positions) > 5:\n","        senescent_positions = np.array(senescent_positions)\n","\n","        # Plot heatmap for senescent cells\n","        try:\n","            # Create a 2D histogram\n","            heatmap, xedges, yedges = np.histogram2d(\n","                [p[1] for p in senescent_positions],\n","                [-p[0] for p in senescent_positions],\n","                bins=50\n","            )\n","\n","            # Smooth the heatmap\n","            heatmap = ndimage.gaussian_filter(heatmap, sigma=1.5)\n","\n","            # Plot the heatmap with transparency\n","            extent = [xedges[0], xedges[-1], yedges[0], yedges[-1]]\n","            plt.imshow(heatmap.T, extent=extent, origin='lower', cmap='Reds', alpha=0.7)\n","\n","            # Add contour lines\n","            plt.contour(heatmap.T, extent=extent, colors='red', alpha=0.5, levels=5)\n","        except Exception as e:\n","            print(f\"Warning: Could not create heatmap for {sample_id}: {e}\")\n","\n","    # Plot all cell positions\n","    plt.scatter(\n","        [p[1] for p in centroids],\n","        [-p[0] for p in centroids],\n","        c=[{'Senescent': 'red', 'Non-senescent': 'blue', 'Unknown': 'gray'}[c] for c in classifications],\n","        s=30,\n","        alpha=0.7,\n","        edgecolor='black',\n","        linewidth=0.5\n","    )\n","\n","    plt.title(f'Senescent Cell Density - {sample_id}', fontsize=14)\n","    plt.xlabel('X Position', fontsize=12)\n","    plt.ylabel('Y Position', fontsize=12)\n","    plt.colorbar(label='Senescent Cell Density')\n","\n","    # Save the visualization\n","    plt.tight_layout()\n","    plt.savefig(os.path.join(output_dir, f'{sample_id}_senescent_density.png'), dpi=300, bbox_inches='tight')\n","    plt.close()\n","\n","def create_summary_visualizations(spatial_df, neighbor_df, output_dir):\n","    \"\"\"\n","    Create summary visualizations of spatial statistics across all samples.\n","\n","    Parameters:\n","    -----------\n","    spatial_df : DataFrame\n","        DataFrame with spatial statistics\n","    neighbor_df : DataFrame\n","        DataFrame with neighbor statistics\n","    output_dir : str\n","        Directory to save visualizations\n","    \"\"\"\n","    if spatial_df.empty or neighbor_df.empty:\n","        return\n","\n","    # Merge the dataframes\n","    df = pd.merge(spatial_df, neighbor_df, on='sample_id', how='outer')\n","\n","    # Calculate overall senescent clustering pattern\n","    # 1. Plot clustering index vs percentage of senescent cells\n","    plt.figure(figsize=(10, 8))\n","\n","    plt.scatter(\n","        df['senescent_percentage'],\n","        df['sen_clustering_index'],\n","        s=80,\n","        alpha=0.7,\n","        c=df['senescent_percentage'],\n","        cmap='RdYlBu_r',\n","        edgecolor='black'\n","    )\n","\n","    # Add trendline\n","    if len(df) > 1:\n","        try:\n","            z = np.polyfit(df['senescent_percentage'], df['sen_clustering_index'], 1)\n","            p = np.poly1d(z)\n","            plt.plot(\n","                np.sort(df['senescent_percentage']),\n","                p(np.sort(df['senescent_percentage'])),\n","                \"r--\",\n","                alpha=0.8\n","            )\n","\n","            # Calculate correlation\n","            corr = df['senescent_percentage'].corr(df['sen_clustering_index'])\n","            plt.text(\n","                0.05, 0.95,\n","                f'Correlation: {corr:.2f}',\n","                transform=plt.gca().transAxes,\n","                fontsize=12,\n","                verticalalignment='top',\n","                bbox=dict(boxstyle='round', facecolor='white', alpha=0.8)\n","            )\n","        except Exception as e:\n","            print(f\"Warning: Could not create trendline: {e}\")\n","\n","    # Add reference line for random distribution\n","    plt.axhline(y=1.0, color='gray', linestyle='--', alpha=0.5)\n","\n","    plt.title('Senescent Cell Clustering vs Percentage', fontsize=14)\n","    plt.xlabel('Percentage of Senescent Cells (%)', fontsize=12)\n","    plt.ylabel('Clustering Index\\n(>1 = Clustered, <1 = Dispersed)', fontsize=12)\n","    plt.colorbar(label='Percentage of Senescent Cells (%)')\n","    plt.grid(True, alpha=0.3)\n","\n","    # Save the visualization\n","    plt.tight_layout()\n","    plt.savefig(os.path.join(output_dir, 'senescent_clustering_vs_percentage.png'), dpi=300, bbox_inches='tight')\n","    plt.close()\n","\n","    # 2. Create a spatial pattern summary for all samples\n","    plt.figure(figsize=(12, 10))\n","\n","    # Prepare data for boxplot\n","    boxplot_data = [\n","        df['senescent_nn_mean_distance'].dropna(),\n","        df['non_senescent_nn_mean_distance'].dropna(),\n","    ]\n","\n","    # Create boxplot\n","    plt.boxplot(\n","        boxplot_data,\n","        labels=['Senescent', 'Non-senescent'],\n","        patch_artist=True,\n","        boxprops=dict(facecolor='lightblue'),\n","        medianprops=dict(color='red'),\n","        showfliers=False\n","    )\n","\n","    # Add individual points\n","    for i, data in enumerate(boxplot_data):\n","        x = np.random.normal(i+1, 0.04, size=len(data))\n","        plt.scatter(x, data, alpha=0.6, s=40, edgecolor='black', linewidth=0.5)\n","\n","    plt.title('Nearest Neighbor Distances by Cell Type', fontsize=14)\n","    plt.ylabel('Mean Nearest Neighbor Distance', fontsize=12)\n","    plt.grid(axis='y', alpha=0.3)\n","\n","    # Save the visualization\n","    plt.tight_layout()\n","    plt.savefig(os.path.join(output_dir, 'nearest_neighbor_distances.png'), dpi=300, bbox_inches='tight')\n","    plt.close()\n","\n","    # 3. Create a heatmap of correlation between spatial metrics\n","    plt.figure(figsize=(12, 10))\n","\n","    # Select relevant columns for correlation\n","    correlation_cols = [\n","        'senescent_percentage', 'sen_clustering_index', 'nn_ratio',\n","        'sen_dispersion_index', 'senescent_to_senescent_ratio',\n","        'mixed_neighbor_percentage'\n","    ]\n","\n","    # Calculate correlation matrix\n","    corr_matrix = df[correlation_cols].corr()\n","\n","    # Create heatmap\n","    sns.heatmap(\n","        corr_matrix,\n","        annot=True,\n","        cmap='coolwarm',\n","        vmin=-1,\n","        vmax=1,\n","        linewidths=0.5,\n","        fmt='.2f'\n","    )\n","\n","    plt.title('Correlation Between Spatial Metrics', fontsize=14)\n","    plt.tight_layout()\n","    plt.savefig(os.path.join(output_dir, 'spatial_metrics_correlation.png'), dpi=300, bbox_inches='tight')\n","    plt.close()\n","\n","    # 4. Create a distribution of senescent cell clustering index\n","    plt.figure(figsize=(10, 8))\n","\n","    # Create histogram with KDE\n","    sns.histplot(\n","        df['sen_clustering_index'].dropna(),\n","        kde=True,\n","        stat='density',\n","        color='skyblue',\n","        edgecolor='black',\n","        alpha=0.7\n","    )\n","\n","    # Add vertical line at random distribution (1.0)\n","    plt.axvline(x=1.0, color='red', linestyle='--', alpha=0.7, label='Random Distribution')\n","\n","    # Add mean line\n","    mean_value = df['sen_clustering_index'].mean()\n","    plt.axvline(x=mean_value, color='green', linestyle='-', alpha=0.7, label=f'Mean = {mean_value:.2f}')\n","\n","    plt.title('Distribution of Senescent Cell Clustering Index', fontsize=14)\n","    plt.xlabel('Clustering Index\\n(>1 = Clustered, <1 = Dispersed)', fontsize=12)\n","    plt.ylabel('Density', fontsize=12)\n","    plt.legend()\n","    plt.grid(alpha=0.3)\n","\n","    # Save the visualization\n","    plt.tight_layout()\n","    plt.savefig(os.path.join(output_dir, 'clustering_index_distribution.png'), dpi=300, bbox_inches='tight')\n","    plt.close()"],"metadata":{"id":"RP0slpClnBEg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Here it's possible to visualise the classification"],"metadata":{"id":"n2GuhT3BOilw"}},{"cell_type":"code","source":["import os\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as mpatches\n","from matplotlib.colors import ListedColormap\n","from skimage import io, measure, segmentation, color\n","import seaborn as sns\n","from scipy import ndimage\n","import cv2\n","from tqdm import tqdm\n","\n","def visualize_classification_on_masks(cell_mask_dir, nuclei_dir, results_csv, output_dir=\"visualization_results\"):\n","    \"\"\"\n","    Visualize the senescent cell classification results by overlaying them on the original masks.\n","\n","    Parameters:\n","    -----------\n","    cell_mask_dir : str\n","        Directory containing the cell mask files\n","    nuclei_dir : str\n","        Directory containing the nuclei mask files\n","    results_csv : str\n","        Path to the cell_classification_results.csv file\n","    output_dir : str\n","        Directory to save the visualization results\n","    \"\"\"\n","    print(\"=== Visualization of Senescent Cell Classification ===\")\n","\n","    # Create output directory if it doesn't exist\n","    if not os.path.exists(output_dir):\n","        os.makedirs(output_dir)\n","\n","    # Load classification results\n","    results_df = pd.read_csv(results_csv)\n","    print(f\"Loaded {len(results_df)} classified cells\")\n","\n","    # Extract sample IDs and cell IDs from the results\n","    # Assuming cell_id format is \"sample_id_cell_id\"\n","    results_df['original_sample_id'] = results_df['cell_id'].apply(lambda x: '_'.join(x.split('_')[:-1]))\n","    results_df['original_cell_id'] = results_df['cell_id'].apply(lambda x: int(x.split('_')[-1]))\n","\n","    # Group by sample ID\n","    sample_groups = results_df.groupby('original_sample_id')\n","\n","    # Find and process mask files for each sample\n","    cell_files = [f for f in os.listdir(cell_mask_dir) if f.endswith(('.tif', '.tiff')) and not f.startswith('.')]\n","    nuclei_files = [f for f in os.listdir(nuclei_dir) if f.endswith(('.tif', '.tiff')) and not f.startswith('.')]\n","\n","    # Process each sample in the results\n","    for sample_id, group in tqdm(sample_groups, desc=\"Visualizing samples\"):\n","        # Find the corresponding cell and nuclei mask files\n","        cell_file = next((f for f in cell_files if sample_id in f), None)\n","        nuclei_file = next((f for f in nuclei_files if sample_id in f), None)\n","\n","        if cell_file is None or nuclei_file is None:\n","            print(f\"Warning: Could not find mask files for sample {sample_id}\")\n","            continue\n","\n","        # Load the mask images\n","        cell_mask_path = os.path.join(cell_mask_dir, cell_file)\n","        nuclei_mask_path = os.path.join(nuclei_dir, nuclei_file)\n","\n","        try:\n","            # Load masks\n","            cell_mask = load_mask_image(cell_mask_path)\n","            nuclei_mask = load_mask_image(nuclei_mask_path)\n","\n","            if cell_mask is None or nuclei_mask is None:\n","                print(f\"Error: Could not load masks for {sample_id}\")\n","                continue\n","\n","            # Create colored overlay based on classification\n","            colored_mask = create_classification_overlay(cell_mask, nuclei_mask, group)\n","\n","            # Save the visualization\n","            output_file = os.path.join(output_dir, f\"{sample_id}_classification_overlay.png\")\n","            plt.imsave(output_file, colored_mask)\n","\n","            # Create a more detailed visualization with boundaries\n","            detailed_vis = create_detailed_visualization(cell_mask, nuclei_mask, group)\n","            detailed_output = os.path.join(output_dir, f\"{sample_id}_detailed_classification.png\")\n","            plt.imsave(detailed_output, detailed_vis)\n","\n","        except Exception as e:\n","            print(f\"Error processing {sample_id}: {str(e)}\")\n","\n","    # Create summary visualizations\n","    create_summary_visualizations(results_df, output_dir)\n","\n","    print(f\"\\nVisualization complete! Results saved to {output_dir}/\")\n","\n","def load_mask_image(filepath):\n","    \"\"\"Loads a mask image, ensuring it's properly formatted for visualization.\"\"\"\n","    try:\n","        img = io.imread(filepath)\n","\n","        # Handle multi-channel images\n","        if img.ndim > 2:\n","            if img.shape[2] == 3:  # RGB\n","                img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n","            elif img.shape[2] == 4:  # RGBA\n","                img = cv2.cvtColor(img, cv2.COLOR_RGBA2GRAY)\n","            else:\n","                img = img[:,:,0]\n","\n","        # If it's already a labeled mask (values > 1), use it directly\n","        if np.max(img) > 1:\n","            return img\n","\n","        # Otherwise, label the connected components\n","        labeled_img, num_features = ndimage.label(img > 0)\n","        return labeled_img\n","\n","    except Exception as e:\n","        print(f\"Error loading image {filepath}: {str(e)}\")\n","        return None\n","\n","def create_classification_overlay(cell_mask, nuclei_mask, classification_group):\n","    \"\"\"\n","    Create a colored overlay showing senescent vs non-senescent cells.\n","\n","    Parameters:\n","    -----------\n","    cell_mask : ndarray\n","        Labeled cell mask\n","    nuclei_mask : ndarray\n","        Labeled nuclei mask\n","    classification_group : DataFrame\n","        DataFrame containing classification results for this sample\n","\n","    Returns:\n","    --------\n","    colored_mask : ndarray\n","        RGB image with colored overlay\n","    \"\"\"\n","    # Create a blank RGB image\n","    h, w = cell_mask.shape\n","    colored_mask = np.zeros((h, w, 3), dtype=np.uint8)\n","\n","    # Define colors for each class\n","    # Senescent: Red, Non-senescent: Blue, Background: Black\n","    senescent_color = np.array([220, 50, 50])     # Red\n","    non_senescent_color = np.array([50, 50, 220]) # Blue\n","    nuclei_color = np.array([255, 255, 100])      # Yellow\n","\n","    # Create mapping of cell IDs to classifications\n","    cell_classifications = dict(zip(\n","        classification_group['original_cell_id'],\n","        classification_group['cell_type']\n","    ))\n","\n","    # Get unique cell IDs\n","    cell_ids = np.unique(cell_mask)\n","    if 0 in cell_ids:  # Skip background (0)\n","        cell_ids = cell_ids[cell_ids > 0]\n","\n","    # Color each cell according to its classification\n","    for cell_id in cell_ids:\n","        if cell_id in cell_classifications:\n","            cell_type = cell_classifications[cell_id]\n","            if cell_type == 'Senescent':\n","                colored_mask[cell_mask == cell_id] = senescent_color\n","            else:\n","                colored_mask[cell_mask == cell_id] = non_senescent_color\n","\n","    # Overlay nuclei\n","    nuclei_ids = np.unique(nuclei_mask)\n","    if 0 in nuclei_ids:\n","        nuclei_ids = nuclei_ids[nuclei_ids > 0]\n","\n","    for nuc_id in nuclei_ids:\n","        colored_mask[nuclei_mask == nuc_id] = nuclei_color\n","\n","    return colored_mask\n","\n","def create_detailed_visualization(cell_mask, nuclei_mask, classification_group):\n","    \"\"\"\n","    Create a detailed visualization with cell boundaries and labels.\n","\n","    Parameters:\n","    -----------\n","    cell_mask : ndarray\n","        Labeled cell mask\n","    nuclei_mask : ndarray\n","        Labeled nuclei mask\n","    classification_group : DataFrame\n","        DataFrame containing classification results for this sample\n","\n","    Returns:\n","    --------\n","    detailed_vis : ndarray\n","        RGB image with boundaries, labels, and classification overlay\n","    \"\"\"\n","    # Create a blank RGB image\n","    h, w = cell_mask.shape\n","    detailed_vis = np.zeros((h, w, 3), dtype=np.uint8)\n","\n","    # Define colors\n","    senescent_color = np.array([220, 100, 100])    # Lighter red\n","    non_senescent_color = np.array([100, 100, 220]) # Lighter blue\n","    boundary_color = np.array([255, 255, 255])      # White\n","    nuclei_color = np.array([200, 200, 50])         # Lighter yellow\n","\n","    # Create mapping of cell IDs to classifications\n","    cell_classifications = dict(zip(\n","        classification_group['original_cell_id'],\n","        classification_group['cell_type']\n","    ))\n","\n","    # Get unique cell IDs\n","    cell_ids = np.unique(cell_mask)\n","    if 0 in cell_ids:  # Skip background (0)\n","        cell_ids = cell_ids[cell_ids > 0]\n","\n","    # Color each cell according to its classification\n","    for cell_id in cell_ids:\n","        if cell_id in cell_classifications:\n","            cell_type = cell_classifications[cell_id]\n","            # Fill cell\n","            if cell_type == 'Senescent':\n","                detailed_vis[cell_mask == cell_id] = senescent_color\n","            else:\n","                detailed_vis[cell_mask == cell_id] = non_senescent_color\n","\n","    # Find and highlight cell boundaries\n","    cell_boundaries = segmentation.find_boundaries(cell_mask, mode='outer')\n","    detailed_vis[cell_boundaries] = boundary_color\n","\n","    # Overlay nuclei\n","    nuclei_ids = np.unique(nuclei_mask)\n","    if 0 in nuclei_ids:\n","        nuclei_ids = nuclei_ids[nuclei_ids > 0]\n","\n","    for nuc_id in nuclei_ids:\n","        detailed_vis[nuclei_mask == nuc_id] = nuclei_color\n","\n","    return detailed_vis\n","\n","def create_summary_visualizations(results_df, output_dir):\n","    \"\"\"\n","    Create summary visualizations of the classification results.\n","\n","    Parameters:\n","    -----------\n","    results_df : DataFrame\n","        DataFrame containing all classification results\n","    output_dir : str\n","        Directory to save the visualization results\n","    \"\"\"\n","    # 1. Improved UMAP visualization\n","    plt.figure(figsize=(12, 10))\n","\n","    # Scatter plot with UMAP results colored by cell type\n","    plt.scatter(\n","        results_df['umap_x'],\n","        results_df['umap_y'],\n","        c=results_df['cell_type'].map({'Senescent': 'red', 'Non-senescent': 'blue'}),\n","        s=30,\n","        alpha=0.7,\n","        edgecolor='k',\n","        linewidth=0.5\n","    )\n","\n","    # Add contour lines to show density\n","    for cell_type, color in zip(['Senescent', 'Non-senescent'], ['red', 'blue']):\n","        subset = results_df[results_df['cell_type'] == cell_type]\n","        if len(subset) > 10:  # Need enough points for kernel density\n","            sns.kdeplot(\n","                x=subset['umap_x'],\n","                y=subset['umap_y'],\n","                levels=5,\n","                color=color,\n","                alpha=0.3,\n","                linewidths=1\n","            )\n","\n","    # Add legend\n","    plt.legend(\n","        handles=[\n","            mpatches.Patch(color='red', label='Senescent'),\n","            mpatches.Patch(color='blue', label='Non-senescent')\n","        ],\n","        title='Cell Type',\n","        loc='upper right'\n","    )\n","\n","    plt.title('UMAP Projection of Cells by Senescence Classification', fontsize=14)\n","    plt.xlabel('UMAP Dimension 1', fontsize=12)\n","    plt.ylabel('UMAP Dimension 2', fontsize=12)\n","    plt.grid(True, linestyle='--', alpha=0.7)\n","\n","    # Save the UMAP visualization\n","    plt.savefig(os.path.join(output_dir, 'enhanced_umap_clustering.png'), dpi=300, bbox_inches='tight')\n","    plt.close()\n","\n","    # 2. Feature importance visualization\n","    key_features = [\n","        'cell_area', 'nuclei_count', 'avg_nucleus_area',\n","        'cell_perimeter', 'cell_circularity', 'nucleus_to_cell_area_ratio',\n","        'cell_eccentricity', 'nucleus_displacement'\n","    ]\n","\n","    # Calculate feature differences between cell types\n","    feature_differences = {}\n","    for feature in key_features:\n","        if feature in results_df.columns:\n","            sen_mean = results_df[results_df['cell_type'] == 'Senescent'][feature].mean()\n","            non_sen_mean = results_df[results_df['cell_type'] == 'Non-senescent'][feature].mean()\n","\n","            # Calculate ratio or difference\n","            if non_sen_mean != 0:\n","                ratio = sen_mean / non_sen_mean\n","            else:\n","                ratio = float('inf') if sen_mean != 0 else 1.0\n","\n","            feature_differences[feature] = (feature, ratio, sen_mean, non_sen_mean)\n","\n","    # Sort by ratio (most discriminative first)\n","    sorted_features = sorted(\n","        feature_differences.values(),\n","        key=lambda x: abs(x[1] - 1.0),\n","        reverse=True\n","    )\n","\n","    # Create bar chart of feature importance\n","    fig, ax = plt.subplots(figsize=(12, 8))\n","\n","    features = [f[0].replace('_', ' ').title() for f in sorted_features]\n","    ratios = [f[1] for f in sorted_features]\n","\n","    # Transform ratios for better visualization\n","    log_ratios = []\n","    for r in ratios:\n","        if r > 1:\n","            log_ratios.append(r - 1)  # For values > 1, show how much greater than 1\n","        else:\n","            log_ratios.append(-(1/r - 1))  # For values < 1, show negative of how much less than 1\n","\n","    bars = ax.bar(\n","        features,\n","        log_ratios,\n","        color=[\n","            'red' if r > 0 else 'blue' for r in log_ratios\n","        ]\n","    )\n","\n","    # Add exact ratio values as text\n","    for i, bar in enumerate(bars):\n","        height = bar.get_height()\n","        if height >= 0:\n","            va = 'bottom'\n","            offset = 0.05\n","        else:\n","            va = 'top'\n","            offset = -0.1\n","        ax.text(\n","            bar.get_x() + bar.get_width()/2,\n","            height + offset,\n","            f'Ratio: {ratios[i]:.2f}',\n","            ha='center',\n","            va=va,\n","            rotation=45,\n","            fontsize=9\n","        )\n","\n","    plt.axhline(y=0, color='k', linestyle='-', alpha=0.3)\n","    plt.title('Feature Importance for Senescence Classification', fontsize=14)\n","    plt.ylabel('Log Ratio (Senescent / Non-senescent)', fontsize=12)\n","    plt.xticks(rotation=45, ha='right')\n","    plt.grid(axis='y', linestyle='--', alpha=0.7)\n","\n","    # Add legend\n","    plt.legend(\n","        handles=[\n","            mpatches.Patch(color='red', label='Higher in Senescent'),\n","            mpatches.Patch(color='blue', label='Higher in Non-senescent')\n","        ],\n","        loc='upper right'\n","    )\n","\n","    plt.tight_layout()\n","    plt.savefig(os.path.join(output_dir, 'feature_importance.png'), dpi=300)\n","    plt.close()\n","\n","    # 3. Create a multi-feature visualization\n","    plt.figure(figsize=(12, 10))\n","\n","    # Scatter plot with cell area vs nuclear area, colored by classification\n","    scatter = plt.scatter(\n","        results_df['cell_area'],\n","        results_df['avg_nucleus_area'],\n","        c=results_df['cell_type'].map({'Senescent': 'red', 'Non-senescent': 'blue'}),\n","        s=results_df['nuclei_count'] * 10,  # Size by nuclei count\n","        alpha=0.7,\n","        edgecolor='k',\n","        linewidth=0.5\n","    )\n","\n","    # Add contour lines to show density\n","    for cell_type, color in zip(['Senescent', 'Non-senescent'], ['red', 'blue']):\n","        subset = results_df[results_df['cell_type'] == cell_type]\n","        if len(subset) > 10:  # Need enough points for kernel density\n","            sns.kdeplot(\n","                x=subset['cell_area'],\n","                y=subset['avg_nucleus_area'],\n","                levels=3,\n","                color=color,\n","                alpha=0.3,\n","                linewidths=1\n","            )\n","\n","    # Create custom legend\n","    handles = [\n","        mpatches.Patch(color='red', label='Senescent'),\n","        mpatches.Patch(color='blue', label='Non-senescent'),\n","        plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='gray',\n","                  markersize=5, label='1 Nucleus'),\n","        plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='gray',\n","                  markersize=10, label='2 Nuclei'),\n","        plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='gray',\n","                  markersize=15, label='3 Nuclei')\n","    ]\n","    plt.legend(handles=handles, loc='upper left')\n","\n","    plt.title('Cell Area vs Nuclear Area with Nuclei Count', fontsize=14)\n","    plt.xlabel('Cell Area', fontsize=12)\n","    plt.ylabel('Average Nucleus Area', fontsize=12)\n","    plt.grid(True, linestyle='--', alpha=0.7)\n","\n","    plt.savefig(os.path.join(output_dir, 'multi_feature_visualization.png'), dpi=300, bbox_inches='tight')\n","    plt.close()\n","\n","    # 4. Boxplot visualization with statistical significance\n","    plt.figure(figsize=(15, 10))\n","\n","    # Select up to 6 most discriminative features\n","    top_features = sorted_features[:6]\n","\n","    # Create subplot grid\n","    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n","    axes = axes.flatten()\n","\n","    for i, (feature, ratio, sen_mean, non_sen_mean) in enumerate(top_features):\n","        if i < 6:  # Limit to 6 features\n","            ax = axes[i]\n","\n","            # Create violin plot with individual points\n","            sns.violinplot(\n","                x='cell_type',\n","                y=feature,\n","                data=results_df,\n","                palette={'Senescent': 'red', 'Non-senescent': 'blue'},\n","                ax=ax,\n","                inner='quartile',\n","                alpha=0.7\n","            )\n","\n","            # Add individual points\n","            sns.stripplot(\n","                x='cell_type',\n","                y=feature,\n","                data=results_df,\n","                color='black',\n","                size=2,\n","                alpha=0.3,\n","                ax=ax,\n","                jitter=True\n","            )\n","\n","            # Set title and labels\n","            ax.set_title(feature.replace('_', ' ').title(), fontsize=12)\n","            ax.set_xlabel('')\n","\n","            # Add ratio text\n","            ax.text(\n","                0.5, 0.95,\n","                f'Ratio: {ratio:.2f}',\n","                transform=ax.transAxes,\n","                ha='center',\n","                va='top',\n","                bbox=dict(facecolor='white', alpha=0.8, boxstyle='round,pad=0.5')\n","            )\n","\n","    plt.tight_layout()\n","    plt.savefig(os.path.join(output_dir, 'feature_distribution_comparison.png'), dpi=300)\n","    plt.close()\n","\n","def integrate_with_existing_code(main_func, cell_dir, nuclei_dir, results_csv, output_dir):\n","    \"\"\"\n","    This function shows how to integrate the new visualization code with the existing code.\n","\n","    Parameters:\n","    -----------\n","    main_func : function\n","        The main function from the original code\n","    cell_dir : str\n","        Directory containing cell mask files\n","    nuclei_dir : str\n","        Directory containing nuclei mask files\n","    results_csv : str\n","        Path to the cell_classification_results.csv file\n","    output_dir : str\n","        Directory to save visualization results\n","    \"\"\"\n","    # First run the main analysis if results don't exist yet\n","    if not os.path.exists(results_csv):\n","        print(\"Running senescent cell classification analysis...\")\n","        main_func(cell_dir, nuclei_dir, os.path.dirname(results_csv))\n","\n","    # Then run the visualization\n","    print(\"\\nCreating enhanced visualizations...\")\n","    visualize_classification_on_masks(cell_dir, nuclei_dir, results_csv, output_dir)\n","\n","if __name__ == \"__main__\":\n","    # Example usage\n","    cell_mask_dir = \"/content/drive/MyDrive/knowledge/University/Master/Thesis/Segmented/flow3-x20/Cell_merged_conservative\"\n","    nuclei_dir = \"/content/drive/MyDrive/knowledge/University/Master/Thesis/Segmented/flow3-x20/Nuclei\"\n","    results_csv = \"/content/drive/MyDrive/knowledge/University/Master/Thesis/Analysis/flow3-x20/Senescence/cell_classification_results.csv\"\n","    visualization_dir = \"/content/drive/MyDrive/knowledge/University/Master/Thesis/Analysis/flow3-x20/Senescence/visualization\"\n","\n","    # If you want to run just the visualization:\n","    visualize_classification_on_masks(cell_mask_dir, nuclei_dir, results_csv, visualization_dir)\n","\n","    # If you want to integrate with the original code:\n","    # from original_code import main\n","    # integrate_with_existing_code(main, cell_mask_dir, nuclei_dir, results_csv, visualization_dir)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4AXUuUBKkJJr","executionInfo":{"status":"ok","timestamp":1746945167505,"user_tz":-120,"elapsed":53172,"user":{"displayName":"Guido Putignano","userId":"13974663347531370398"}},"outputId":"d45eca8e-199d-40d7-8d32-ffd93ee51b41"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["=== Visualization of Senescent Cell Classification ===\n","Loaded 2472 classified cells\n"]},{"output_type":"stream","name":"stderr","text":["Visualizing samples: 100%|██████████| 8/8 [00:40<00:00,  5.07s/it]\n","<ipython-input-5-67182bb7d836>:449: FutureWarning: \n","\n","Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n","\n","  sns.violinplot(\n","<ipython-input-5-67182bb7d836>:449: FutureWarning: \n","\n","Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n","\n","  sns.violinplot(\n","<ipython-input-5-67182bb7d836>:449: FutureWarning: \n","\n","Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n","\n","  sns.violinplot(\n","<ipython-input-5-67182bb7d836>:449: FutureWarning: \n","\n","Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n","\n","  sns.violinplot(\n","<ipython-input-5-67182bb7d836>:449: FutureWarning: \n","\n","Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n","\n","  sns.violinplot(\n","<ipython-input-5-67182bb7d836>:449: FutureWarning: \n","\n","Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n","\n","  sns.violinplot(\n"]},{"output_type":"stream","name":"stdout","text":["\n","Visualization complete! Results saved to /content/drive/MyDrive/knowledge/University/Master/Thesis/Analysis/flow3-x20/Senescence/visualization/\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 1500x1000 with 0 Axes>"]},"metadata":{}}]},{"cell_type":"code","source":["import os\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as mpatches\n","import seaborn as sns\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.cluster import KMeans\n","import umap\n","from tqdm import tqdm\n","\n","# --- Configuration & Parameters ---\n","INPUT_CSV_PATH = \"/content/drive/MyDrive/knowledge/University/Master/Thesis/Analysis/flow3-x20/Senescence/cell_classification_results.csv\" # Path to your existing results\n","OUTPUT_DIR = \"/content/drive/MyDrive/knowledge/University/Master/Thesis/Analysis/flow3-x20/Senescence_Refined_V3\" # New directory for refined results\n","# User updated this threshold\n","MULTINUCLEATION_THRESHOLD = 1 # Cells with nuclei_count > this threshold will be marked senescent\n","\n","# Quantile for preliminary senescence classification based on the normalized score.\n","PRELIMINARY_SENESCENCE_QUANTILE = 0.90 # Target ~15% initially senescent by score (before multinucleation rule)\n","\n","FEATURES_FOR_CLUSTERING = [\n","    'cell_area',\n","    'cell_perimeter',\n","    'cell_eccentricity',\n","    'cell_circularity',\n","    'cell_aspect_ratio',\n","    'avg_nucleus_area',\n","    'max_nucleus_area',\n","    'avg_nucleus_eccentricity',\n","    'nucleus_area_std',\n","    'nucleus_displacement',\n","    'nucleus_to_cell_area_ratio'\n","]\n","\n","SENESCENCE_SCORE_WEIGHTS = {\n","    'cell_area': 1.5,\n","    'cell_perimeter': 0.5,\n","    'cell_eccentricity': 0.5,\n","    'cell_circularity': -1.0,\n","    'cell_aspect_ratio': 0.5,\n","    'avg_nucleus_area': 1.0,\n","    'avg_nucleus_eccentricity': 0.3,\n","    'nucleus_to_cell_area_ratio': -1.5,\n","    'nuclear_enlargement': 1.0,\n","    'cell_enlargement': 1.5,\n","    'nucleus_displacement': 0.2,\n","}\n","\n","AREA_FEATURES_TO_LOG = ['cell_area', 'avg_nucleus_area', 'max_nucleus_area', 'cell_perimeter']\n","\n","\n","def load_and_prepare_data(csv_path):\n","    \"\"\"Loads the data and checks for required columns.\"\"\"\n","    print(f\"Loading data from {csv_path}...\")\n","    try:\n","        df = pd.read_csv(csv_path)\n","        print(f\"Successfully loaded {len(df)} cells.\")\n","    except FileNotFoundError:\n","        print(f\"Error: CSV file not found at {csv_path}\")\n","        return None\n","\n","    essential_cols_for_operation = list(SENESCENCE_SCORE_WEIGHTS.keys()) + ['nuclei_count', 'cell_id', 'sample_id']\n","    all_needed_cols = list(set(FEATURES_FOR_CLUSTERING + essential_cols_for_operation))\n","\n","    missing_cols = [col for col in all_needed_cols if col not in df.columns]\n","    if missing_cols:\n","        missing_scoring_or_rules_cols = [col for col in essential_cols_for_operation if col not in df.columns]\n","        if missing_scoring_or_rules_cols:\n","            print(f\"Error: Critical columns for scoring/rules are missing: {missing_scoring_or_rules_cols}\")\n","            return None\n","        print(f\"Warning: Some columns listed in FEATURES_FOR_CLUSTERING are missing: {missing_cols}. UMAP/KMeans might be affected if these are used.\")\n","\n","    return df\n","\n","def calculate_senescence_score(df, score_weights):\n","    \"\"\"Calculates a per-cell senescence score.\"\"\"\n","    print(\"Calculating per-cell senescence score...\")\n","\n","    features_for_scoring_present = [f for f in score_weights.keys() if f in df.columns]\n","    if not features_for_scoring_present:\n","        print(\"Error: No features for senescence score calculation are present in the DataFrame.\")\n","        df['senescence_score'] = np.nan\n","        df['senescence_score_normalized'] = np.nan\n","        return df\n","\n","    score_df = df[features_for_scoring_present].copy()\n","\n","    for col in AREA_FEATURES_TO_LOG:\n","        if col in score_df.columns:\n","            score_df[col] = np.log1p(score_df[col])\n","            print(f\"  Log-transformed scoring feature: {col}\")\n","\n","    scaler = StandardScaler()\n","    numeric_score_cols = score_df.select_dtypes(include=np.number).columns\n","    if not numeric_score_cols.empty:\n","        score_features_standardized = scaler.fit_transform(score_df[numeric_score_cols])\n","        score_features_standardized_df = pd.DataFrame(score_features_standardized, columns=numeric_score_cols, index=score_df.index)\n","    else:\n","        print(\"  Warning: No numeric columns found for standardization in scoring features.\")\n","        score_features_standardized_df = pd.DataFrame(index=score_df.index)\n","\n","    df['senescence_score'] = 0.0\n","    for feature, weight in score_weights.items():\n","        if feature in score_features_standardized_df.columns:\n","            df['senescence_score'] += score_features_standardized_df[feature] * weight\n","        elif feature in df.columns:\n","            print(f\"  Warning: Scoring feature '{feature}' was not in standardized set, using original value (ensure this is intended).\")\n","        else:\n","             print(f\"  Warning: Feature '{feature}' for scoring not found. Skipping.\")\n","\n","    if df['senescence_score'].isna().all() or (df['senescence_score'].max() == df['senescence_score'].min()):\n","        print(\"  Warning: Senescence scores are all NaN or uniform. Normalization will result in NaN or 0.\")\n","        df['senescence_score_normalized'] = np.nan if df['senescence_score'].isna().all() else 0.0\n","    else:\n","        df['senescence_score_normalized'] = (df['senescence_score'] - df['senescence_score'].min()) / \\\n","                                           (df['senescence_score'].max() - df['senescence_score'].min())\n","    print(\"Senescence score calculation complete.\")\n","    return df\n","\n","def perform_refined_clustering(df, feature_columns_for_clustering, umap_n_neighbors=30, umap_min_dist=0.1, umap_random_state=42, kmeans_n_clusters=2, kmeans_random_state=42):\n","    \"\"\"\n","    Performs UMAP and k-Means clustering on selected features.\n","    \"\"\"\n","    print(f\"\\nPerforming refined clustering using features: {feature_columns_for_clustering}...\")\n","\n","    actual_clustering_features = [col for col in feature_columns_for_clustering if col in df.columns]\n","    if not actual_clustering_features:\n","        print(\"Error: None of the specified FEATURES_FOR_CLUSTERING are present in the DataFrame. Skipping UMAP/KMeans.\")\n","        df['umap_x_refined'] = np.nan\n","        df['umap_y_refined'] = np.nan\n","        df['cluster_refined'] = np.nan\n","        return df\n","\n","    features_for_clustering_df = df[actual_clustering_features].copy()\n","\n","    for col in actual_clustering_features:\n","        if not pd.api.types.is_numeric_dtype(features_for_clustering_df[col]):\n","            try:\n","                features_for_clustering_df[col] = pd.to_numeric(features_for_clustering_df[col])\n","                print(f\"  Column {col} converted to numeric for clustering.\")\n","            except ValueError:\n","                print(f\"  Warning: Column {col} for clustering is not numeric and could not be converted. It will be excluded.\")\n","                features_for_clustering_df = features_for_clustering_df.drop(columns=[col])\n","                actual_clustering_features.remove(col)\n","\n","    features_for_clustering_df = features_for_clustering_df.fillna(features_for_clustering_df.mean())\n","\n","    if features_for_clustering_df.empty or features_for_clustering_df.shape[1] == 0:\n","        print(\"Error: No valid numeric features available for clustering after processing. Skipping UMAP/KMeans.\")\n","        df['umap_x_refined'] = np.nan\n","        df['umap_y_refined'] = np.nan\n","        df['cluster_refined'] = np.nan\n","        return df\n","\n","    print(\"\\nApplying log transformation to selected area/perimeter features for clustering...\")\n","    for col in AREA_FEATURES_TO_LOG:\n","        if col in features_for_clustering_df.columns:\n","            features_for_clustering_df[col] = np.log1p(features_for_clustering_df[col])\n","            print(f\"  Log-transformed clustering feature: {col}\")\n","\n","    print(\"\\nStandardizing features for clustering...\")\n","    scaler = StandardScaler()\n","    features_standardized = scaler.fit_transform(features_for_clustering_df)\n","\n","    print(\"\\nPerforming UMAP reduction...\")\n","    actual_umap_n_neighbors = min(umap_n_neighbors, len(features_standardized) - 1)\n","    if actual_umap_n_neighbors < 2 :\n","        print(f\"  Warning: Not enough samples ({len(features_standardized)}) for UMAP with n_neighbors={umap_n_neighbors}. Skipping UMAP and KMeans.\")\n","        df['umap_x_refined'] = np.nan\n","        df['umap_y_refined'] = np.nan\n","        df['cluster_refined'] = np.nan\n","        return df\n","\n","    print(f\"  Using UMAP n_neighbors: {actual_umap_n_neighbors}\")\n","    reducer = umap.UMAP(n_neighbors=actual_umap_n_neighbors, min_dist=umap_min_dist, random_state=umap_random_state, n_components=2)\n","    embedding = reducer.fit_transform(features_standardized)\n","    df['umap_x_refined'] = embedding[:, 0]\n","    df['umap_y_refined'] = embedding[:, 1]\n","\n","    print(f\"\\nPerforming k-Means clustering (k={kmeans_n_clusters})...\")\n","    if len(embedding) >= kmeans_n_clusters:\n","        kmeans = KMeans(n_clusters=kmeans_n_clusters, random_state=kmeans_random_state, n_init='auto')\n","        df['cluster_refined'] = kmeans.fit_predict(embedding)\n","    else:\n","        print(f\"  Warning: Not enough samples ({len(embedding)}) for KMeans with n_clusters={kmeans_n_clusters}. Skipping KMeans.\")\n","        df['cluster_refined'] = np.nan\n","\n","    print(\"Refined clustering complete.\")\n","    return df\n","\n","def classify_cells(df, preliminary_quantile, multinucleation_threshold):\n","    \"\"\"Assigns preliminary and final cell types based on senescence score and multinucleation.\"\"\"\n","    print(\"\\nClassifying cells...\")\n","\n","    if 'senescence_score_normalized' not in df.columns or df['senescence_score_normalized'].isna().all():\n","        print(\"  Error: 'senescence_score_normalized' is missing or all NaN. Cannot perform preliminary classification.\")\n","        df['cell_type_preliminary'] = 'Unknown'\n","        prelim_sen_count_by_score = 0\n","    else:\n","        score_threshold = df['senescence_score_normalized'].quantile(preliminary_quantile)\n","        print(f\"  Using senescence score quantile {preliminary_quantile} (threshold = {score_threshold:.4f}) for preliminary classification.\")\n","        df['cell_type_preliminary'] = df['senescence_score_normalized'].apply(\n","            lambda x: 'Senescent' if x >= score_threshold else 'Non-senescent'\n","        )\n","        prelim_sen_count_by_score = (df['cell_type_preliminary'] == 'Senescent').sum()\n","        print(f\"  {prelim_sen_count_by_score} cells ({prelim_sen_count_by_score/len(df)*100:.2f}%) preliminarily classified as Senescent by score.\")\n","\n","    # --- Detailed breakdown for multinucleation ---\n","    df['cell_type_final'] = df['cell_type_preliminary'] # Start final classification from preliminary\n","\n","    if 'nuclei_count' in df.columns:\n","        multinucleated_mask = df['nuclei_count'] > multinucleation_threshold\n","        total_multinucleated = multinucleated_mask.sum()\n","\n","        print(f\"\\n--- Multinucleation Rule (nuclei_count > {multinucleation_threshold}) ---\")\n","        print(f\"  Total cells considered polynucleated: {total_multinucleated} ({total_multinucleated/len(df)*100:.2f}%)\")\n","\n","        if total_multinucleated > 0:\n","            # Cells that are polynucleated AND were already called Senescent by score\n","            multinucleated_and_sen_by_score = (multinucleated_mask & (df['cell_type_preliminary'] == 'Senescent')).sum()\n","            print(f\"    Of these {total_multinucleated} polynucleated cells:\")\n","            print(f\"      - {multinucleated_and_sen_by_score} were ALREADY 'Senescent' by score.\")\n","\n","            # Cells that are polynucleated AND were Non-senescent by score (these will be reclassified)\n","            multinucleated_reclassified_to_senescent = (multinucleated_mask & (df['cell_type_preliminary'] == 'Non-senescent')).sum()\n","            print(f\"      - {multinucleated_reclassified_to_senescent} were 'Non-senescent' by score and are NOW RECLASSIFIED to 'Senescent'.\")\n","\n","        # Apply the rule: all multinucleated cells are finally 'Senescent'\n","        df.loc[multinucleated_mask, 'cell_type_final'] = 'Senescent'\n","    else:\n","        print(\"  Warning: 'nuclei_count' column not found. Cannot apply multinucleation rule.\")\n","\n","    final_sen_count = (df['cell_type_final'] == 'Senescent').sum()\n","    print(f\"\\nTotal cells finally classified as Senescent: {final_sen_count} ({final_sen_count/len(df)*100:.2f}%)\")\n","    print(\"Cell classification complete.\")\n","    return df\n","\n","def visualize_refined_results(df, output_dir):\n","    \"\"\"Generates and saves visualizations for the refined analysis.\"\"\"\n","    print(\"\\nGenerating visualizations for refined results...\")\n","    if not os.path.exists(output_dir):\n","        os.makedirs(output_dir)\n","\n","    # 1. UMAP colored by Senescence Score (Continuous)\n","    if 'umap_x_refined' in df.columns and 'umap_y_refined' in df.columns and df['umap_x_refined'].notna().any() and 'senescence_score_normalized' in df.columns and df['senescence_score_normalized'].notna().any():\n","        plt.figure(figsize=(12, 10))\n","        scatter = plt.scatter(\n","            df['umap_x_refined'], df['umap_y_refined'],\n","            c=df['senescence_score_normalized'],\n","            cmap='viridis', s=15, alpha=0.7\n","        )\n","        plt.colorbar(scatter, label='Normalized Senescence Score')\n","        plt.title('Refined UMAP: Cells Colored by Senescence Score', fontsize=16)\n","        plt.xlabel('UMAP Dimension 1 (Refined)', fontsize=12)\n","        plt.ylabel('UMAP Dimension 2 (Refined)', fontsize=12)\n","        plt.grid(True, linestyle='--', alpha=0.5)\n","        plt.savefig(os.path.join(output_dir, 'umap_refined_by_senescence_score.png'), dpi=300, bbox_inches='tight')\n","        plt.close()\n","    else:\n","        print(\"  Skipping UMAP by senescence score plot (UMAP data or score data missing/all NaN).\")\n","\n","    # 2. UMAP colored by Final Cell Type (Binary/Categorical)\n","    if 'umap_x_refined' in df.columns and 'umap_y_refined' in df.columns and df['umap_x_refined'].notna().any() and 'cell_type_final' in df.columns:\n","        plt.figure(figsize=(12, 10))\n","        unique_cell_types = df['cell_type_final'].unique()\n","        palette = {ctype: ('red' if ctype == 'Senescent' else ('blue' if ctype == 'Non-senescent' else 'grey')) for ctype in unique_cell_types}\n","\n","        for cell_type, color in palette.items():\n","            subset = df[df['cell_type_final'] == cell_type]\n","            if not subset.empty:\n","                 plt.scatter(subset['umap_x_refined'], subset['umap_y_refined'], label=cell_type, color=color, s=15, alpha=0.7)\n","\n","        plt.title('Refined UMAP: Cells Colored by Final Classification', fontsize=16)\n","        plt.xlabel('UMAP Dimension 1 (Refined)', fontsize=12)\n","        plt.ylabel('UMAP Dimension 2 (Refined)', fontsize=12)\n","        if palette:\n","            plt.legend(title='Final Cell Type')\n","        plt.grid(True, linestyle='--', alpha=0.5)\n","        plt.savefig(os.path.join(output_dir, 'umap_refined_by_final_cell_type.png'), dpi=300, bbox_inches='tight')\n","        plt.close()\n","    else:\n","        print(\"  Skipping UMAP by final cell type plot (UMAP or classification data missing).\")\n","\n","    # 3. Distribution of Senescence Score\n","    if 'senescence_score_normalized' in df.columns and df['senescence_score_normalized'].notna().any():\n","        plt.figure(figsize=(10, 6))\n","        sns.histplot(df['senescence_score_normalized'].dropna(), kde=True, bins=50)\n","        plt.title('Distribution of Normalized Senescence Score', fontsize=16)\n","        plt.xlabel('Normalized Senescence Score', fontsize=12)\n","        plt.ylabel('Frequency', fontsize=12)\n","        if 'cell_type_preliminary' in df.columns:\n","            score_threshold_val = df['senescence_score_normalized'].quantile(PRELIMINARY_SENESCENCE_QUANTILE)\n","            plt.axvline(score_threshold_val, color='r', linestyle='--', label=f'Quantile Threshold ({PRELIMINARY_SENESCENCE_QUANTILE*100:.0f}th percentile)')\n","            plt.legend()\n","        plt.grid(True, linestyle='--', alpha=0.5)\n","        plt.savefig(os.path.join(output_dir, 'senescence_score_distribution.png'), dpi=300, bbox_inches='tight')\n","        plt.close()\n","    else:\n","        print(\"  Skipping senescence score distribution plot (score data missing or all NaN).\")\n","\n","    # 4. Key Feature Comparison for Final Cell Types\n","    if 'cell_type_final' in df.columns and df['cell_type_final'].nunique() > 1:\n","        key_comparison_features = [\n","            'cell_area', 'avg_nucleus_area', 'cell_circularity',\n","            'nucleus_to_cell_area_ratio', 'senescence_score_normalized', 'nuclei_count'\n","        ]\n","        key_comparison_features = [f for f in key_comparison_features if f in df.columns and df[f].notna().any()]\n","\n","        if key_comparison_features:\n","            num_features_to_plot = len(key_comparison_features)\n","            if num_features_to_plot > 0:\n","                cols_subplot = 3\n","                rows_subplot = (num_features_to_plot + cols_subplot - 1) // cols_subplot\n","                fig, axes = plt.subplots(rows_subplot, cols_subplot, figsize=(5 * cols_subplot, 5 * rows_subplot), squeeze=False)\n","                axes = axes.flatten()\n","\n","                current_palette = palette if 'palette' in locals() else 'coolwarm'\n","                order = sorted(df['cell_type_final'].unique())\n","\n","\n","                for i, feature in enumerate(key_comparison_features):\n","                    sns.boxplot(x='cell_type_final', y=feature, data=df, ax=axes[i], palette=current_palette, order=order)\n","                    axes[i].set_title(feature.replace('_', ' ').title(), fontsize=14)\n","                    axes[i].set_xlabel('Final Cell Type', fontsize=10)\n","                    axes[i].set_ylabel(feature.replace('_', ' ').title(), fontsize=10)\n","\n","                for j in range(i + 1, len(axes)):\n","                    fig.delaxes(axes[j])\n","\n","                plt.tight_layout()\n","                plt.savefig(os.path.join(output_dir, 'feature_comparison_by_final_type.png'), dpi=300, bbox_inches='tight')\n","                plt.close()\n","        else:\n","            print(\"  Skipping feature comparison plot (no key features with valid data found).\")\n","    else:\n","        print(\"  Skipping feature comparison plot (final cell type data insufficient).\")\n","\n","    print(\"Visualizations saved.\")\n","\n","def main_refined_analysis():\n","    \"\"\"Main function to run the refined senescence analysis.\"\"\"\n","\n","    if not os.path.exists(OUTPUT_DIR):\n","        os.makedirs(OUTPUT_DIR)\n","        print(f\"Created output directory: {OUTPUT_DIR}\")\n","\n","    df = load_and_prepare_data(INPUT_CSV_PATH)\n","    if df is None:\n","        return\n","\n","    df = calculate_senescence_score(df, SENESCENCE_SCORE_WEIGHTS)\n","    df = perform_refined_clustering(df, FEATURES_FOR_CLUSTERING)\n","\n","    # Call classify_cells with the globally defined MULTINUCLEATION_THRESHOLD\n","    df = classify_cells(df, PRELIMINARY_SENESCENCE_QUANTILE, MULTINUCLEATION_THRESHOLD)\n","\n","    output_csv_path = os.path.join(OUTPUT_DIR, 'cell_classification_results_refined.csv')\n","    cols_to_save = [col for col in df.columns if col not in ['umap_x', 'umap_y', 'cluster', 'cell_type']]\n","\n","    if 'umap_x_refined' in df.columns and df['umap_x_refined'].isna().all():\n","        cols_to_save = [col for col in cols_to_save if col not in ['umap_x_refined', 'umap_y_refined']]\n","    if 'cluster_refined' in df.columns and df['cluster_refined'].isna().all():\n","        cols_to_save = [col for col in cols_to_save if col not in ['cluster_refined']]\n","\n","    df_to_save = df[cols_to_save]\n","    df_to_save.to_csv(output_csv_path, index=False)\n","    print(f\"\\nRefined results saved to: {output_csv_path}\")\n","\n","    visualize_refined_results(df, OUTPUT_DIR)\n","\n","    print(\"\\nRefined analysis complete!\")\n","\n","if __name__ == '__main__':\n","    main_refined_analysis()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ir6P7dNvZaAq","executionInfo":{"status":"ok","timestamp":1747203403171,"user_tz":-120,"elapsed":26157,"user":{"displayName":"Guido Putignano","userId":"13974663347531370398"}},"outputId":"701d58e0-f5ac-42f2-fbd7-ec4c3deacb4f"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading data from /content/drive/MyDrive/knowledge/University/Master/Thesis/Analysis/flow3-x20/Senescence/cell_classification_results.csv...\n","Successfully loaded 2472 cells.\n","Calculating per-cell senescence score...\n","  Log-transformed scoring feature: cell_area\n","  Log-transformed scoring feature: avg_nucleus_area\n","  Log-transformed scoring feature: cell_perimeter\n","Senescence score calculation complete.\n","\n","Performing refined clustering using features: ['cell_area', 'cell_perimeter', 'cell_eccentricity', 'cell_circularity', 'cell_aspect_ratio', 'avg_nucleus_area', 'max_nucleus_area', 'avg_nucleus_eccentricity', 'nucleus_area_std', 'nucleus_displacement', 'nucleus_to_cell_area_ratio']...\n","\n","Applying log transformation to selected area/perimeter features for clustering...\n","  Log-transformed clustering feature: cell_area\n","  Log-transformed clustering feature: avg_nucleus_area\n","  Log-transformed clustering feature: max_nucleus_area\n","  Log-transformed clustering feature: cell_perimeter\n","\n","Standardizing features for clustering...\n","\n","Performing UMAP reduction...\n","  Using UMAP n_neighbors: 30\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n","  warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","Performing k-Means clustering (k=2)...\n","Refined clustering complete.\n","\n","Classifying cells...\n","  Using senescence score quantile 0.9 (threshold = 0.5531) for preliminary classification.\n","  248 cells (10.03%) preliminarily classified as Senescent by score.\n","\n","--- Multinucleation Rule (nuclei_count > 1) ---\n","  Total cells considered polynucleated: 225 (9.10%)\n","    Of these 225 polynucleated cells:\n","      - 42 were ALREADY 'Senescent' by score.\n","      - 183 were 'Non-senescent' by score and are NOW RECLASSIFIED to 'Senescent'.\n","\n","Total cells finally classified as Senescent: 431 (17.44%)\n","Cell classification complete.\n","\n","Refined results saved to: /content/drive/MyDrive/knowledge/University/Master/Thesis/Analysis/flow3-x20/Senescence_Refined_V3/cell_classification_results_refined.csv\n","\n","Generating visualizations for refined results...\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-7-72c63bf85243>:322: FutureWarning: \n","\n","Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n","\n","  sns.boxplot(x='cell_type_final', y=feature, data=df, ax=axes[i], palette=current_palette, order=order)\n","<ipython-input-7-72c63bf85243>:322: FutureWarning: \n","\n","Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n","\n","  sns.boxplot(x='cell_type_final', y=feature, data=df, ax=axes[i], palette=current_palette, order=order)\n","<ipython-input-7-72c63bf85243>:322: FutureWarning: \n","\n","Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n","\n","  sns.boxplot(x='cell_type_final', y=feature, data=df, ax=axes[i], palette=current_palette, order=order)\n","<ipython-input-7-72c63bf85243>:322: FutureWarning: \n","\n","Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n","\n","  sns.boxplot(x='cell_type_final', y=feature, data=df, ax=axes[i], palette=current_palette, order=order)\n","<ipython-input-7-72c63bf85243>:322: FutureWarning: \n","\n","Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n","\n","  sns.boxplot(x='cell_type_final', y=feature, data=df, ax=axes[i], palette=current_palette, order=order)\n","<ipython-input-7-72c63bf85243>:322: FutureWarning: \n","\n","Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n","\n","  sns.boxplot(x='cell_type_final', y=feature, data=df, ax=axes[i], palette=current_palette, order=order)\n"]},{"output_type":"stream","name":"stdout","text":["Visualizations saved.\n","\n","Refined analysis complete!\n"]}]},{"cell_type":"code","source":["import os\n","import re # Added for extract_sample_id\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as mpatches # Added for legends in mask visualization\n","import seaborn as sns\n","from skimage import io, measure, segmentation # Added segmentation for find_boundaries\n","import cv2 # Added for cvtColor if needed by load_image_as_labeled_mask\n","from scipy import ndimage # Added for ndimage.label\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.cluster import KMeans\n","import umap\n","from tqdm import tqdm\n","\n","# --- Configuration & Parameters ---\n","INPUT_CSV_PATH = \"/content/drive/MyDrive/knowledge/University/Master/Thesis/Analysis/flow3-x20/Senescence/cell_classification_results.csv\"\n","OUTPUT_DIR = \"/content/drive/MyDrive/knowledge/University/Master/Thesis/Analysis/flow3-x20/Senescence_Refined_V4\" # New version for this run\n","\n","# Directories for original mask images - UPDATE THESE PATHS\n","CELL_MASK_DIR = \"/content/drive/MyDrive/knowledge/University/Master/Thesis/Segmented/flow3-x20/Cell_merged_conservative\"\n","NUCLEI_MASK_DIR = \"/content/drive/MyDrive/knowledge/University/Master/Thesis/Segmented/flow3-x20/Nuclei\"\n","MASK_VISUALIZATION_SUBDIR = \"mask_overlays\" # Subdirectory for saving mask visualizations\n","\n","MULTINUCLEATION_THRESHOLD = 1\n","PRELIMINARY_SENESCENCE_QUANTILE = 0.85\n","\n","FEATURES_FOR_CLUSTERING = [\n","    'cell_area', 'cell_perimeter', 'cell_eccentricity', 'cell_circularity',\n","    'cell_aspect_ratio', 'avg_nucleus_area', 'max_nucleus_area',\n","    'avg_nucleus_eccentricity', 'nucleus_area_std', 'nucleus_displacement',\n","    'nucleus_to_cell_area_ratio'\n","]\n","\n","SENESCENCE_SCORE_WEIGHTS = {\n","    'cell_area': 1.5, 'cell_perimeter': 0.5, 'cell_eccentricity': 0.5,\n","    'cell_circularity': -1.0, 'cell_aspect_ratio': 0.5, 'avg_nucleus_area': 1.0,\n","    'avg_nucleus_eccentricity': 0.3, 'nucleus_to_cell_area_ratio': -1.0,\n","    'nuclear_enlargement': 1.0, 'cell_enlargement': 1.5, 'nucleus_displacement': 0.2,\n","}\n","\n","AREA_FEATURES_TO_LOG = ['cell_area', 'avg_nucleus_area', 'max_nucleus_area', 'cell_perimeter']\n","\n","# --- Helper Functions ---\n","def extract_sample_id(filename):\n","    \"\"\"\n","    Extract the sample ID from a filename based on the specific naming pattern.\n","    (Adapted from user's original notebook)\n","    \"\"\"\n","    base_name = os.path.splitext(filename)[0]\n","    if base_name.startswith('denoised_'):\n","        base_name = base_name[len('denoised_'):]\n","    # Regex to capture the part up to seqXXX\n","    pattern = re.compile(r'([\\d\\.]+Pa_[^_]+_[^_]+_[^_]+_[^_]+_[^_]+_seq\\d+)')\n","    match = pattern.search(base_name)\n","    if match:\n","        return match.group(1)\n","    # Fallback if regex doesn't match (simplified)\n","    parts = base_name.split('_')\n","    for i, part in enumerate(parts):\n","        if part.startswith('seq') and i >= 2:\n","            return '_'.join(parts[:i+1]) # Join parts up to and including seqXXX\n","    # More general fallback\n","    common_prefix = \"_\".join(filename.split('_')[:6]) # Adjust if needed\n","    return common_prefix if 'seq' in common_prefix else os.path.splitext(os.path.basename(filename))[0]\n","\n","\n","def load_image_as_labeled_mask(filepath):\n","    \"\"\"Loads a mask image, ensuring it's a labeled integer mask.\"\"\"\n","    print(f\"    Loading mask: {os.path.basename(filepath)}\")\n","    try:\n","        img = io.imread(filepath)\n","        # Handle multi-channel images by converting to grayscale\n","        if img.ndim > 2:\n","            if img.shape[-1] == 3:  # RGB\n","                img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n","            elif img.shape[-1] == 4:  # RGBA\n","                img = cv2.cvtColor(img, cv2.COLOR_RGBA2GRAY)\n","            else: # Take first channel if not RGB/RGBA\n","                img = img[..., 0]\n","\n","        # If the image is already a labeled mask (e.g., integer types with max > 1)\n","        if img.dtype.kind in 'iu' and np.max(img) > 1: # integer unsigned/signed\n","            print(f\"    Mask {os.path.basename(filepath)} appears to be already labeled.\")\n","            return img.astype(np.uint16) # Ensure consistent type for labels\n","\n","        # If it's binary or float, threshold and label\n","        if img.dtype.kind == 'f': # float\n","            img = (img > 0.5).astype(np.uint8) # Threshold for float images\n","        elif np.max(img) == 1: # Binary\n","             img = img.astype(np.uint8)\n","\n","        if np.max(img) <=1 : # If binary after potential conversion\n","            labeled_img, num_features = ndimage.label(img)\n","            print(f\"    Labeled binary mask {os.path.basename(filepath)}, found {num_features} features.\")\n","            return labeled_img.astype(np.uint16)\n","\n","        # If it was uint8 with labels (e.g. from CellProfiler)\n","        print(f\"    Mask {os.path.basename(filepath)} treated as pre-labeled uint8/uint16.\")\n","        return img.astype(np.uint16)\n","\n","    except Exception as e:\n","        print(f\"    Error loading image {filepath}: {str(e)}\")\n","        return None\n","\n","def load_and_prepare_data(csv_path):\n","    \"\"\"Loads the data and checks for required columns.\"\"\"\n","    print(f\"Loading data from {csv_path}...\")\n","    try:\n","        df = pd.read_csv(csv_path)\n","        # Ensure 'sample_id' is present from the original CSV structure\n","        if 'sample_id' not in df.columns and 'cell_id' in df.columns:\n","             # Attempt to derive sample_id if it's embedded in cell_id\n","             # This assumes cell_id is like 'actual_sample_id_originalcelllabel'\n","             df['derived_sample_id'] = df['cell_id'].apply(lambda x: '_'.join(x.split('_')[:-1]))\n","             print(\"Derived 'derived_sample_id' from 'cell_id'. Will use this for matching masks.\")\n","        elif 'sample_id' in df.columns:\n","            df['derived_sample_id'] = df['sample_id'] # Use existing if available\n","            print(\"Using existing 'sample_id' column for matching masks.\")\n","        else:\n","            print(\"Error: Cannot determine sample_id. 'sample_id' column missing and cannot derive from 'cell_id'.\")\n","            return None\n","\n","        print(f\"Successfully loaded {len(df)} cells.\")\n","    except FileNotFoundError:\n","        print(f\"Error: CSV file not found at {csv_path}\")\n","        return None\n","\n","    essential_cols_for_operation = list(SENESCENCE_SCORE_WEIGHTS.keys()) + ['nuclei_count', 'cell_id'] # 'sample_id' checked above\n","    all_needed_cols = list(set(FEATURES_FOR_CLUSTERING + essential_cols_for_operation))\n","\n","    missing_cols = [col for col in all_needed_cols if col not in df.columns]\n","    if missing_cols:\n","        missing_critical_cols = [col for col in essential_cols_for_operation if col not in df.columns]\n","        if missing_critical_cols:\n","            print(f\"Error: Critical columns for scoring/rules are missing: {missing_critical_cols}\")\n","            return None\n","        print(f\"Warning: Some columns listed in FEATURES_FOR_CLUSTERING are missing: {missing_cols}.\")\n","\n","    return df\n","\n","def calculate_senescence_score(df, score_weights):\n","    \"\"\"Calculates a per-cell senescence score.\"\"\"\n","    print(\"Calculating per-cell senescence score...\")\n","    features_for_scoring_present = [f for f in score_weights.keys() if f in df.columns]\n","    if not features_for_scoring_present:\n","        print(\"Error: No features for senescence score calculation are present in the DataFrame.\")\n","        df['senescence_score'] = np.nan\n","        df['senescence_score_normalized'] = np.nan\n","        return df\n","    score_df = df[features_for_scoring_present].copy()\n","    for col in AREA_FEATURES_TO_LOG:\n","        if col in score_df.columns:\n","            score_df[col] = np.log1p(score_df[col])\n","    scaler = StandardScaler()\n","    numeric_score_cols = score_df.select_dtypes(include=np.number).columns\n","    if not numeric_score_cols.empty:\n","        score_features_standardized = scaler.fit_transform(score_df[numeric_score_cols])\n","        score_features_standardized_df = pd.DataFrame(score_features_standardized, columns=numeric_score_cols, index=score_df.index)\n","    else:\n","        score_features_standardized_df = pd.DataFrame(index=score_df.index)\n","    df['senescence_score'] = 0.0\n","    for feature, weight in score_weights.items():\n","        if feature in score_features_standardized_df.columns:\n","            df['senescence_score'] += score_features_standardized_df[feature] * weight\n","    if df['senescence_score'].isna().all() or (df['senescence_score'].max() == df['senescence_score'].min()):\n","        df['senescence_score_normalized'] = np.nan if df['senescence_score'].isna().all() else 0.0\n","    else:\n","        df['senescence_score_normalized'] = (df['senescence_score'] - df['senescence_score'].min()) / \\\n","                                           (df['senescence_score'].max() - df['senescence_score'].min())\n","    print(\"Senescence score calculation complete.\")\n","    return df\n","\n","def perform_refined_clustering(df, feature_columns_for_clustering, umap_n_neighbors=30, umap_min_dist=0.1, umap_random_state=42, kmeans_n_clusters=2, kmeans_random_state=42):\n","    \"\"\"Performs UMAP and k-Means clustering on selected features.\"\"\"\n","    print(f\"\\nPerforming refined clustering using features: {feature_columns_for_clustering}...\")\n","    actual_clustering_features = [col for col in feature_columns_for_clustering if col in df.columns]\n","    if not actual_clustering_features:\n","        df['umap_x_refined'], df['umap_y_refined'], df['cluster_refined'] = np.nan, np.nan, np.nan\n","        return df\n","    features_df = df[actual_clustering_features].copy()\n","    for col in actual_clustering_features:\n","        if not pd.api.types.is_numeric_dtype(features_df[col]):\n","            try: features_df[col] = pd.to_numeric(features_df[col])\n","            except ValueError:\n","                features_df = features_df.drop(columns=[col])\n","                actual_clustering_features.remove(col)\n","    features_df = features_df.fillna(features_df.mean())\n","    if features_df.empty or features_df.shape[1] == 0:\n","        df['umap_x_refined'], df['umap_y_refined'], df['cluster_refined'] = np.nan, np.nan, np.nan\n","        return df\n","    for col in AREA_FEATURES_TO_LOG:\n","        if col in features_df.columns: features_df[col] = np.log1p(features_df[col])\n","    scaler = StandardScaler()\n","    features_standardized = scaler.fit_transform(features_df)\n","    actual_umap_n_neighbors = min(umap_n_neighbors, len(features_standardized) - 1)\n","    if actual_umap_n_neighbors < 2 :\n","        df['umap_x_refined'], df['umap_y_refined'], df['cluster_refined'] = np.nan, np.nan, np.nan\n","        return df\n","    reducer = umap.UMAP(n_neighbors=actual_umap_n_neighbors, min_dist=umap_min_dist, random_state=umap_random_state, n_components=2)\n","    embedding = reducer.fit_transform(features_standardized)\n","    df['umap_x_refined'], df['umap_y_refined'] = embedding[:, 0], embedding[:, 1]\n","    if len(embedding) >= kmeans_n_clusters:\n","        kmeans = KMeans(n_clusters=kmeans_n_clusters, random_state=kmeans_random_state, n_init='auto')\n","        df['cluster_refined'] = kmeans.fit_predict(embedding)\n","    else: df['cluster_refined'] = np.nan\n","    print(\"Refined clustering complete.\")\n","    return df\n","\n","def classify_cells(df, preliminary_quantile, multinucleation_threshold):\n","    \"\"\"Assigns preliminary and final cell types.\"\"\"\n","    print(\"\\nClassifying cells...\")\n","    if 'senescence_score_normalized' not in df.columns or df['senescence_score_normalized'].isna().all():\n","        df['cell_type_preliminary'] = 'Unknown'\n","    else:\n","        score_threshold = df['senescence_score_normalized'].quantile(preliminary_quantile)\n","        print(f\"  Using senescence score quantile {preliminary_quantile} (threshold = {score_threshold:.4f}) for preliminary classification.\")\n","        df['cell_type_preliminary'] = df['senescence_score_normalized'].apply(\n","            lambda x: 'Senescent' if x >= score_threshold else 'Non-senescent')\n","        prelim_sen_count = (df['cell_type_preliminary'] == 'Senescent').sum()\n","        print(f\"  {prelim_sen_count} cells ({prelim_sen_count/len(df)*100:.2f}%) preliminarily classified as Senescent by score.\")\n","    df['cell_type_final'] = df['cell_type_preliminary']\n","    if 'nuclei_count' in df.columns:\n","        multinucleated_mask = df['nuclei_count'] > multinucleation_threshold\n","        total_multinucleated = multinucleated_mask.sum()\n","        print(f\"\\n--- Multinucleation Rule (nuclei_count > {multinucleation_threshold}) ---\")\n","        print(f\"  Total cells considered polynucleated: {total_multinucleated} ({total_multinucleated/len(df)*100:.2f}%)\")\n","        if total_multinucleated > 0:\n","            multinucleated_and_sen_by_score = (multinucleated_mask & (df['cell_type_preliminary'] == 'Senescent')).sum()\n","            print(f\"    Of these {total_multinucleated} polynucleated cells:\")\n","            print(f\"      - {multinucleated_and_sen_by_score} were ALREADY 'Senescent' by score.\")\n","            multinucleated_reclassified_to_senescent = (multinucleated_mask & (df['cell_type_preliminary'] == 'Non-senescent')).sum()\n","            print(f\"      - {multinucleated_reclassified_to_senescent} were 'Non-senescent' by score and are NOW RECLASSIFIED to 'Senescent'.\")\n","        df.loc[multinucleated_mask, 'cell_type_final'] = 'Senescent'\n","    else: print(\"  Warning: 'nuclei_count' column not found. Cannot apply multinucleation rule.\")\n","    final_sen_count = (df['cell_type_final'] == 'Senescent').sum()\n","    print(f\"\\nTotal cells finally classified as Senescent: {final_sen_count} ({final_sen_count/len(df)*100:.2f}%)\")\n","    print(\"Cell classification complete.\")\n","    return df\n","\n","def visualize_refined_results(df, output_dir):\n","    \"\"\"Generates and saves summary visualizations for the refined analysis.\"\"\"\n","    # (Implementation from previous response, ensure it's up-to-date)\n","    print(\"\\nGenerating summary visualizations for refined results...\")\n","    if not os.path.exists(output_dir): os.makedirs(output_dir)\n","    if 'umap_x_refined' in df.columns and df['umap_x_refined'].notna().any() and 'senescence_score_normalized' in df.columns and df['senescence_score_normalized'].notna().any():\n","        plt.figure(figsize=(12, 10)); scatter = plt.scatter(df['umap_x_refined'], df['umap_y_refined'], c=df['senescence_score_normalized'], cmap='viridis', s=15, alpha=0.7)\n","        plt.colorbar(scatter, label='Normalized Senescence Score'); plt.title('Refined UMAP: Cells Colored by Senescence Score', fontsize=16)\n","        plt.xlabel('UMAP Dimension 1 (Refined)'); plt.ylabel('UMAP Dimension 2 (Refined)'); plt.grid(True, linestyle='--', alpha=0.5)\n","        plt.savefig(os.path.join(output_dir, 'umap_refined_by_senescence_score.png'), dpi=300, bbox_inches='tight'); plt.close()\n","    if 'umap_x_refined' in df.columns and df['umap_x_refined'].notna().any() and 'cell_type_final' in df.columns:\n","        plt.figure(figsize=(12, 10)); unique_types = df['cell_type_final'].unique(); palette = {t: ('red' if t == 'Senescent' else ('blue' if t == 'Non-senescent' else 'grey')) for t in unique_types}\n","        for ct, col in palette.items(): subset = df[df['cell_type_final'] == ct]; plt.scatter(subset['umap_x_refined'], subset['umap_y_refined'], label=ct, color=col, s=15, alpha=0.7)\n","        plt.title('Refined UMAP: Cells Colored by Final Classification', fontsize=16); plt.xlabel('UMAP Dimension 1 (Refined)'); plt.ylabel('UMAP Dimension 2 (Refined)')\n","        if palette: plt.legend(title='Final Cell Type'); plt.grid(True, linestyle='--', alpha=0.5)\n","        plt.savefig(os.path.join(output_dir, 'umap_refined_by_final_cell_type.png'), dpi=300, bbox_inches='tight'); plt.close()\n","    if 'senescence_score_normalized' in df.columns and df['senescence_score_normalized'].notna().any():\n","        plt.figure(figsize=(10, 6)); sns.histplot(df['senescence_score_normalized'].dropna(), kde=True, bins=50)\n","        plt.title('Distribution of Normalized Senescence Score', fontsize=16); plt.xlabel('Normalized Senescence Score'); plt.ylabel('Frequency')\n","        if 'cell_type_preliminary' in df.columns: score_thresh = df['senescence_score_normalized'].quantile(PRELIMINARY_SENESCENCE_QUANTILE); plt.axvline(score_thresh, color='r', linestyle='--', label=f'Quantile Threshold ({PRELIMINARY_SENESCENCE_QUANTILE*100:.0f}th percentile)'); plt.legend()\n","        plt.grid(True, linestyle='--', alpha=0.5); plt.savefig(os.path.join(output_dir, 'senescence_score_distribution.png'), dpi=300, bbox_inches='tight'); plt.close()\n","    if 'cell_type_final' in df.columns and df['cell_type_final'].nunique() > 1:\n","        features = ['cell_area', 'avg_nucleus_area', 'cell_circularity', 'nucleus_to_cell_area_ratio', 'senescence_score_normalized', 'nuclei_count']\n","        features = [f for f in features if f in df.columns and df[f].notna().any()]\n","        if features:\n","            cols_plot = 3; rows_plot = (len(features) + cols_plot - 1) // cols_plot; fig, axes = plt.subplots(rows_plot, cols_plot, figsize=(5*cols_plot, 5*rows_plot), squeeze=False); axes = axes.flatten()\n","            pal = palette if 'palette' in locals() else 'coolwarm'; ord_list = sorted(df['cell_type_final'].unique())\n","            for i, feat in enumerate(features): sns.boxplot(x='cell_type_final', y=feat, data=df, ax=axes[i], palette=pal, order=ord_list); axes[i].set_title(feat.replace('_',' ').title()); axes[i].set_xlabel('Final Cell Type'); axes[i].set_ylabel(feat.replace('_',' ').title())\n","            for j in range(i + 1, len(axes)): fig.delaxes(axes[j])\n","            plt.tight_layout(); plt.savefig(os.path.join(output_dir, 'feature_comparison_by_final_type.png'), dpi=300, bbox_inches='tight'); plt.close()\n","    print(\"Summary visualizations saved.\")\n","\n","\n","def visualize_classification_on_masks(df_results, cell_mask_dir, nuclei_mask_dir, output_dir_masks):\n","    \"\"\"\n","    Visualizes the final cell classification by overlaying it on the original mask images.\n","    \"\"\"\n","    print(f\"\\nGenerating classification overlays on original masks in: {output_dir_masks}\")\n","    if not os.path.exists(output_dir_masks):\n","        os.makedirs(output_dir_masks)\n","\n","    # Define colors for visualization\n","    senescent_color = [255, 0, 0]  # Red\n","    non_senescent_color = [0, 0, 255]  # Blue\n","    nuclei_overlay_color = [0, 255, 0]  # Green for nuclei outline or fill\n","    boundary_color = [200, 200, 200] # Light grey for cell boundaries\n","\n","    # Get unique sample IDs from the results DataFrame\n","    # Use 'derived_sample_id' which was created in load_and_prepare_data\n","    if 'derived_sample_id' not in df_results.columns:\n","        print(\"Error: 'derived_sample_id' column not found in results. Cannot match to mask files.\")\n","        return\n","\n","    unique_sample_ids = df_results['derived_sample_id'].unique()\n","\n","    # Create a lookup dictionary for cell classifications\n","    # cell_id in df_results is 'derived_sample_id_originalcelllabel'\n","    classification_lookup = pd.Series(df_results.cell_type_final.values, index=df_results.cell_id).to_dict()\n","\n","    available_cell_mask_files = [f for f in os.listdir(cell_mask_dir) if f.endswith(('.tif', '.tiff'))]\n","    available_nuclei_mask_files = [f for f in os.listdir(nuclei_mask_dir) if f.endswith(('.tif', '.tiff'))]\n","\n","    for sample_id_from_csv in tqdm(unique_sample_ids, desc=\"Processing samples for mask visualization\"):\n","        # Find corresponding mask files\n","        cell_mask_file = None\n","        for f_name in available_cell_mask_files:\n","            extracted_id = extract_sample_id(f_name)\n","            if extracted_id == sample_id_from_csv:\n","                cell_mask_file = f_name\n","                break\n","\n","        nuclei_mask_file = None\n","        for f_name in available_nuclei_mask_files:\n","            extracted_id = extract_sample_id(f_name)\n","            if extracted_id == sample_id_from_csv:\n","                nuclei_mask_file = f_name\n","                break\n","\n","        if not cell_mask_file:\n","            print(f\"  Warning: Cell mask file not found for sample ID: {sample_id_from_csv}\")\n","            continue\n","\n","        print(f\"\\n  Processing sample: {sample_id_from_csv}\")\n","        cell_mask_path = os.path.join(cell_mask_dir, cell_mask_file)\n","\n","        # Load cell mask (should be a labeled mask where each integer is a cell ID)\n","        labeled_cell_mask = load_image_as_labeled_mask(cell_mask_path)\n","        if labeled_cell_mask is None:\n","            continue\n","\n","        # Create an empty RGB image for the overlay\n","        overlay_image = np.zeros((labeled_cell_mask.shape[0], labeled_cell_mask.shape[1], 3), dtype=np.uint8)\n","\n","        # Iterate through each cell label in the mask\n","        cell_props = measure.regionprops(labeled_cell_mask)\n","        for props in cell_props:\n","            original_cell_label = props.label # This is the integer ID from the mask\n","\n","            # Construct the full cell_id as it appears in the CSV results\n","            # This assumes 'cell_id' in CSV is 'derived_sample_id_originalcelllabel'\n","            # and 'original_cell_id' column was created as int(full_cell_id.split('_')[-1])\n","            # For lookup, we need the full ID.\n","            full_cell_id_for_lookup = f\"{sample_id_from_csv}_{original_cell_label}\"\n","\n","            cell_type = classification_lookup.get(full_cell_id_for_lookup, 'Unknown')\n","\n","            current_color = non_senescent_color\n","            if cell_type == 'Senescent':\n","                current_color = senescent_color\n","            elif cell_type == 'Unknown':\n","                current_color = [128, 128, 128] # Grey for unknown\n","\n","            # Color the cell region\n","            overlay_image[labeled_cell_mask == original_cell_label] = current_color\n","\n","            # Draw cell boundaries (optional, can make image busy but more informative)\n","            # cell_boundary = segmentation.find_boundaries(labeled_cell_mask == original_cell_label, mode='inner')\n","            # overlay_image[cell_boundary] = boundary_color\n","\n","\n","        # Optionally, overlay nuclei\n","        if nuclei_mask_file:\n","            nuclei_mask_path = os.path.join(nuclei_mask_dir, nuclei_mask_file)\n","            labeled_nuclei_mask = load_image_as_labeled_mask(nuclei_mask_path)\n","            if labeled_nuclei_mask is not None:\n","                # Find boundaries of nuclei to make them more visible as outlines\n","                nuclei_boundaries = segmentation.find_boundaries(labeled_nuclei_mask, mode='inner', background=0)\n","                overlay_image[nuclei_boundaries] = nuclei_overlay_color\n","                # Or fill nuclei:\n","                # overlay_image[labeled_nuclei_mask > 0] = nuclei_overlay_color\n","\n","\n","        # Save the overlay image\n","        output_filename = os.path.join(output_dir_masks, f\"{sample_id_from_csv}_classification_overlay.png\")\n","\n","        # Add a legend to the image (matplotlib approach)\n","        fig_legend, ax_legend = plt.subplots(figsize=(overlay_image.shape[1]/100, overlay_image.shape[0]/100), dpi=100) # Adjust size as needed\n","        ax_legend.imshow(overlay_image)\n","\n","        sen_patch = mpatches.Patch(color=np.array(senescent_color)/255., label='Senescent')\n","        non_sen_patch = mpatches.Patch(color=np.array(non_senescent_color)/255., label='Non-senescent')\n","        nuc_patch = mpatches.Patch(color=np.array(nuclei_overlay_color)/255., label='Nuclei Outline')\n","        handles = [sen_patch, non_sen_patch]\n","        if nuclei_mask_file and labeled_nuclei_mask is not None: # only add nuclei legend if nuclei were processed\n","            handles.append(nuc_patch)\n","\n","        ax_legend.legend(handles=handles, loc='upper right', fontsize='small', bbox_to_anchor=(1.25, 1)) # Adjust bbox_to_anchor\n","        ax_legend.axis('off') # Turn off axis numbers and ticks\n","        plt.tight_layout()\n","        plt.savefig(output_filename, dpi=150) # Adjust DPI as needed\n","        plt.close(fig_legend)\n","        print(f\"    Saved overlay for {sample_id_from_csv} to {output_filename}\")\n","\n","    print(\"Mask overlay visualization complete.\")\n","\n","\n","def main_refined_analysis():\n","    \"\"\"Main function to run the refined senescence analysis.\"\"\"\n","    if not os.path.exists(OUTPUT_DIR):\n","        os.makedirs(OUTPUT_DIR)\n","        print(f\"Created output directory: {OUTPUT_DIR}\")\n","\n","    df = load_and_prepare_data(INPUT_CSV_PATH)\n","    if df is None: return\n","\n","    df = calculate_senescence_score(df, SENESCENCE_SCORE_WEIGHTS)\n","    df = perform_refined_clustering(df, FEATURES_FOR_CLUSTERING)\n","    df = classify_cells(df, PRELIMINARY_SENESCENCE_QUANTILE, MULTINUCLEATION_THRESHOLD)\n","\n","    output_csv_path = os.path.join(OUTPUT_DIR, 'cell_classification_results_refined.csv')\n","    cols_to_save = [col for col in df.columns if col not in ['umap_x', 'umap_y', 'cluster', 'cell_type']]\n","    if 'umap_x_refined' in df.columns and df['umap_x_refined'].isna().all():\n","        cols_to_save = [col for col in cols_to_save if col not in ['umap_x_refined', 'umap_y_refined']]\n","    if 'cluster_refined' in df.columns and df['cluster_refined'].isna().all():\n","        cols_to_save = [col for col in cols_to_save if col not in ['cluster_refined']]\n","    df_to_save = df[cols_to_save]\n","    df_to_save.to_csv(output_csv_path, index=False)\n","    print(f\"\\nRefined results saved to: {output_csv_path}\")\n","\n","    visualize_refined_results(df, OUTPUT_DIR) # Summary visualizations\n","\n","    # New call for visualizing on actual masks\n","    mask_overlay_output_path = os.path.join(OUTPUT_DIR, MASK_VISUALIZATION_SUBDIR)\n","    visualize_classification_on_masks(df, CELL_MASK_DIR, NUCLEI_MASK_DIR, mask_overlay_output_path)\n","\n","    print(\"\\nRefined analysis and mask visualization complete!\")\n","\n","if __name__ == '__main__':\n","    main_refined_analysis()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YK5PMnk0axqo","executionInfo":{"status":"ok","timestamp":1747203516452,"user_tz":-120,"elapsed":35275,"user":{"displayName":"Guido Putignano","userId":"13974663347531370398"}},"outputId":"afe90f05-85f1-4f67-8344-76f599deb2a0"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading data from /content/drive/MyDrive/knowledge/University/Master/Thesis/Analysis/flow3-x20/Senescence/cell_classification_results.csv...\n","Using existing 'sample_id' column for matching masks.\n","Successfully loaded 2472 cells.\n","Calculating per-cell senescence score...\n","Senescence score calculation complete.\n","\n","Performing refined clustering using features: ['cell_area', 'cell_perimeter', 'cell_eccentricity', 'cell_circularity', 'cell_aspect_ratio', 'avg_nucleus_area', 'max_nucleus_area', 'avg_nucleus_eccentricity', 'nucleus_area_std', 'nucleus_displacement', 'nucleus_to_cell_area_ratio']...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n","  warn(\n"]},{"output_type":"stream","name":"stdout","text":["Refined clustering complete.\n","\n","Classifying cells...\n","  Using senescence score quantile 0.85 (threshold = 0.5115) for preliminary classification.\n","  371 cells (15.01%) preliminarily classified as Senescent by score.\n","\n","--- Multinucleation Rule (nuclei_count > 1) ---\n","  Total cells considered polynucleated: 225 (9.10%)\n","    Of these 225 polynucleated cells:\n","      - 54 were ALREADY 'Senescent' by score.\n","      - 171 were 'Non-senescent' by score and are NOW RECLASSIFIED to 'Senescent'.\n","\n","Total cells finally classified as Senescent: 542 (21.93%)\n","Cell classification complete.\n","\n","Refined results saved to: /content/drive/MyDrive/knowledge/University/Master/Thesis/Analysis/flow3-x20/Senescence_Refined_V4/cell_classification_results_refined.csv\n","\n","Generating summary visualizations for refined results...\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-8-855c6e2b9f4c>:268: FutureWarning: \n","\n","Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n","\n","  for i, feat in enumerate(features): sns.boxplot(x='cell_type_final', y=feat, data=df, ax=axes[i], palette=pal, order=ord_list); axes[i].set_title(feat.replace('_',' ').title()); axes[i].set_xlabel('Final Cell Type'); axes[i].set_ylabel(feat.replace('_',' ').title())\n","<ipython-input-8-855c6e2b9f4c>:268: FutureWarning: \n","\n","Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n","\n","  for i, feat in enumerate(features): sns.boxplot(x='cell_type_final', y=feat, data=df, ax=axes[i], palette=pal, order=ord_list); axes[i].set_title(feat.replace('_',' ').title()); axes[i].set_xlabel('Final Cell Type'); axes[i].set_ylabel(feat.replace('_',' ').title())\n","<ipython-input-8-855c6e2b9f4c>:268: FutureWarning: \n","\n","Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n","\n","  for i, feat in enumerate(features): sns.boxplot(x='cell_type_final', y=feat, data=df, ax=axes[i], palette=pal, order=ord_list); axes[i].set_title(feat.replace('_',' ').title()); axes[i].set_xlabel('Final Cell Type'); axes[i].set_ylabel(feat.replace('_',' ').title())\n","<ipython-input-8-855c6e2b9f4c>:268: FutureWarning: \n","\n","Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n","\n","  for i, feat in enumerate(features): sns.boxplot(x='cell_type_final', y=feat, data=df, ax=axes[i], palette=pal, order=ord_list); axes[i].set_title(feat.replace('_',' ').title()); axes[i].set_xlabel('Final Cell Type'); axes[i].set_ylabel(feat.replace('_',' ').title())\n","<ipython-input-8-855c6e2b9f4c>:268: FutureWarning: \n","\n","Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n","\n","  for i, feat in enumerate(features): sns.boxplot(x='cell_type_final', y=feat, data=df, ax=axes[i], palette=pal, order=ord_list); axes[i].set_title(feat.replace('_',' ').title()); axes[i].set_xlabel('Final Cell Type'); axes[i].set_ylabel(feat.replace('_',' ').title())\n","<ipython-input-8-855c6e2b9f4c>:268: FutureWarning: \n","\n","Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n","\n","  for i, feat in enumerate(features): sns.boxplot(x='cell_type_final', y=feat, data=df, ax=axes[i], palette=pal, order=ord_list); axes[i].set_title(feat.replace('_',' ').title()); axes[i].set_xlabel('Final Cell Type'); axes[i].set_ylabel(feat.replace('_',' ').title())\n"]},{"output_type":"stream","name":"stdout","text":["Summary visualizations saved.\n","\n","Generating classification overlays on original masks in: /content/drive/MyDrive/knowledge/University/Master/Thesis/Analysis/flow3-x20/Senescence_Refined_V4/mask_overlays\n"]},{"output_type":"stream","name":"stderr","text":["\rProcessing samples for mask visualization:   0%|          | 0/8 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","  Processing sample: 0Pa_U_05mar19_20x_L2RA_Flat_seq001\n","    Loading mask: 0Pa_U_05mar19_20x_L2RA_Flat_seq001_cell_mask_merged_conservative.tif\n","    Mask 0Pa_U_05mar19_20x_L2RA_Flat_seq001_cell_mask_merged_conservative.tif appears to be already labeled.\n","    Loading mask: denoised_0Pa_U_05mar19_20x_L2RA_Flat_seq001_Cadherins_filtered_mask.tif\n","    Mask denoised_0Pa_U_05mar19_20x_L2RA_Flat_seq001_Cadherins_filtered_mask.tif appears to be already labeled.\n"]},{"output_type":"stream","name":"stderr","text":["\rProcessing samples for mask visualization:  12%|█▎        | 1/8 [00:01<00:10,  1.52s/it]"]},{"output_type":"stream","name":"stdout","text":["    Saved overlay for 0Pa_U_05mar19_20x_L2RA_Flat_seq001 to /content/drive/MyDrive/knowledge/University/Master/Thesis/Analysis/flow3-x20/Senescence_Refined_V4/mask_overlays/0Pa_U_05mar19_20x_L2RA_Flat_seq001_classification_overlay.png\n","\n","  Processing sample: 0Pa_U_05mar19_20x_L2RA_Flat_seq002\n","    Loading mask: 0Pa_U_05mar19_20x_L2RA_Flat_seq002_cell_mask_merged_conservative.tif\n","    Mask 0Pa_U_05mar19_20x_L2RA_Flat_seq002_cell_mask_merged_conservative.tif appears to be already labeled.\n","    Loading mask: denoised_0Pa_U_05mar19_20x_L2RA_Flat_seq002_Cadherins_filtered_mask.tif\n","    Mask denoised_0Pa_U_05mar19_20x_L2RA_Flat_seq002_Cadherins_filtered_mask.tif appears to be already labeled.\n"]},{"output_type":"stream","name":"stderr","text":["\rProcessing samples for mask visualization:  25%|██▌       | 2/8 [00:03<00:09,  1.57s/it]"]},{"output_type":"stream","name":"stdout","text":["    Saved overlay for 0Pa_U_05mar19_20x_L2RA_Flat_seq002 to /content/drive/MyDrive/knowledge/University/Master/Thesis/Analysis/flow3-x20/Senescence_Refined_V4/mask_overlays/0Pa_U_05mar19_20x_L2RA_Flat_seq002_classification_overlay.png\n","\n","  Processing sample: 0Pa_U_05mar19_20x_L2RA_Flat_seq003\n","    Loading mask: 0Pa_U_05mar19_20x_L2RA_Flat_seq003_cell_mask_merged_conservative.tif\n","    Mask 0Pa_U_05mar19_20x_L2RA_Flat_seq003_cell_mask_merged_conservative.tif appears to be already labeled.\n","    Loading mask: denoised_0Pa_U_05mar19_20x_L2RA_Flat_seq003_Cadherins_filtered_mask.tif\n","    Mask denoised_0Pa_U_05mar19_20x_L2RA_Flat_seq003_Cadherins_filtered_mask.tif appears to be already labeled.\n"]},{"output_type":"stream","name":"stderr","text":["\rProcessing samples for mask visualization:  38%|███▊      | 3/8 [00:04<00:07,  1.60s/it]"]},{"output_type":"stream","name":"stdout","text":["    Saved overlay for 0Pa_U_05mar19_20x_L2RA_Flat_seq003 to /content/drive/MyDrive/knowledge/University/Master/Thesis/Analysis/flow3-x20/Senescence_Refined_V4/mask_overlays/0Pa_U_05mar19_20x_L2RA_Flat_seq003_classification_overlay.png\n","\n","  Processing sample: 1.4Pa_U_05mar19_20x_L2R_Flat_seq001\n","    Loading mask: 1.4Pa_U_05mar19_20x_L2R_Flat_seq001_cell_mask_merged_conservative.tif\n","    Mask 1.4Pa_U_05mar19_20x_L2R_Flat_seq001_cell_mask_merged_conservative.tif appears to be already labeled.\n","    Loading mask: denoised_1.4Pa_U_05mar19_20x_L2R_Flat_seq001_Cadherins_filtered_mask.tif\n","    Mask denoised_1.4Pa_U_05mar19_20x_L2R_Flat_seq001_Cadherins_filtered_mask.tif appears to be already labeled.\n"]},{"output_type":"stream","name":"stderr","text":["\rProcessing samples for mask visualization:  50%|█████     | 4/8 [00:06<00:05,  1.49s/it]"]},{"output_type":"stream","name":"stdout","text":["    Saved overlay for 1.4Pa_U_05mar19_20x_L2R_Flat_seq001 to /content/drive/MyDrive/knowledge/University/Master/Thesis/Analysis/flow3-x20/Senescence_Refined_V4/mask_overlays/1.4Pa_U_05mar19_20x_L2R_Flat_seq001_classification_overlay.png\n","\n","  Processing sample: 1.4Pa_U_05mar19_20x_L2R_Flat_seq002\n","    Loading mask: 1.4Pa_U_05mar19_20x_L2R_Flat_seq002_cell_mask_merged_conservative.tif\n","    Mask 1.4Pa_U_05mar19_20x_L2R_Flat_seq002_cell_mask_merged_conservative.tif appears to be already labeled.\n","    Loading mask: denoised_1.4Pa_U_05mar19_20x_L2R_Flat_seq002_Cadherins_filtered_mask.tif\n","    Mask denoised_1.4Pa_U_05mar19_20x_L2R_Flat_seq002_Cadherins_filtered_mask.tif appears to be already labeled.\n"]},{"output_type":"stream","name":"stderr","text":["\rProcessing samples for mask visualization:  62%|██████▎   | 5/8 [00:07<00:04,  1.39s/it]"]},{"output_type":"stream","name":"stdout","text":["    Saved overlay for 1.4Pa_U_05mar19_20x_L2R_Flat_seq002 to /content/drive/MyDrive/knowledge/University/Master/Thesis/Analysis/flow3-x20/Senescence_Refined_V4/mask_overlays/1.4Pa_U_05mar19_20x_L2R_Flat_seq002_classification_overlay.png\n","\n","  Processing sample: 1.4Pa_U_05mar19_20x_L2R_Flat_seq003\n","    Loading mask: 1.4Pa_U_05mar19_20x_L2R_Flat_seq003_cell_mask_merged_conservative.tif\n","    Mask 1.4Pa_U_05mar19_20x_L2R_Flat_seq003_cell_mask_merged_conservative.tif appears to be already labeled.\n","    Loading mask: denoised_1.4Pa_U_05mar19_20x_L2R_Flat_seq003_Cadherins_filtered_mask.tif\n","    Mask denoised_1.4Pa_U_05mar19_20x_L2R_Flat_seq003_Cadherins_filtered_mask.tif appears to be already labeled.\n"]},{"output_type":"stream","name":"stderr","text":["\rProcessing samples for mask visualization:  75%|███████▌  | 6/8 [00:09<00:03,  1.63s/it]"]},{"output_type":"stream","name":"stdout","text":["    Saved overlay for 1.4Pa_U_05mar19_20x_L2R_Flat_seq003 to /content/drive/MyDrive/knowledge/University/Master/Thesis/Analysis/flow3-x20/Senescence_Refined_V4/mask_overlays/1.4Pa_U_05mar19_20x_L2R_Flat_seq003_classification_overlay.png\n","\n","  Processing sample: 1.4Pa_U_05mar19_20x_L2R_Flat_seq004\n","    Loading mask: 1.4Pa_U_05mar19_20x_L2R_Flat_seq004_cell_mask_merged_conservative.tif\n","    Mask 1.4Pa_U_05mar19_20x_L2R_Flat_seq004_cell_mask_merged_conservative.tif appears to be already labeled.\n","    Loading mask: denoised_1.4Pa_U_05mar19_20x_L2R_Flat_seq004_Cadherins_filtered_mask.tif\n","    Mask denoised_1.4Pa_U_05mar19_20x_L2R_Flat_seq004_Cadherins_filtered_mask.tif appears to be already labeled.\n"]},{"output_type":"stream","name":"stderr","text":["\rProcessing samples for mask visualization:  88%|████████▊ | 7/8 [00:11<00:01,  1.73s/it]"]},{"output_type":"stream","name":"stdout","text":["    Saved overlay for 1.4Pa_U_05mar19_20x_L2R_Flat_seq004 to /content/drive/MyDrive/knowledge/University/Master/Thesis/Analysis/flow3-x20/Senescence_Refined_V4/mask_overlays/1.4Pa_U_05mar19_20x_L2R_Flat_seq004_classification_overlay.png\n","\n","  Processing sample: 1.4Pa_U_05mar19_20x_L2R_Flat_seq005\n","    Loading mask: 1.4Pa_U_05mar19_20x_L2R_Flat_seq005_cell_mask_merged_conservative.tif\n","    Mask 1.4Pa_U_05mar19_20x_L2R_Flat_seq005_cell_mask_merged_conservative.tif appears to be already labeled.\n","    Loading mask: denoised_1.4Pa_U_05mar19_20x_L2R_Flat_seq005_Cadherins_filtered_mask.tif\n","    Mask denoised_1.4Pa_U_05mar19_20x_L2R_Flat_seq005_Cadherins_filtered_mask.tif appears to be already labeled.\n"]},{"output_type":"stream","name":"stderr","text":["Processing samples for mask visualization: 100%|██████████| 8/8 [00:12<00:00,  1.61s/it]"]},{"output_type":"stream","name":"stdout","text":["    Saved overlay for 1.4Pa_U_05mar19_20x_L2R_Flat_seq005 to /content/drive/MyDrive/knowledge/University/Master/Thesis/Analysis/flow3-x20/Senescence_Refined_V4/mask_overlays/1.4Pa_U_05mar19_20x_L2R_Flat_seq005_classification_overlay.png\n","Mask overlay visualization complete.\n","\n","Refined analysis and mask visualization complete!\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"markdown","source":["try something else"],"metadata":{"id":"bcDXImhQqsrP"}},{"cell_type":"code","source":["pip install scanpy"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2kHvbtJHr5C4","executionInfo":{"status":"ok","timestamp":1747207581371,"user_tz":-120,"elapsed":15354,"user":{"displayName":"Guido Putignano","userId":"13974663347531370398"}},"outputId":"cd400fc5-17e9-49d8-9a9b-446770b3a96b"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting scanpy\n","  Downloading scanpy-1.11.1-py3-none-any.whl.metadata (9.9 kB)\n","Collecting anndata>=0.8 (from scanpy)\n","  Downloading anndata-0.11.4-py3-none-any.whl.metadata (9.3 kB)\n","Requirement already satisfied: h5py>=3.7 in /usr/local/lib/python3.11/dist-packages (from scanpy) (3.13.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from scanpy) (1.5.0)\n","Collecting legacy-api-wrap>=1.4 (from scanpy)\n","  Downloading legacy_api_wrap-1.4.1-py3-none-any.whl.metadata (2.1 kB)\n","Requirement already satisfied: matplotlib>=3.7 in /usr/local/lib/python3.11/dist-packages (from scanpy) (3.10.0)\n","Requirement already satisfied: natsort in /usr/local/lib/python3.11/dist-packages (from scanpy) (8.4.0)\n","Requirement already satisfied: networkx>=2.7 in /usr/local/lib/python3.11/dist-packages (from scanpy) (3.4.2)\n","Requirement already satisfied: numba>=0.57 in /usr/local/lib/python3.11/dist-packages (from scanpy) (0.60.0)\n","Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.11/dist-packages (from scanpy) (2.0.2)\n","Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from scanpy) (24.2)\n","Requirement already satisfied: pandas>=1.5 in /usr/local/lib/python3.11/dist-packages (from scanpy) (2.2.2)\n","Requirement already satisfied: patsy!=1.0.0 in /usr/local/lib/python3.11/dist-packages (from scanpy) (1.0.1)\n","Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.11/dist-packages (from scanpy) (0.5.13)\n","Collecting scikit-learn<1.6.0,>=1.1 (from scanpy)\n","  Downloading scikit_learn-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n","Requirement already satisfied: scipy>=1.8 in /usr/local/lib/python3.11/dist-packages (from scanpy) (1.15.3)\n","Requirement already satisfied: seaborn>=0.13 in /usr/local/lib/python3.11/dist-packages (from scanpy) (0.13.2)\n","Collecting session-info2 (from scanpy)\n","  Downloading session_info2-0.1.2-py3-none-any.whl.metadata (2.5 kB)\n","Requirement already satisfied: statsmodels>=0.13 in /usr/local/lib/python3.11/dist-packages (from scanpy) (0.14.4)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from scanpy) (4.67.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from scanpy) (4.13.2)\n","Requirement already satisfied: umap-learn!=0.5.0,>=0.5 in /usr/local/lib/python3.11/dist-packages (from scanpy) (0.5.7)\n","Collecting array-api-compat!=1.5,>1.4 (from anndata>=0.8->scanpy)\n","  Downloading array_api_compat-1.11.2-py3-none-any.whl.metadata (1.9 kB)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7->scanpy) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7->scanpy) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7->scanpy) (4.57.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7->scanpy) (1.4.8)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7->scanpy) (11.2.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7->scanpy) (3.2.3)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7->scanpy) (2.9.0.post0)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.57->scanpy) (0.43.0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5->scanpy) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5->scanpy) (2025.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<1.6.0,>=1.1->scanpy) (3.6.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.7->scanpy) (1.17.0)\n","Downloading scanpy-1.11.1-py3-none-any.whl (2.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading anndata-0.11.4-py3-none-any.whl (144 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.5/144.5 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading legacy_api_wrap-1.4.1-py3-none-any.whl (10.0 kB)\n","Downloading scikit_learn-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading session_info2-0.1.2-py3-none-any.whl (14 kB)\n","Downloading array_api_compat-1.11.2-py3-none-any.whl (53 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: session-info2, legacy-api-wrap, array-api-compat, scikit-learn, anndata, scanpy\n","  Attempting uninstall: scikit-learn\n","    Found existing installation: scikit-learn 1.6.1\n","    Uninstalling scikit-learn-1.6.1:\n","      Successfully uninstalled scikit-learn-1.6.1\n","Successfully installed anndata-0.11.4 array-api-compat-1.11.2 legacy-api-wrap-1.4.1 scanpy-1.11.1 scikit-learn-1.5.2 session-info2-0.1.2\n"]}]},{"cell_type":"code","source":["import os\n","import re\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as mpatches\n","import seaborn as sns\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.cluster import DBSCAN\n","from sklearn.mixture import GaussianMixture\n","from sklearn.neighbors import NearestNeighbors\n","import umap\n","\n","try:\n","    import scanpy as sc\n","    SCANPY_AVAILABLE = True\n","except ImportError:\n","    print(\"Scanpy library not found. Diffusion map functionality will be skipped.\")\n","    SCANPY_AVAILABLE = False\n","\n","# --- Configuration & Parameters ---\n","INPUT_REFINED_CSV_PATH = \"/content/drive/MyDrive/knowledge/University/Master/Thesis/Analysis/flow3-x20/Senescence_Refined_V5_DiffMap/cell_classification_results_refined.csv\"\n","EXPLORATORY_OUTPUT_DIR = \"/content/drive/MyDrive/knowledge/University/Master/Thesis/Analysis/flow3-x20/Exploratory_Analysis_V4_fix\" # Incremented version\n","\n","FEATURES_FOR_ANALYSIS = [ # Features used for UMAP, DiffMap, DBSCAN on features, GMM on features\n","    'cell_area', 'cell_perimeter', 'cell_eccentricity', 'cell_circularity',\n","    'cell_aspect_ratio', 'avg_nucleus_area', 'max_nucleus_area',\n","    'avg_nucleus_eccentricity', 'nucleus_area_std', 'nucleus_displacement',\n","    'nucleus_to_cell_area_ratio',\n","    'nuclear_enlargement', 'cell_enlargement'\n","]\n","AREA_FEATURES_TO_LOG = ['cell_area', 'avg_nucleus_area', 'max_nucleus_area', 'cell_perimeter']\n","\n","# Diffusion Map parameters\n","N_DIFFUSION_COMPONENTS = 10\n","N_DCS_TO_PLOT = 3\n","N_NEIGHBORS_FOR_SCANPY = 15\n","\n","# DBSCAN Parameters - IMPORTANT: TUNE THESE MANUALLY AFTER FIRST RUN!\n","# These are now just defaults if specific values aren't passed to run_dbscan_and_plot\n","DBSCAN_EPS_DEFAULT = 0.75\n","DBSCAN_MIN_SAMPLES_DEFAULT = 10\n","\n","ESTIMATE_DBSCAN_EPS = True # Set to False after you've chosen your eps values.\n","K_FOR_EPS_ESTIMATION = 10\n","RUN_DBSCAN_ON_DIFFMAP = True\n","N_DCS_FOR_DBSCAN = 3\n","\n","# GMM Parameters\n","GMM_N_COMPONENTS_RANGE = range(2, 5)\n","GMM_COVARIANCE_TYPE = 'full'\n","\n","# Rule-Based Gating Parameters (Example - MODIFY THESE RULES)\n","RULE_BASED_GATES = [\n","    {\n","        'name': 'Polynucleated_Large',\n","        'conditions': [\n","            ('nuclei_count', '>', 1),\n","            ('cell_area', '>', 2500) # Example threshold, adjust!\n","        ],\n","        'output_label': 'Rule_Sen_Poly_Large'\n","    },\n","    {\n","        'name': 'Very_Large_Cell',\n","        'conditions': [\n","            ('cell_area', '>', 3500) # Example threshold, adjust!\n","        ],\n","        'output_label': 'Rule_Sen_VeryLarge'\n","    },\n","    {\n","        'name': 'High_Score_Not_Otherwise_Caught',\n","        'conditions': [\n","            ('senescence_score_normalized', '>', 0.85) # Example threshold, adjust!\n","        ],\n","        'output_label': 'Rule_Sen_HighScore'\n","    }\n","]\n","RULE_BASED_DEFAULT_LABEL = 'Rule_NonSenescent'\n","\n","\n","def load_data(csv_path):\n","    \"\"\"Loads the refined data.\"\"\"\n","    print(f\"Loading refined data from {csv_path}...\")\n","    try:\n","        df = pd.read_csv(csv_path)\n","        print(f\"Successfully loaded {len(df)} cells.\")\n","        for col_check in ['senescence_score_normalized', 'cell_type_final', 'nuclei_count', 'cell_area']:\n","            if col_check not in df.columns:\n","                print(f\"Warning: Essential column '{col_check}' not found. Some functionalities might be affected.\")\n","        return df\n","    except FileNotFoundError:\n","        print(f\"Error: CSV file not found at {csv_path}\")\n","        return None\n","\n","def preprocess_features_for_ml(df, feature_columns, log_transform_cols):\n","    \"\"\"Prepares features specifically for ML algorithms (scaling).\"\"\"\n","    print(f\"\\nPreprocessing features for ML. Selected: {feature_columns}\")\n","\n","    actual_features_for_ml = [col for col in feature_columns if col in df.columns]\n","    if not actual_features_for_ml:\n","        print(\"  Error: None of the specified FEATURES_FOR_ANALYSIS are present in the DataFrame for ML.\")\n","        return None, None\n","\n","    features_for_scaling_df = df[actual_features_for_ml].copy()\n","\n","    for col in log_transform_cols:\n","        if col in features_for_scaling_df.columns:\n","            features_for_scaling_df[col] = np.log1p(features_for_scaling_df[col])\n","            print(f\"  Log-transformed for scaling: {col}\")\n","\n","    if features_for_scaling_df.isnull().sum().any():\n","        print(f\"  Handling NaNs using mean imputation for {features_for_scaling_df.isnull().sum().sum()} values (for scaled features).\")\n","        features_for_scaling_df = features_for_scaling_df.fillna(features_for_scaling_df.mean())\n","\n","    cols_to_drop_scaled = features_for_scaling_df.columns[features_for_scaling_df.isna().all()].tolist()\n","    if cols_to_drop_scaled:\n","        print(f\"  Dropping all-NaN columns from scaled set: {cols_to_drop_scaled}\")\n","        features_for_scaling_df = features_for_scaling_df.drop(columns=cols_to_drop_scaled)\n","        actual_features_for_ml = [f for f in actual_features_for_ml if f not in cols_to_drop_scaled]\n","\n","    if features_for_scaling_df.empty or not actual_features_for_ml:\n","        print(\" Error: No features remaining for scaling after processing.\")\n","        return None, None\n","\n","    scaler = StandardScaler()\n","    features_scaled = scaler.fit_transform(features_for_scaling_df)\n","    print(\"  Features standardized for ML algorithms.\")\n","\n","    return features_scaled, actual_features_for_ml\n","\n","\n","def compute_and_plot_diffusion_map(df, scaled_features, feature_names_used, output_dir):\n","    \"\"\"Computes and plots diffusion map.\"\"\"\n","    if not SCANPY_AVAILABLE: print(\"Skipping diffusion map: Scanpy not available.\"); return df\n","    print(\"\\n--- Computing Diffusion Map ---\")\n","    if scaled_features is None or scaled_features.shape[0] == 0 : print(\"  No scaled features for Diffusion Map. Skipping.\"); return df\n","\n","    adata = sc.AnnData(scaled_features, var=pd.DataFrame(index=feature_names_used))\n","    adata.obs_names = df.index.astype(str)\n","    if 'senescence_score_normalized' in df.columns: adata.obs['senescence_score_normalized'] = df['senescence_score_normalized'].values\n","    if 'cell_type_final' in df.columns: adata.obs['cell_type_final'] = df['cell_type_final'].astype('category').values\n","\n","    actual_n_neighbors = min(N_NEIGHBORS_FOR_SCANPY, adata.n_obs - 1)\n","    if actual_n_neighbors < 2: print(f\"  Not enough samples for Scanpy neighbors. Skipping.\"); return df\n","\n","    print(f\"  Computing neighbors (k={actual_n_neighbors})...\")\n","    sc.pp.neighbors(adata, n_neighbors=actual_n_neighbors, use_rep='X')\n","    print(\"  Running sc.tl.diffmap...\")\n","    sc.tl.diffmap(adata, n_comps=N_DIFFUSION_COMPONENTS)\n","\n","    if 'X_diffmap' in adata.obsm:\n","        num_dc = min(N_DIFFUSION_COMPONENTS, adata.obsm['X_diffmap'].shape[1] - 1)\n","        for i in range(num_dc): df[f'dc_{i+1}'] = adata.obsm['X_diffmap'][:, i+1]\n","        print(f\"  Added {num_dc} DCs to DataFrame.\")\n","\n","        pairs = [(f'dc_{i}', f'dc_{j}') for i in range(1, N_DCS_TO_PLOT + 1) for j in range(i + 1, N_DCS_TO_PLOT + 1) if f'dc_{i}' in df.columns and f'dc_{j}' in df.columns]\n","        for dcx, dcy in pairs:\n","            if df[dcx].notna().any() and df[dcy].notna().any():\n","                if 'senescence_score_normalized' in df.columns and df['senescence_score_normalized'].notna().any():\n","                    plt.figure(figsize=(10,8)); plt.scatter(df[dcx], df[dcy], c=df['senescence_score_normalized'], cmap='viridis', s=12, alpha=0.7); plt.colorbar(label='Norm. Senescence Score')\n","                    plt.title(f'DiffMap ({dcx} vs {dcy}) by Score'); plt.xlabel(dcx.upper()); plt.ylabel(dcy.upper()); plt.grid(True,alpha=0.3); plt.savefig(os.path.join(output_dir, f'diffmap_{dcx}_{dcy}_by_score.png'),dpi=300,bbox_inches='tight'); plt.close()\n","                if 'cell_type_final' in df.columns:\n","                    plt.figure(figsize=(10,8)); types=df['cell_type_final'].unique(); pal={t:('red' if t=='Senescent' else ('blue' if t=='Non-senescent' else 'grey')) for t in types}\n","                    for ct,col in pal.items(): subset=df[df['cell_type_final']==ct]; plt.scatter(subset[dcx],subset[dcy],label=ct,color=col,s=12,alpha=0.7)\n","                    plt.title(f'DiffMap ({dcx} vs {dcy}) by Classif.'); plt.xlabel(dcx.upper()); plt.ylabel(dcy.upper());\n","                    if pal: plt.legend(title='Final Cell Type'); plt.grid(True,alpha=0.3); plt.savefig(os.path.join(output_dir, f'diffmap_{dcx}_{dcy}_by_type.png'),dpi=300,bbox_inches='tight'); plt.close()\n","        print(f\"  DiffMap pair plots for top {N_DCS_TO_PLOT} DCs saved.\")\n","    else: print(\"  Error: 'X_diffmap' not found in AnnData object after sc.tl.diffmap.\")\n","    return df\n","\n","def run_dbscan_and_plot(df, data_for_dbscan, data_desc, output_dir, umap_emb=None, current_eps_val=None, current_min_samples_val=None):\n","    \"\"\"Runs DBSCAN and plots results. Uses specific eps and min_samples if provided.\"\"\"\n","    print(f\"\\n--- Running DBSCAN on {data_desc} ---\")\n","    if data_for_dbscan is None or data_for_dbscan.shape[0] == 0:\n","        print(f\"  No data for DBSCAN on {data_desc}. Skipping.\")\n","        df[f'dbscan_{data_desc.lower().replace(\" \",\"_\")}']=-1\n","        return df\n","\n","    eps_to_use = current_eps_val if current_eps_val is not None else DBSCAN_EPS_DEFAULT\n","    min_s_to_use = current_min_samples_val if current_min_samples_val is not None else DBSCAN_MIN_SAMPLES_DEFAULT\n","\n","    if ESTIMATE_DBSCAN_EPS and current_eps_val is None :\n","        k_est = min(K_FOR_EPS_ESTIMATION, data_for_dbscan.shape[0]-1); k_est=max(1,k_est)\n","        nn=NearestNeighbors(n_neighbors=k_est); nn.fit(data_for_dbscan); dists, _ = nn.kneighbors(data_for_dbscan)\n","        actual_k_for_dists = min(k_est, dists.shape[1])\n","        if actual_k_for_dists > 0:\n","            k_dists = dists[:,actual_k_for_dists-1]\n","            k_dists_sorted = np.sort(k_dists)\n","            plt.figure(figsize=(8,6)); plt.plot(k_dists_sorted); plt.title(f'{actual_k_for_dists}-Dist Graph for Eps ({data_desc})');\n","            plt.xlabel(\"Points sorted by distance\"); plt.ylabel(f\"{actual_k_for_dists}-th NN Distance (eps candidate)\"); plt.grid(True,alpha=0.3);\n","            eps_path=os.path.join(output_dir, f'dbscan_eps_est_{data_desc.lower().replace(\" \",\"_\")}.png'); plt.savefig(eps_path,dpi=300); plt.close();\n","            print(f\"  Saved k-dist graph: {eps_path}. PLEASE INSPECT THIS PLOT TO SET appropriate DBSCAN_EPS for {data_desc}.\")\n","            if len(k_dists_sorted)>10:\n","                sug_eps=np.percentile(k_dists_sorted,90);\n","                print(f\"  A percentile-based suggestion for eps for {data_desc} is: {sug_eps:.3f}. The script will use eps={eps_to_use} (default or passed).\")\n","        else:\n","            print(f\"  Could not determine k-distances for eps estimation for {data_desc}. Using eps={eps_to_use}\")\n","\n","    print(f\"  Running DBSCAN with eps={eps_to_use}, min_samples={min_s_to_use} on {data_desc}...\")\n","    db=DBSCAN(eps=eps_to_use,min_samples=min_s_to_use).fit(data_for_dbscan)\n","    clust_col=f'dbscan_{data_desc.lower().replace(\" \",\"_\")}'; df[clust_col]=db.labels_\n","    n_clust=len(set(db.labels_))-(1 if -1 in db.labels_ else 0); n_noise=list(db.labels_).count(-1)\n","    print(f\"  DBSCAN on {data_desc}: {n_clust} clusters, {n_noise} noise ({n_noise/len(df)*100:.2f}%).\")\n","\n","    if umap_emb is not None and 'umap_x_refined' in df.columns and 'umap_y_refined' in df.columns:\n","        plt.figure(figsize=(12,10));\n","        labels_unique_dbscan=sorted(df[clust_col].unique());\n","        n_actual_clusters = len([l for l in labels_unique_dbscan if l != -1])\n","        dbscan_cmap_obj = plt.cm.get_cmap('Spectral', n_actual_clusters if n_actual_clusters > 0 else 1)\n","        cdict = {}; cluster_idx = 0\n","        for lbl in labels_unique_dbscan:\n","            if lbl == -1: cdict[lbl] = (0.5, 0.5, 0.5, 1)\n","            else: cdict[lbl] = dbscan_cmap_obj(cluster_idx); cluster_idx += 1\n","        for k_val in labels_unique_dbscan:\n","            mask=(df[clust_col]==k_val); xy=umap_emb[mask]\n","            if xy.shape[0]>0:\n","                 plt.scatter(xy[:,0],xy[:,1], s=(20 if k_val!=-1 else 10), c=[cdict[k_val]],\n","                             marker=('o' if k_val!=-1 else 'x'), label=('Noise' if k_val == -1 else f'Cluster {k_val}'))\n","        plt.title(f'DBSCAN on {data_desc} (UMAP proj.)\\neps={eps_to_use:.3f}, min_s={min_s_to_use}');\n","        plt.xlabel('UMAP 1'); plt.ylabel('UMAP 2');\n","        plt.legend(title='DBSCAN Cluster',bbox_to_anchor=(1.05,1),loc='upper left',markerscale=1.5);\n","        plt.grid(True,alpha=0.3); plt.tight_layout(rect=[0,0,0.85,1]);\n","        plt.savefig(os.path.join(output_dir, f'dbscan_on_umap_{data_desc.lower().replace(\" \",\"_\")}.png'),dpi=300); plt.close();\n","        print(f\"  DBSCAN on {data_desc} plotted on UMAP.\")\n","    return df\n","\n","def run_gmm_and_plot(df, data_for_gmm, data_desc, output_dir, umap_embedding=None):\n","    \"\"\"Runs Gaussian Mixture Model clustering and plots results.\"\"\"\n","    print(f\"\\n--- Running Gaussian Mixture Model (GMM) on {data_desc} ---\")\n","    if data_for_gmm is None or data_for_gmm.shape[0] == 0:\n","        print(f\"  No data available for GMM on {data_desc}. Skipping.\")\n","        df[f'gmm_cluster_{data_desc.lower().replace(\" \", \"_\")}'] = -1\n","        df[f'gmm_prob_max_{data_desc.lower().replace(\" \", \"_\")}'] = np.nan\n","        return df\n","\n","    best_gmm = None; lowest_bic = np.inf\n","    print(f\"  Testing GMM with n_components in {list(GMM_N_COMPONENTS_RANGE)} using BIC...\")\n","    for n_components in GMM_N_COMPONENTS_RANGE:\n","        if n_components > data_for_gmm.shape[0]: continue\n","        gmm = GaussianMixture(n_components=n_components, covariance_type=GMM_COVARIANCE_TYPE, random_state=42, n_init=5)\n","        gmm.fit(data_for_gmm); bic = gmm.bic(data_for_gmm)\n","        print(f\"    GMM with {n_components} components: BIC = {bic:.2f}\")\n","        if bic < lowest_bic: lowest_bic = bic; best_gmm = gmm\n","\n","    if best_gmm is None:\n","        print(\"  GMM fitting failed. Skipping GMM.\"); df[f'gmm_cluster_{data_desc.lower().replace(\" \", \"_\")}'] = -1; df[f'gmm_prob_max_{data_desc.lower().replace(\" \", \"_\")}'] = np.nan\n","        return df\n","\n","    print(f\"  Best GMM found with {best_gmm.n_components} components (BIC={lowest_bic:.2f}).\")\n","    cluster_col_name = f'gmm_{data_desc.lower().replace(\" \", \"_\")}'; prob_col_name = f'gmm_prob_max_{data_desc.lower().replace(\" \", \"_\")}'\n","    df[cluster_col_name] = best_gmm.predict(data_for_gmm); df[prob_col_name] = np.max(best_gmm.predict_proba(data_for_gmm), axis=1)\n","\n","    if 'senescence_score_normalized' in df.columns:\n","        print(f\"  Mean senescence_score_normalized per GMM component (for {data_desc}):\\n{df.groupby(cluster_col_name)['senescence_score_normalized'].mean().sort_values()}\")\n","\n","    if umap_embedding is not None and 'umap_x_refined' in df.columns and 'umap_y_refined' in df.columns:\n","        plt.figure(figsize=(12, 10)); unique_gmm_labels = sorted(df[cluster_col_name].unique())\n","        gmm_palette = sns.color_palette(\"viridis\", n_colors=len(unique_gmm_labels))\n","        for i, label in enumerate(unique_gmm_labels):\n","            subset = df[df[cluster_col_name] == label]\n","            plt.scatter(subset['umap_x_refined'], subset['umap_y_refined'], label=f'GMM Comp. {label}', color=gmm_palette[i], s=15, alpha=0.7)\n","        plt.title(f'GMM ({best_gmm.n_components} comp.) on {data_desc} (UMAP proj.)', fontsize=14)\n","        plt.xlabel('UMAP 1'); plt.ylabel('UMAP 2'); plt.legend(title='GMM Component', bbox_to_anchor=(1.05, 1), loc='upper left')\n","        plt.grid(True, alpha=0.3); plt.tight_layout(rect=[0,0,0.85,1])\n","        plt.savefig(os.path.join(output_dir, f'gmm_on_umap_{data_desc.lower().replace(\" \", \"_\")}.png'), dpi=300); plt.close()\n","        print(f\"  GMM on {data_desc} results plotted on UMAP.\")\n","\n","        plt.figure(figsize=(12, 10)); scatter_gmm_prob = plt.scatter(df['umap_x_refined'], df['umap_y_refined'], c=df[prob_col_name], cmap='magma', s=15, alpha=0.7, vmin=0, vmax=1)\n","        plt.colorbar(scatter_gmm_prob, label='Max Probability of GMM Assignment')\n","        plt.title(f'GMM Max Assignment Probability on {data_desc} (UMAP proj.)', fontsize=14)\n","        plt.xlabel('UMAP 1'); plt.ylabel('UMAP 2'); plt.grid(True, alpha=0.3); plt.tight_layout()\n","        plt.savefig(os.path.join(output_dir, f'gmm_prob_on_umap_{data_desc.lower().replace(\" \", \"_\")}.png'), dpi=300); plt.close()\n","        print(f\"  GMM max probability on {data_desc} plotted on UMAP.\")\n","    return df\n","\n","def apply_rule_based_gating(df_main, rules, default_label, output_dir, umap_embedding=None):\n","    \"\"\"Applies a series of defined rules to classify cells. Operates on df_main.\"\"\"\n","    print(\"\\n--- Applying Rule-Based Gating ---\")\n","    df_main['rule_based_classification'] = default_label\n","\n","    # Check if all features required by any rule exist in df_main\n","    all_rule_features = set()\n","    for rule in rules:\n","        for condition in rule['conditions']:\n","            all_rule_features.add(condition[0])\n","\n","    missing_features_in_df = [feat for feat in all_rule_features if feat not in df_main.columns]\n","    if missing_features_in_df:\n","        print(f\"  Error: The following features required by rules are missing from the DataFrame: {missing_features_in_df}. Skipping rule-based gating.\")\n","        return df_main\n","\n","    for rule_idx, rule in enumerate(rules):\n","        print(f\"  Applying rule: {rule['name']}\")\n","        eligible_mask = (df_main['rule_based_classification'] == default_label)\n","        if not eligible_mask.any():\n","            print(f\"    No cells eligible for rule '{rule['name']}'.\")\n","            continue\n","\n","        rule_condition_mask = pd.Series([True] * len(df_main), index=df_main.index)\n","        for feature, operator, value in rule['conditions']:\n","            # This check is now redundant due to the one above, but kept for safety per condition\n","            if feature not in df_main.columns:\n","                print(f\"    Feature '{feature}' not found in DataFrame for rule '{rule['name']}'. Skipping this rule.\")\n","                rule_condition_mask[:] = False\n","                break\n","            try:\n","                # Ensure the column is numeric before comparison, handle potential errors\n","                feature_series = pd.to_numeric(df_main[feature], errors='coerce')\n","                if feature_series.isnull().any():\n","                    print(f\"    Warning: Feature '{feature}' contains non-numeric values after coercion for rule '{rule['name']}'. Comparisons may be affected.\")\n","\n","                if   operator == '>':  rule_condition_mask &= (feature_series > value)\n","                elif operator == '<':  rule_condition_mask &= (feature_series < value)\n","                elif operator == '>=': rule_condition_mask &= (feature_series >= value)\n","                elif operator == '<=': rule_condition_mask &= (feature_series <= value)\n","                elif operator == '==': rule_condition_mask &= (feature_series == value)\n","                elif operator == '!=': rule_condition_mask &= (feature_series != value)\n","                else:\n","                    print(f\"    Unknown operator '{operator}' in rule '{rule['name']}'. Skipping condition.\")\n","                    rule_condition_mask[:] = False; break\n","\n","            except Exception as e: # Catch any other error during comparison\n","                print(f\"    Error comparing feature '{feature}' in rule '{rule['name']}': {e}. Skipping condition.\")\n","                rule_condition_mask[:] = False; break\n","\n","        if not rule_condition_mask.all() and not rule_condition_mask.any() and rule_condition_mask is not False : # If mask became all False due to an issue\n","             print(f\"    Rule '{rule['name']}' resulted in an invalid condition mask. No cells labeled.\")\n","             continue\n","\n","\n","        if rule_condition_mask.any():\n","            cells_to_label_now = eligible_mask & rule_condition_mask\n","            df_main.loc[cells_to_label_now, 'rule_based_classification'] = rule['output_label']\n","            print(f\"    {cells_to_label_now.sum()} cells labeled as '{rule['output_label']}'.\")\n","        else:\n","            print(f\"    No cells met all conditions for rule '{rule['name']}'.\")\n","\n","    print(f\"\\nRule-based classification counts:\\n{df_main['rule_based_classification'].value_counts()}\")\n","\n","    if umap_embedding is not None and 'umap_x_refined' in df_main.columns and 'umap_y_refined' in df_main.columns:\n","        plt.figure(figsize=(12, 10)); unique_rule_labels = sorted(df_main['rule_based_classification'].unique())\n","        # Ensure enough colors if many rule labels\n","        if len(unique_rule_labels) > 0:\n","            rule_palette = sns.color_palette(\"Set3\", n_colors=max(10, len(unique_rule_labels)))\n","            for i, label in enumerate(unique_rule_labels):\n","                subset = df_main[df_main['rule_based_classification'] == label]\n","                plt.scatter(subset['umap_x_refined'], subset['umap_y_refined'], label=label, color=rule_palette[i % len(rule_palette)], s=15, alpha=0.7) # Modulo for safety\n","            plt.title('Rule-Based Gating Classification (UMAP proj.)', fontsize=14)\n","            plt.xlabel('UMAP 1'); plt.ylabel('UMAP 2'); plt.legend(title='Rule-Based Class', bbox_to_anchor=(1.05, 1), loc='upper left')\n","            plt.grid(True, alpha=0.3); plt.tight_layout(rect=[0,0,0.85,1])\n","            plt.savefig(os.path.join(output_dir, 'rule_based_gating_on_umap.png'), dpi=300); plt.close()\n","            print(\"  Rule-based gating results plotted on UMAP.\")\n","    return df_main\n","\n","\n","def main_exploratory_analysis():\n","    \"\"\"Main function to run exploratory analysis.\"\"\"\n","    if not os.path.exists(EXPLORATORY_OUTPUT_DIR):\n","        os.makedirs(EXPLORATORY_OUTPUT_DIR)\n","        print(f\"Created output directory: {EXPLORATORY_OUTPUT_DIR}\")\n","\n","    df = load_data(INPUT_REFINED_CSV_PATH)\n","    if df is None: return\n","\n","    # scaled_features are for ML algos, feature_names_used_for_scaling are their names\n","    # The main 'df' is used for rule-based gating as it contains all columns.\n","    scaled_features, feature_names_used_for_scaling = preprocess_features_for_ml(df, FEATURES_FOR_ANALYSIS, AREA_FEATURES_TO_LOG)\n","\n","    if scaled_features is None:\n","        print(\"Scaled feature preprocessing failed. Some ML-based analyses might be skipped or fail.\")\n","\n","    umap_embedding_for_plotting = None\n","    if 'umap_x_refined' in df.columns and 'umap_y_refined' in df.columns and df['umap_x_refined'].notna().all():\n","        print(\"\\nUsing existing UMAP coordinates from input CSV for visualizations.\")\n","        umap_embedding_for_plotting = df[['umap_x_refined', 'umap_y_refined']].values\n","    elif scaled_features is not None:\n","        print(\"\\nRecomputing UMAP for visualization...\")\n","        try:\n","            reducer = umap.UMAP(n_neighbors=15, min_dist=0.1, random_state=42, n_components=2)\n","            embedding = reducer.fit_transform(scaled_features)\n","            df['umap_x_refined'] = embedding[:, 0]; df['umap_y_refined'] = embedding[:, 1]\n","            umap_embedding_for_plotting = df[['umap_x_refined', 'umap_y_refined']].values\n","            print(\"  UMAP recomputed.\")\n","        except Exception as e: print(f\"  Error recomputing UMAP: {e}.\")\n","    else: print(\"\\nSkipping UMAP computation as scaled features are unavailable.\")\n","\n","    if scaled_features is not None and feature_names_used_for_scaling is not None:\n","        df = compute_and_plot_diffusion_map(df, scaled_features, feature_names_used_for_scaling, EXPLORATORY_OUTPUT_DIR)\n","\n","        # DBSCAN on Scaled Features - User needs to set DBSCAN_EPS_SCALED_FEATURES\n","        # based on dbscan_eps_est_scaled_features.png from the previous run.\n","        # Example: User looked at plot and chose this\n","        DBSCAN_EPS_SCALED_FEATURES = 2.3\n","        DBSCAN_MIN_SAMPLES_SCALED_FEATURES = 10 # Default or user-tuned\n","        print(f\"\\nNOTE: For DBSCAN on Scaled Features, using DBSCAN_EPS = {DBSCAN_EPS_SCALED_FEATURES}, MIN_SAMPLES = {DBSCAN_MIN_SAMPLES_SCALED_FEATURES}\")\n","        df = run_dbscan_and_plot(df, scaled_features, \"Scaled_Features\", EXPLORATORY_OUTPUT_DIR,\n","                                 umap_emb=umap_embedding_for_plotting,\n","                                 current_eps_val=DBSCAN_EPS_SCALED_FEATURES,\n","                                 current_min_samples_val=DBSCAN_MIN_SAMPLES_SCALED_FEATURES)\n","\n","        df = run_gmm_and_plot(df, scaled_features, \"Scaled_Features\", EXPLORATORY_OUTPUT_DIR, umap_embedding=umap_embedding_for_plotting)\n","\n","        if RUN_DBSCAN_ON_DIFFMAP and SCANPY_AVAILABLE:\n","            dc_cols = [f'dc_{i+1}' for i in range(N_DCS_FOR_DBSCAN) if f'dc_{i+1}' in df.columns and df[f'dc_{i+1}'].notna().any()]\n","            if dc_cols:\n","                data_dc = df[dc_cols].values\n","                # DBSCAN on DCs - User needs to set DBSCAN_EPS_DCS\n","                # based on dbscan_eps_est_top_X_dcs.png from the previous run.\n","                DBSCAN_EPS_DCS = 0.01 # Example: User looked at plot and chose this\n","                DBSCAN_MIN_SAMPLES_DCS = 10 # Default or user-tuned\n","                print(f\"\\nNOTE: For DBSCAN on Top DCs, using DBSCAN_EPS = {DBSCAN_EPS_DCS}, MIN_SAMPLES = {DBSCAN_MIN_SAMPLES_DCS}\")\n","                df = run_dbscan_and_plot(df, data_dc, f\"Top_{len(dc_cols)}_DCs\", EXPLORATORY_OUTPUT_DIR,\n","                                         umap_emb=umap_embedding_for_plotting,\n","                                         current_eps_val=DBSCAN_EPS_DCS,\n","                                         current_min_samples_val=DBSCAN_MIN_SAMPLES_DCS)\n","            else: print(f\"\\nSkipping DBSCAN on DCs: Not enough valid DC columns.\")\n","\n","        global RUN_GMM_ON_DIFFMAP, N_DCS_FOR_GMM\n","        if RUN_GMM_ON_DIFFMAP and SCANPY_AVAILABLE:\n","            dc_cols_gmm = [f'dc_{i+1}' for i in range(N_DCS_FOR_GMM) if f'dc_{i+1}' in df.columns and df[f'dc_{i+1}'].notna().any()]\n","            if dc_cols_gmm:\n","                data_dc_gmm = df[dc_cols_gmm].values\n","                df = run_gmm_and_plot(df, data_dc_gmm, f\"Top_{len(dc_cols_gmm)}_DCs\", EXPLORATORY_OUTPUT_DIR, umap_embedding=umap_embedding_for_plotting)\n","            else: print(f\"\\nSkipping GMM on DCs: Not enough valid DC columns.\")\n","\n","    # Apply rule-based gating using the main df, which contains all original and calculated columns\n","    # The first argument to apply_rule_based_gating is the DataFrame it will operate on for checking rules.\n","    df = apply_rule_based_gating(df, RULE_BASED_GATES, RULE_BASED_DEFAULT_LABEL, EXPLORATORY_OUTPUT_DIR, umap_embedding=umap_embedding_for_plotting)\n","\n","    exploratory_csv_path = os.path.join(EXPLORATORY_OUTPUT_DIR, 'exploratory_analysis_results_v4.csv')\n","    df.to_csv(exploratory_csv_path, index=False)\n","    print(f\"\\nExploratory analysis results saved to: {exploratory_csv_path}\")\n","    print(\"\\nExploratory analysis script finished.\")\n","\n","RUN_GMM_ON_DIFFMAP = True\n","N_DCS_FOR_GMM = 3\n","\n","if __name__ == '__main__':\n","    main_exploratory_analysis()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H0ddDO2HyEfJ","executionInfo":{"status":"ok","timestamp":1747209208118,"user_tz":-120,"elapsed":29984,"user":{"displayName":"Guido Putignano","userId":"13974663347531370398"}},"outputId":"fa3a525d-dd65-4600-b237-293b5fa731fd"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Created output directory: /content/drive/MyDrive/knowledge/University/Master/Thesis/Analysis/flow3-x20/Exploratory_Analysis_V4_fix\n","Loading refined data from /content/drive/MyDrive/knowledge/University/Master/Thesis/Analysis/flow3-x20/Senescence_Refined_V5_DiffMap/cell_classification_results_refined.csv...\n","Successfully loaded 2472 cells.\n","\n","Preprocessing features for ML. Selected: ['cell_area', 'cell_perimeter', 'cell_eccentricity', 'cell_circularity', 'cell_aspect_ratio', 'avg_nucleus_area', 'max_nucleus_area', 'avg_nucleus_eccentricity', 'nucleus_area_std', 'nucleus_displacement', 'nucleus_to_cell_area_ratio', 'nuclear_enlargement', 'cell_enlargement']\n","  Log-transformed for scaling: cell_area\n","  Log-transformed for scaling: avg_nucleus_area\n","  Log-transformed for scaling: max_nucleus_area\n","  Log-transformed for scaling: cell_perimeter\n","  Features standardized for ML algorithms.\n","\n","Using existing UMAP coordinates from input CSV for visualizations.\n","\n","--- Computing Diffusion Map ---\n","  Computing neighbors (k=15)...\n","  Running sc.tl.diffmap...\n","  Added 9 DCs to DataFrame.\n","  DiffMap pair plots for top 3 DCs saved.\n","\n","NOTE: For DBSCAN on Scaled Features, using DBSCAN_EPS = 2.3, MIN_SAMPLES = 10\n","\n","--- Running DBSCAN on Scaled_Features ---\n","  Running DBSCAN with eps=2.3, min_samples=10 on Scaled_Features...\n","  DBSCAN on Scaled_Features: 1 clusters, 137 noise (5.54%).\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-22-37f4cf34d37b>:209: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n","  dbscan_cmap_obj = plt.cm.get_cmap('Spectral', n_actual_clusters if n_actual_clusters > 0 else 1)\n"]},{"output_type":"stream","name":"stdout","text":["  DBSCAN on Scaled_Features plotted on UMAP.\n","\n","--- Running Gaussian Mixture Model (GMM) on Scaled_Features ---\n","  Testing GMM with n_components in [2, 3, 4] using BIC...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n","  # that has no feature names.\n","/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n","  # that has no feature names.\n","/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n","  # that has no feature names.\n"]},{"output_type":"stream","name":"stdout","text":["    GMM with 2 components: BIC = -11876.19\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n","  # that has no feature names.\n","/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n","  # that has no feature names.\n"]},{"output_type":"stream","name":"stdout","text":["    GMM with 3 components: BIC = -20370.16\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n","  # that has no feature names.\n","/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n","  # that has no feature names.\n","/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n","  # that has no feature names.\n"]},{"output_type":"stream","name":"stdout","text":["    GMM with 4 components: BIC = -26836.71\n","  Best GMM found with 4 components (BIC=-26836.71).\n","  Mean senescence_score_normalized per GMM component (for Scaled_Features):\n","gmm_scaled_features\n","1    0.316948\n","0    0.365966\n","3    0.500682\n","2    0.500958\n","Name: senescence_score_normalized, dtype: float64\n","  GMM on Scaled_Features results plotted on UMAP.\n","  GMM max probability on Scaled_Features plotted on UMAP.\n","\n","NOTE: For DBSCAN on Top DCs, using DBSCAN_EPS = 0.01, MIN_SAMPLES = 10\n","\n","--- Running DBSCAN on Top_3_DCs ---\n","  Running DBSCAN with eps=0.01, min_samples=10 on Top_3_DCs...\n","  DBSCAN on Top_3_DCs: 2 clusters, 42 noise (1.70%).\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-22-37f4cf34d37b>:209: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n","  dbscan_cmap_obj = plt.cm.get_cmap('Spectral', n_actual_clusters if n_actual_clusters > 0 else 1)\n"]},{"output_type":"stream","name":"stdout","text":["  DBSCAN on Top_3_DCs plotted on UMAP.\n","\n","--- Running Gaussian Mixture Model (GMM) on Top_3_DCs ---\n","  Testing GMM with n_components in [2, 3, 4] using BIC...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n","  # that has no feature names.\n","/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n","  # that has no feature names.\n","/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n","  # that has no feature names.\n","/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n","  # that has no feature names.\n","/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n","  # that has no feature names.\n"]},{"output_type":"stream","name":"stdout","text":["    GMM with 2 components: BIC = -42744.54\n","    GMM with 3 components: BIC = -43790.09\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n","  # that has no feature names.\n","/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n","  # that has no feature names.\n","/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n","  # that has no feature names.\n"]},{"output_type":"stream","name":"stdout","text":["    GMM with 4 components: BIC = -44590.14\n","  Best GMM found with 4 components (BIC=-44590.14).\n","  Mean senescence_score_normalized per GMM component (for Top_3_DCs):\n","gmm_top_3_dcs\n","0    0.319583\n","1    0.398703\n","2    0.427525\n","3    0.543944\n","Name: senescence_score_normalized, dtype: float64\n","  GMM on Top_3_DCs results plotted on UMAP.\n","  GMM max probability on Top_3_DCs plotted on UMAP.\n","\n","--- Applying Rule-Based Gating ---\n","  Applying rule: Polynucleated_Large\n","    200 cells labeled as 'Rule_Sen_Poly_Large'.\n","  Applying rule: Very_Large_Cell\n","    728 cells labeled as 'Rule_Sen_VeryLarge'.\n","  Applying rule: High_Score_Not_Otherwise_Caught\n","    0 cells labeled as 'Rule_Sen_HighScore'.\n","\n","Rule-based classification counts:\n","rule_based_classification\n","Rule_NonSenescent      1544\n","Rule_Sen_VeryLarge      728\n","Rule_Sen_Poly_Large     200\n","Name: count, dtype: int64\n","  Rule-based gating results plotted on UMAP.\n","\n","Exploratory analysis results saved to: /content/drive/MyDrive/knowledge/University/Master/Thesis/Analysis/flow3-x20/Exploratory_Analysis_V4_fix/exploratory_analysis_results_v4.csv\n","\n","Exploratory analysis script finished.\n"]}]},{"cell_type":"code","source":["import os\n","import re\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as mpatches\n","import seaborn as sns\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.cluster import DBSCAN\n","from sklearn.mixture import GaussianMixture\n","from sklearn.neighbors import NearestNeighbors\n","import umap\n","\n","try:\n","    import scanpy as sc\n","    SCANPY_AVAILABLE = True\n","except ImportError:\n","    print(\"Scanpy library not found. Diffusion map functionality will be skipped.\")\n","    SCANPY_AVAILABLE = False\n","\n","# --- Configuration & Parameters ---\n","INPUT_REFINED_CSV_PATH = \"/content/drive/MyDrive/knowledge/University/Master/Thesis/Analysis/flow3-x20/Senescence_Refined_V5_DiffMap/cell_classification_results_refined.csv\"\n","EXPLORATORY_OUTPUT_DIR = \"/content/drive/MyDrive/knowledge/University/Master/Thesis/Analysis/flow3-x20/Exploratory_Analysis_V5_rules\" # Incremented version\n","\n","FEATURES_FOR_ANALYSIS = [ # Features used for UMAP, DiffMap, DBSCAN on features, GMM on features\n","    'cell_area', 'cell_perimeter', 'cell_eccentricity', 'cell_circularity',\n","    'cell_aspect_ratio', 'avg_nucleus_area', 'max_nucleus_area',\n","    'avg_nucleus_eccentricity', 'nucleus_area_std', 'nucleus_displacement',\n","    'nucleus_to_cell_area_ratio',\n","    'nuclear_enlargement', 'cell_enlargement'\n","]\n","AREA_FEATURES_TO_LOG = ['cell_area', 'avg_nucleus_area', 'max_nucleus_area', 'cell_perimeter']\n","\n","# Diffusion Map parameters\n","N_DIFFUSION_COMPONENTS = 10\n","N_DCS_TO_PLOT = 3\n","N_NEIGHBORS_FOR_SCANPY = 15\n","\n","# DBSCAN Parameters - IMPORTANT: TUNE THESE MANUALLY AFTER FIRST RUN!\n","DBSCAN_EPS_DEFAULT = 0.75\n","DBSCAN_MIN_SAMPLES_DEFAULT = 10\n","ESTIMATE_DBSCAN_EPS = True\n","K_FOR_EPS_ESTIMATION = 10\n","RUN_DBSCAN_ON_DIFFMAP = True\n","N_DCS_FOR_DBSCAN = 3\n","\n","# GMM Parameters\n","GMM_N_COMPONENTS_RANGE = range(2, 5)\n","GMM_COVARIANCE_TYPE = 'full'\n","\n","# Rule-Based Gating Parameters (Updated with user's new rules)\n","# Rules are applied sequentially. A cell gets the label of the first rule it matches.\n","RULE_BASED_GATES = [\n","    {\n","        'name': 'Polynucleated', # Changed from Polynucleated_Large for broader capture\n","        'conditions': [\n","            ('nuclei_count', '>', 1),\n","        ],\n","        'output_label': 'Rule_Sen_Poly' # Cells with >1 nucleus\n","    },\n","    {\n","        'name': 'Very_Large_Cell',\n","        'conditions': [\n","            ('cell_area', '>', 5000) # User-defined threshold\n","        ],\n","        'output_label': 'Rule_Sen_VeryLarge'\n","    },\n","    {\n","        'name': 'Low_Circularity', # New rule\n","        'conditions': [\n","            ('cell_circularity', '<', 0.2)\n","        ],\n","        'output_label': 'Rule_Sen_LowCirc'\n","    },\n","    {\n","        'name': 'Low_NucToCellRatio', # New rule\n","        'conditions': [\n","            ('nucleus_to_cell_area_ratio', '<', 0.1)\n","        ],\n","        'output_label': 'Rule_Sen_LowNucRatio'\n","    },\n","    {\n","        'name': 'High_Score_Not_Otherwise_Caught',\n","        'conditions': [\n","            ('senescence_score_normalized', '>', 0.75) # User-defined threshold\n","        ],\n","        'output_label': 'Rule_Sen_HighScore'\n","    }\n","]\n","RULE_BASED_DEFAULT_LABEL = 'Rule_NonSenescent'\n","\n","\n","def load_data(csv_path):\n","    \"\"\"Loads the refined data.\"\"\"\n","    print(f\"Loading refined data from {csv_path}...\")\n","    try:\n","        df = pd.read_csv(csv_path)\n","        print(f\"Successfully loaded {len(df)} cells.\")\n","        # Check for essential columns for visualization and rules\n","        # Added all features used in new rules to this check\n","        for col_check in ['senescence_score_normalized', 'cell_type_final',\n","                          'nuclei_count', 'cell_area', 'cell_circularity',\n","                          'nucleus_to_cell_area_ratio']:\n","            if col_check not in df.columns:\n","                print(f\"Warning: Essential column '{col_check}' not found. Some functionalities might be affected.\")\n","        return df\n","    except FileNotFoundError:\n","        print(f\"Error: CSV file not found at {csv_path}\")\n","        return None\n","\n","def preprocess_features_for_ml(df, feature_columns, log_transform_cols):\n","    \"\"\"Prepares features specifically for ML algorithms (scaling).\"\"\"\n","    print(f\"\\nPreprocessing features for ML. Selected: {feature_columns}\")\n","\n","    actual_features_for_ml = [col for col in feature_columns if col in df.columns]\n","    if not actual_features_for_ml:\n","        print(\"  Error: None of the specified FEATURES_FOR_ANALYSIS are present in the DataFrame for ML.\")\n","        return None, None\n","\n","    features_for_scaling_df = df[actual_features_for_ml].copy()\n","\n","    for col in log_transform_cols:\n","        if col in features_for_scaling_df.columns:\n","            features_for_scaling_df[col] = np.log1p(features_for_scaling_df[col])\n","            print(f\"  Log-transformed for scaling: {col}\")\n","\n","    if features_for_scaling_df.isnull().sum().any():\n","        print(f\"  Handling NaNs using mean imputation for {features_for_scaling_df.isnull().sum().sum()} values (for scaled features).\")\n","        features_for_scaling_df = features_for_scaling_df.fillna(features_for_scaling_df.mean())\n","\n","    cols_to_drop_scaled = features_for_scaling_df.columns[features_for_scaling_df.isna().all()].tolist()\n","    if cols_to_drop_scaled:\n","        print(f\"  Dropping all-NaN columns from scaled set: {cols_to_drop_scaled}\")\n","        features_for_scaling_df = features_for_scaling_df.drop(columns=cols_to_drop_scaled)\n","        actual_features_for_ml = [f for f in actual_features_for_ml if f not in cols_to_drop_scaled]\n","\n","    if features_for_scaling_df.empty or not actual_features_for_ml:\n","        print(\" Error: No features remaining for scaling after processing.\")\n","        return None, None\n","\n","    scaler = StandardScaler()\n","    features_scaled = scaler.fit_transform(features_for_scaling_df)\n","    print(\"  Features standardized for ML algorithms.\")\n","\n","    return features_scaled, actual_features_for_ml\n","\n","\n","def compute_and_plot_diffusion_map(df, scaled_features, feature_names_used, output_dir):\n","    \"\"\"Computes and plots diffusion map.\"\"\"\n","    if not SCANPY_AVAILABLE: print(\"Skipping diffusion map: Scanpy not available.\"); return df\n","    print(\"\\n--- Computing Diffusion Map ---\")\n","    if scaled_features is None or scaled_features.shape[0] == 0 : print(\"  No scaled features for Diffusion Map. Skipping.\"); return df\n","\n","    adata = sc.AnnData(scaled_features, var=pd.DataFrame(index=feature_names_used))\n","    adata.obs_names = df.index.astype(str)\n","    if 'senescence_score_normalized' in df.columns: adata.obs['senescence_score_normalized'] = df['senescence_score_normalized'].values\n","    if 'cell_type_final' in df.columns: adata.obs['cell_type_final'] = df['cell_type_final'].astype('category').values\n","\n","    actual_n_neighbors = min(N_NEIGHBORS_FOR_SCANPY, adata.n_obs - 1)\n","    if actual_n_neighbors < 2: print(f\"  Not enough samples for Scanpy neighbors. Skipping.\"); return df\n","\n","    print(f\"  Computing neighbors (k={actual_n_neighbors})...\")\n","    sc.pp.neighbors(adata, n_neighbors=actual_n_neighbors, use_rep='X')\n","    print(\"  Running sc.tl.diffmap...\")\n","    sc.tl.diffmap(adata, n_comps=N_DIFFUSION_COMPONENTS)\n","\n","    if 'X_diffmap' in adata.obsm:\n","        num_dc = min(N_DIFFUSION_COMPONENTS, adata.obsm['X_diffmap'].shape[1] - 1)\n","        for i in range(num_dc): df[f'dc_{i+1}'] = adata.obsm['X_diffmap'][:, i+1]\n","        print(f\"  Added {num_dc} DCs to DataFrame.\")\n","\n","        pairs = [(f'dc_{i}', f'dc_{j}') for i in range(1, N_DCS_TO_PLOT + 1) for j in range(i + 1, N_DCS_TO_PLOT + 1) if f'dc_{i}' in df.columns and f'dc_{j}' in df.columns]\n","        for dcx, dcy in pairs:\n","            if df[dcx].notna().any() and df[dcy].notna().any():\n","                if 'senescence_score_normalized' in df.columns and df['senescence_score_normalized'].notna().any():\n","                    plt.figure(figsize=(10,8)); plt.scatter(df[dcx], df[dcy], c=df['senescence_score_normalized'], cmap='viridis', s=12, alpha=0.7); plt.colorbar(label='Norm. Senescence Score')\n","                    plt.title(f'DiffMap ({dcx} vs {dcy}) by Score'); plt.xlabel(dcx.upper()); plt.ylabel(dcy.upper()); plt.grid(True,alpha=0.3); plt.savefig(os.path.join(output_dir, f'diffmap_{dcx}_{dcy}_by_score.png'),dpi=300,bbox_inches='tight'); plt.close()\n","                if 'cell_type_final' in df.columns:\n","                    plt.figure(figsize=(10,8)); types=df['cell_type_final'].unique(); pal={t:('red' if t=='Senescent' else ('blue' if t=='Non-senescent' else 'grey')) for t in types}\n","                    for ct,col in pal.items(): subset=df[df['cell_type_final']==ct]; plt.scatter(subset[dcx],subset[dcy],label=ct,color=col,s=12,alpha=0.7)\n","                    plt.title(f'DiffMap ({dcx} vs {dcy}) by Classif.'); plt.xlabel(dcx.upper()); plt.ylabel(dcy.upper());\n","                    if pal: plt.legend(title='Final Cell Type'); plt.grid(True,alpha=0.3); plt.savefig(os.path.join(output_dir, f'diffmap_{dcx}_{dcy}_by_type.png'),dpi=300,bbox_inches='tight'); plt.close()\n","        print(f\"  DiffMap pair plots for top {N_DCS_TO_PLOT} DCs saved.\")\n","    else: print(\"  Error: 'X_diffmap' not found in AnnData object after sc.tl.diffmap.\")\n","    return df\n","\n","def run_dbscan_and_plot(df, data_for_dbscan, data_desc, output_dir, umap_emb=None, current_eps_val=None, current_min_samples_val=None):\n","    \"\"\"Runs DBSCAN and plots results. Uses specific eps and min_samples if provided.\"\"\"\n","    print(f\"\\n--- Running DBSCAN on {data_desc} ---\")\n","    if data_for_dbscan is None or data_for_dbscan.shape[0] == 0:\n","        print(f\"  No data for DBSCAN on {data_desc}. Skipping.\")\n","        df[f'dbscan_{data_desc.lower().replace(\" \",\"_\")}']=-1\n","        return df\n","\n","    eps_to_use = current_eps_val if current_eps_val is not None else DBSCAN_EPS_DEFAULT\n","    min_s_to_use = current_min_samples_val if current_min_samples_val is not None else DBSCAN_MIN_SAMPLES_DEFAULT\n","\n","    if ESTIMATE_DBSCAN_EPS and current_eps_val is None :\n","        k_est = min(K_FOR_EPS_ESTIMATION, data_for_dbscan.shape[0]-1); k_est=max(1,k_est)\n","        nn=NearestNeighbors(n_neighbors=k_est); nn.fit(data_for_dbscan); dists, _ = nn.kneighbors(data_for_dbscan)\n","        actual_k_for_dists = min(k_est, dists.shape[1])\n","        if actual_k_for_dists > 0:\n","            k_dists = dists[:,actual_k_for_dists-1]\n","            k_dists_sorted = np.sort(k_dists)\n","            plt.figure(figsize=(8,6)); plt.plot(k_dists_sorted); plt.title(f'{actual_k_for_dists}-Dist Graph for Eps ({data_desc})');\n","            plt.xlabel(\"Points sorted by distance\"); plt.ylabel(f\"{actual_k_for_dists}-th NN Distance (eps candidate)\"); plt.grid(True,alpha=0.3);\n","            eps_path=os.path.join(output_dir, f'dbscan_eps_est_{data_desc.lower().replace(\" \",\"_\")}.png'); plt.savefig(eps_path,dpi=300); plt.close();\n","            print(f\"  Saved k-dist graph: {eps_path}. PLEASE INSPECT THIS PLOT TO SET appropriate DBSCAN_EPS for {data_desc}.\")\n","            if len(k_dists_sorted)>10:\n","                sug_eps=np.percentile(k_dists_sorted,90);\n","                print(f\"  A percentile-based suggestion for eps for {data_desc} is: {sug_eps:.3f}. The script will use eps={eps_to_use} (default or passed).\")\n","        else:\n","            print(f\"  Could not determine k-distances for eps estimation for {data_desc}. Using eps={eps_to_use}\")\n","\n","    print(f\"  Running DBSCAN with eps={eps_to_use}, min_samples={min_s_to_use} on {data_desc}...\")\n","    db=DBSCAN(eps=eps_to_use,min_samples=min_s_to_use).fit(data_for_dbscan)\n","    clust_col=f'dbscan_{data_desc.lower().replace(\" \",\"_\")}'; df[clust_col]=db.labels_\n","    n_clust=len(set(db.labels_))-(1 if -1 in db.labels_ else 0); n_noise=list(db.labels_).count(-1)\n","    print(f\"  DBSCAN on {data_desc}: {n_clust} clusters, {n_noise} noise ({n_noise/len(df)*100:.2f}%).\")\n","\n","    if umap_emb is not None and 'umap_x_refined' in df.columns and 'umap_y_refined' in df.columns:\n","        plt.figure(figsize=(12,10));\n","        labels_unique_dbscan=sorted(df[clust_col].unique());\n","        n_actual_clusters = len([l for l in labels_unique_dbscan if l != -1])\n","        dbscan_cmap_obj = plt.cm.get_cmap('Spectral', n_actual_clusters if n_actual_clusters > 0 else 1)\n","        cdict = {}; cluster_idx = 0\n","        for lbl in labels_unique_dbscan:\n","            if lbl == -1: cdict[lbl] = (0.5, 0.5, 0.5, 1)\n","            else: cdict[lbl] = dbscan_cmap_obj(cluster_idx); cluster_idx += 1\n","        for k_val in labels_unique_dbscan:\n","            mask=(df[clust_col]==k_val); xy=umap_emb[mask]\n","            if xy.shape[0]>0:\n","                 plt.scatter(xy[:,0],xy[:,1], s=(20 if k_val!=-1 else 10), c=[cdict[k_val]],\n","                             marker=('o' if k_val!=-1 else 'x'), label=('Noise' if k_val == -1 else f'Cluster {k_val}'))\n","        plt.title(f'DBSCAN on {data_desc} (UMAP proj.)\\neps={eps_to_use:.3f}, min_s={min_s_to_use}');\n","        plt.xlabel('UMAP 1'); plt.ylabel('UMAP 2');\n","        plt.legend(title='DBSCAN Cluster',bbox_to_anchor=(1.05,1),loc='upper left',markerscale=1.5);\n","        plt.grid(True,alpha=0.3); plt.tight_layout(rect=[0,0,0.85,1]);\n","        plt.savefig(os.path.join(output_dir, f'dbscan_on_umap_{data_desc.lower().replace(\" \",\"_\")}.png'),dpi=300); plt.close();\n","        print(f\"  DBSCAN on {data_desc} plotted on UMAP.\")\n","    return df\n","\n","def run_gmm_and_plot(df, data_for_gmm, data_desc, output_dir, umap_embedding=None):\n","    \"\"\"Runs Gaussian Mixture Model clustering and plots results.\"\"\"\n","    print(f\"\\n--- Running Gaussian Mixture Model (GMM) on {data_desc} ---\")\n","    if data_for_gmm is None or data_for_gmm.shape[0] == 0:\n","        print(f\"  No data available for GMM on {data_desc}. Skipping.\")\n","        df[f'gmm_cluster_{data_desc.lower().replace(\" \", \"_\")}'] = -1\n","        df[f'gmm_prob_max_{data_desc.lower().replace(\" \", \"_\")}'] = np.nan\n","        return df\n","\n","    best_gmm = None; lowest_bic = np.inf\n","    print(f\"  Testing GMM with n_components in {list(GMM_N_COMPONENTS_RANGE)} using BIC...\")\n","    for n_components in GMM_N_COMPONENTS_RANGE:\n","        if n_components > data_for_gmm.shape[0]: continue\n","        gmm = GaussianMixture(n_components=n_components, covariance_type=GMM_COVARIANCE_TYPE, random_state=42, n_init=5)\n","        gmm.fit(data_for_gmm); bic = gmm.bic(data_for_gmm)\n","        print(f\"    GMM with {n_components} components: BIC = {bic:.2f}\")\n","        if bic < lowest_bic: lowest_bic = bic; best_gmm = gmm\n","\n","    if best_gmm is None:\n","        print(\"  GMM fitting failed. Skipping GMM.\"); df[f'gmm_cluster_{data_desc.lower().replace(\" \", \"_\")}'] = -1; df[f'gmm_prob_max_{data_desc.lower().replace(\" \", \"_\")}'] = np.nan\n","        return df\n","\n","    print(f\"  Best GMM found with {best_gmm.n_components} components (BIC={lowest_bic:.2f}).\")\n","    cluster_col_name = f'gmm_{data_desc.lower().replace(\" \", \"_\")}'; prob_col_name = f'gmm_prob_max_{data_desc.lower().replace(\" \", \"_\")}'\n","    df[cluster_col_name] = best_gmm.predict(data_for_gmm); df[prob_col_name] = np.max(best_gmm.predict_proba(data_for_gmm), axis=1)\n","\n","    if 'senescence_score_normalized' in df.columns:\n","        print(f\"  Mean senescence_score_normalized per GMM component (for {data_desc}):\\n{df.groupby(cluster_col_name)['senescence_score_normalized'].mean().sort_values()}\")\n","\n","    if umap_embedding is not None and 'umap_x_refined' in df.columns and 'umap_y_refined' in df.columns:\n","        plt.figure(figsize=(12, 10)); unique_gmm_labels = sorted(df[cluster_col_name].unique())\n","        gmm_palette = sns.color_palette(\"viridis\", n_colors=len(unique_gmm_labels))\n","        for i, label in enumerate(unique_gmm_labels):\n","            subset = df[df[cluster_col_name] == label]\n","            plt.scatter(subset['umap_x_refined'], subset['umap_y_refined'], label=f'GMM Comp. {label}', color=gmm_palette[i], s=15, alpha=0.7)\n","        plt.title(f'GMM ({best_gmm.n_components} comp.) on {data_desc} (UMAP proj.)', fontsize=14)\n","        plt.xlabel('UMAP 1'); plt.ylabel('UMAP 2'); plt.legend(title='GMM Component', bbox_to_anchor=(1.05, 1), loc='upper left')\n","        plt.grid(True, alpha=0.3); plt.tight_layout(rect=[0,0,0.85,1])\n","        plt.savefig(os.path.join(output_dir, f'gmm_on_umap_{data_desc.lower().replace(\" \", \"_\")}.png'), dpi=300); plt.close()\n","        print(f\"  GMM on {data_desc} results plotted on UMAP.\")\n","\n","        plt.figure(figsize=(12, 10)); scatter_gmm_prob = plt.scatter(df['umap_x_refined'], df['umap_y_refined'], c=df[prob_col_name], cmap='magma', s=15, alpha=0.7, vmin=0, vmax=1)\n","        plt.colorbar(scatter_gmm_prob, label='Max Probability of GMM Assignment')\n","        plt.title(f'GMM Max Assignment Probability on {data_desc} (UMAP proj.)', fontsize=14)\n","        plt.xlabel('UMAP 1'); plt.ylabel('UMAP 2'); plt.grid(True, alpha=0.3); plt.tight_layout()\n","        plt.savefig(os.path.join(output_dir, f'gmm_prob_on_umap_{data_desc.lower().replace(\" \", \"_\")}.png'), dpi=300); plt.close()\n","        print(f\"  GMM max probability on {data_desc} plotted on UMAP.\")\n","    return df\n","\n","def apply_rule_based_gating(df_main, rules, default_label, output_dir, umap_embedding=None):\n","    \"\"\"Applies a series of defined rules to classify cells. Operates on df_main.\"\"\"\n","    print(\"\\n--- Applying Rule-Based Gating ---\")\n","    # This column will store the specific rule label that a cell matches\n","    df_main['rule_based_classification_granular'] = default_label\n","\n","    all_rule_features = set()\n","    for rule in rules:\n","        for condition in rule['conditions']:\n","            all_rule_features.add(condition[0])\n","\n","    missing_features_in_df = [feat for feat in all_rule_features if feat not in df_main.columns]\n","    if missing_features_in_df:\n","        print(f\"  Error: The following features required by rules are missing from the DataFrame: {missing_features_in_df}. Skipping rule-based gating.\")\n","        df_main['rule_based_binary_status'] = 'Unknown_Due_To_Missing_Features' # Indicate error\n","        return df_main\n","\n","    for rule_idx, rule in enumerate(rules):\n","        print(f\"  Applying rule: {rule['name']}\")\n","        # Cells are eligible if they still have the default label for granular classification\n","        eligible_mask = (df_main['rule_based_classification_granular'] == default_label)\n","        if not eligible_mask.any():\n","            print(f\"    No cells eligible for rule '{rule['name']}' (all already classified by prior rules).\")\n","            continue\n","\n","        rule_condition_mask = pd.Series([True] * len(df_main), index=df_main.index)\n","        for feature, operator, value in rule['conditions']:\n","            if feature not in df_main.columns:\n","                print(f\"    Feature '{feature}' not found in DataFrame for rule '{rule['name']}'. Skipping this rule.\")\n","                rule_condition_mask[:] = False; break\n","            try:\n","                feature_series = pd.to_numeric(df_main[feature], errors='coerce')\n","                # Check if coercion introduced NaNs where the original wasn't NaN (means type issue)\n","                if feature_series.isnull().sum() > df_main[feature].isnull().sum():\n","                    print(f\"    Warning: Feature '{feature}' had values that could not be converted to numeric for rule '{rule['name']}'. These will not meet numeric conditions.\")\n","\n","                # Apply condition, NaNs in feature_series will result in False for comparisons\n","                if   operator == '>':  rule_condition_mask &= (feature_series > value)\n","                elif operator == '<':  rule_condition_mask &= (feature_series < value)\n","                elif operator == '>=': rule_condition_mask &= (feature_series >= value)\n","                elif operator == '<=': rule_condition_mask &= (feature_series <= value)\n","                elif operator == '==': rule_condition_mask &= (feature_series == value)\n","                elif operator == '!=': rule_condition_mask &= (feature_series != value)\n","                else:\n","                    print(f\"    Unknown operator '{operator}' in rule '{rule['name']}'. Skipping condition.\")\n","                    rule_condition_mask[:] = False; break\n","            except Exception as e:\n","                print(f\"    Error comparing feature '{feature}' in rule '{rule['name']}': {e}. Skipping condition.\")\n","                rule_condition_mask[:] = False; break\n","\n","        if not rule_condition_mask.all() and not rule_condition_mask.any() and isinstance(rule_condition_mask, pd.Series) and not rule_condition_mask.empty : # If mask became all False due to an issue\n","             # This check was a bit problematic, simplifying: if no cells meet the rule after conditions:\n","             pass # The cells_to_label_now check below will handle it.\n","\n","\n","        if rule_condition_mask.any():\n","            cells_to_label_now = eligible_mask & rule_condition_mask\n","            df_main.loc[cells_to_label_now, 'rule_based_classification_granular'] = rule['output_label']\n","            print(f\"    {cells_to_label_now.sum()} cells labeled as '{rule['output_label']}'.\")\n","        else:\n","            print(f\"    No cells met all conditions for rule '{rule['name']}' among the eligible ones.\")\n","\n","    print(f\"\\nGranular rule-based classification counts:\\n{df_main['rule_based_classification_granular'].value_counts()}\")\n","\n","    # Create the binary 'Senescent' / 'Non-senescent' column based on granular rules\n","    df_main['rule_based_binary_status'] = np.where(\n","        df_main['rule_based_classification_granular'] == default_label,\n","        'Non-senescent', # Or simply default_label if you prefer\n","        'Senescent'\n","    )\n","    print(f\"\\nBinary rule-based classification counts:\\n{df_main['rule_based_binary_status'].value_counts()}\")\n","\n","\n","    # Plot granular rule-based classification\n","    if umap_embedding is not None and 'umap_x_refined' in df_main.columns and 'umap_y_refined' in df_main.columns:\n","        plt.figure(figsize=(12, 10)); unique_granular_labels = sorted(df_main['rule_based_classification_granular'].unique())\n","        if len(unique_granular_labels) > 0:\n","            granular_palette = sns.color_palette(\"Paired\", n_colors=max(10, len(unique_granular_labels)))\n","            for i, label in enumerate(unique_granular_labels):\n","                subset = df_main[df_main['rule_based_classification_granular'] == label]\n","                plt.scatter(subset['umap_x_refined'], subset['umap_y_refined'], label=label, color=granular_palette[i % len(granular_palette)], s=15, alpha=0.7)\n","            plt.title('Rule-Based Gating (Granular Labels - UMAP proj.)', fontsize=14)\n","            plt.xlabel('UMAP 1'); plt.ylabel('UMAP 2'); plt.legend(title='Rule-Based Class (Granular)', bbox_to_anchor=(1.05, 1), loc='upper left')\n","            plt.grid(True, alpha=0.3); plt.tight_layout(rect=[0,0,0.80,1]) # Adjusted rect for potentially longer legend\n","            plt.savefig(os.path.join(output_dir, 'rule_based_gating_granular_on_umap.png'), dpi=300); plt.close()\n","            print(\"  Granular rule-based gating results plotted on UMAP.\")\n","\n","        # Plot binary rule-based classification\n","        plt.figure(figsize=(12, 10)); unique_binary_labels = sorted(df_main['rule_based_binary_status'].unique())\n","        binary_palette_map = {'Senescent': 'red', 'Non-senescent': 'blue', default_label: 'blue'} # Ensure default maps to non-senescent color\n","        # Add any other specific colors if 'Unknown_Due_To_Missing_Features' occurs\n","        if 'Unknown_Due_To_Missing_Features' in unique_binary_labels: binary_palette_map['Unknown_Due_To_Missing_Features'] = 'grey'\n","\n","\n","        for label in unique_binary_labels:\n","            subset = df_main[df_main['rule_based_binary_status'] == label]\n","            plt.scatter(subset['umap_x_refined'], subset['umap_y_refined'], label=label, color=binary_palette_map.get(label, 'grey'), s=15, alpha=0.7)\n","        plt.title('Rule-Based Gating (Binary Status - UMAP proj.)', fontsize=14)\n","        plt.xlabel('UMAP 1'); plt.ylabel('UMAP 2'); plt.legend(title='Rule-Based Status (Binary)', bbox_to_anchor=(1.05, 1), loc='upper left')\n","        plt.grid(True, alpha=0.3); plt.tight_layout(rect=[0,0,0.85,1])\n","        plt.savefig(os.path.join(output_dir, 'rule_based_gating_binary_on_umap.png'), dpi=300); plt.close()\n","        print(\"  Binary rule-based gating results plotted on UMAP.\")\n","\n","    return df_main\n","\n","\n","def main_exploratory_analysis():\n","    \"\"\"Main function to run exploratory analysis.\"\"\"\n","    if not os.path.exists(EXPLORATORY_OUTPUT_DIR):\n","        os.makedirs(EXPLORATORY_OUTPUT_DIR)\n","        print(f\"Created output directory: {EXPLORATORY_OUTPUT_DIR}\")\n","\n","    df = load_data(INPUT_REFINED_CSV_PATH)\n","    if df is None: return\n","\n","    # scaled_features are for ML algos, feature_names_used_for_scaling are their names\n","    scaled_features, feature_names_used_for_scaling = preprocess_features_for_ml(df, FEATURES_FOR_ANALYSIS, AREA_FEATURES_TO_LOG)\n","\n","    if scaled_features is None:\n","        print(\"Scaled feature preprocessing failed. Some ML-based analyses might be skipped or fail.\")\n","\n","    umap_embedding_for_plotting = None\n","    if 'umap_x_refined' in df.columns and 'umap_y_refined' in df.columns and df['umap_x_refined'].notna().all():\n","        print(\"\\nUsing existing UMAP coordinates from input CSV for visualizations.\")\n","        umap_embedding_for_plotting = df[['umap_x_refined', 'umap_y_refined']].values\n","    elif scaled_features is not None:\n","        print(\"\\nRecomputing UMAP for visualization...\")\n","        try:\n","            reducer = umap.UMAP(n_neighbors=15, min_dist=0.1, random_state=42, n_components=2)\n","            embedding = reducer.fit_transform(scaled_features)\n","            df['umap_x_refined'] = embedding[:, 0]; df['umap_y_refined'] = embedding[:, 1]\n","            umap_embedding_for_plotting = df[['umap_x_refined', 'umap_y_refined']].values\n","            print(\"  UMAP recomputed.\")\n","        except Exception as e: print(f\"  Error recomputing UMAP: {e}.\")\n","    else: print(\"\\nSkipping UMAP computation as scaled features are unavailable.\")\n","\n","    if scaled_features is not None and feature_names_used_for_scaling is not None:\n","        df = compute_and_plot_diffusion_map(df, scaled_features, feature_names_used_for_scaling, EXPLORATORY_OUTPUT_DIR)\n","\n","        # DBSCAN on Scaled Features - User needs to set DBSCAN_EPS_SCALED_FEATURES\n","        DBSCAN_EPS_SCALED_FEATURES = 2.3 # From your previous successful run\n","        DBSCAN_MIN_SAMPLES_SCALED_FEATURES = 10\n","        print(f\"\\nNOTE: For DBSCAN on Scaled Features, using DBSCAN_EPS = {DBSCAN_EPS_SCALED_FEATURES}, MIN_SAMPLES = {DBSCAN_MIN_SAMPLES_SCALED_FEATURES}\")\n","        df = run_dbscan_and_plot(df, scaled_features, \"Scaled_Features\", EXPLORATORY_OUTPUT_DIR,\n","                                 umap_emb=umap_embedding_for_plotting,\n","                                 current_eps_val=DBSCAN_EPS_SCALED_FEATURES,\n","                                 current_min_samples_val=DBSCAN_MIN_SAMPLES_SCALED_FEATURES)\n","\n","        df = run_gmm_and_plot(df, scaled_features, \"Scaled_Features\", EXPLORATORY_OUTPUT_DIR, umap_embedding=umap_embedding_for_plotting)\n","\n","        if RUN_DBSCAN_ON_DIFFMAP and SCANPY_AVAILABLE:\n","            dc_cols = [f'dc_{i+1}' for i in range(N_DCS_FOR_DBSCAN) if f'dc_{i+1}' in df.columns and df[f'dc_{i+1}'].notna().any()]\n","            if dc_cols:\n","                data_dc = df[dc_cols].values\n","                DBSCAN_EPS_DCS = 0.01 # From your previous successful run\n","                DBSCAN_MIN_SAMPLES_DCS = 10\n","                print(f\"\\nNOTE: For DBSCAN on Top DCs, using DBSCAN_EPS = {DBSCAN_EPS_DCS}, MIN_SAMPLES = {DBSCAN_MIN_SAMPLES_DCS}\")\n","                df = run_dbscan_and_plot(df, data_dc, f\"Top_{len(dc_cols)}_DCs\", EXPLORATORY_OUTPUT_DIR,\n","                                         umap_emb=umap_embedding_for_plotting,\n","                                         current_eps_val=DBSCAN_EPS_DCS,\n","                                         current_min_samples_val=DBSCAN_MIN_SAMPLES_DCS)\n","            else: print(f\"\\nSkipping DBSCAN on DCs: Not enough valid DC columns.\")\n","\n","        global RUN_GMM_ON_DIFFMAP, N_DCS_FOR_GMM\n","        if RUN_GMM_ON_DIFFMAP and SCANPY_AVAILABLE:\n","            dc_cols_gmm = [f'dc_{i+1}' for i in range(N_DCS_FOR_GMM) if f'dc_{i+1}' in df.columns and df[f'dc_{i+1}'].notna().any()]\n","            if dc_cols_gmm:\n","                data_dc_gmm = df[dc_cols_gmm].values\n","                df = run_gmm_and_plot(df, data_dc_gmm, f\"Top_{len(dc_cols_gmm)}_DCs\", EXPLORATORY_OUTPUT_DIR, umap_embedding=umap_embedding_for_plotting)\n","            else: print(f\"\\nSkipping GMM on DCs: Not enough valid DC columns.\")\n","\n","    # Apply rule-based gating using the main df.\n","    # The 'df' passed here is the one that has been progressively updated.\n","    df = apply_rule_based_gating(df, RULE_BASED_GATES, RULE_BASED_DEFAULT_LABEL, EXPLORATORY_OUTPUT_DIR, umap_embedding=umap_embedding_for_plotting)\n","\n","    exploratory_csv_path = os.path.join(EXPLORATORY_OUTPUT_DIR, 'exploratory_analysis_results_v5_rules.csv') # Incremented output filename\n","    df.to_csv(exploratory_csv_path, index=False)\n","    print(f\"\\nExploratory analysis results saved to: {exploratory_csv_path}\")\n","    print(\"\\nExploratory analysis script finished.\")\n","\n","RUN_GMM_ON_DIFFMAP = True\n","N_DCS_FOR_GMM = 3\n","\n","if __name__ == '__main__':\n","    main_exploratory_analysis()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A95uvmFC52x8","executionInfo":{"status":"ok","timestamp":1747211247008,"user_tz":-120,"elapsed":27832,"user":{"displayName":"Guido Putignano","userId":"13974663347531370398"}},"outputId":"fab69574-0911-44a9-c1ca-b36d52fa05bf"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Created output directory: /content/drive/MyDrive/knowledge/University/Master/Thesis/Analysis/flow3-x20/Exploratory_Analysis_V5_rules\n","Loading refined data from /content/drive/MyDrive/knowledge/University/Master/Thesis/Analysis/flow3-x20/Senescence_Refined_V5_DiffMap/cell_classification_results_refined.csv...\n","Successfully loaded 2472 cells.\n","\n","Preprocessing features for ML. Selected: ['cell_area', 'cell_perimeter', 'cell_eccentricity', 'cell_circularity', 'cell_aspect_ratio', 'avg_nucleus_area', 'max_nucleus_area', 'avg_nucleus_eccentricity', 'nucleus_area_std', 'nucleus_displacement', 'nucleus_to_cell_area_ratio', 'nuclear_enlargement', 'cell_enlargement']\n","  Log-transformed for scaling: cell_area\n","  Log-transformed for scaling: avg_nucleus_area\n","  Log-transformed for scaling: max_nucleus_area\n","  Log-transformed for scaling: cell_perimeter\n","  Features standardized for ML algorithms.\n","\n","Using existing UMAP coordinates from input CSV for visualizations.\n","\n","--- Computing Diffusion Map ---\n","  Computing neighbors (k=15)...\n","  Running sc.tl.diffmap...\n","  Added 9 DCs to DataFrame.\n","  DiffMap pair plots for top 3 DCs saved.\n","\n","NOTE: For DBSCAN on Scaled Features, using DBSCAN_EPS = 2.3, MIN_SAMPLES = 10\n","\n","--- Running DBSCAN on Scaled_Features ---\n","  Running DBSCAN with eps=2.3, min_samples=10 on Scaled_Features...\n","  DBSCAN on Scaled_Features: 1 clusters, 137 noise (5.54%).\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-23-e428a6fa0497>:225: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n","  dbscan_cmap_obj = plt.cm.get_cmap('Spectral', n_actual_clusters if n_actual_clusters > 0 else 1)\n"]},{"output_type":"stream","name":"stdout","text":["  DBSCAN on Scaled_Features plotted on UMAP.\n","\n","--- Running Gaussian Mixture Model (GMM) on Scaled_Features ---\n","  Testing GMM with n_components in [2, 3, 4] using BIC...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n","  # that has no feature names.\n","/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n","  # that has no feature names.\n","/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n","  # that has no feature names.\n"]},{"output_type":"stream","name":"stdout","text":["    GMM with 2 components: BIC = -11876.19\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n","  # that has no feature names.\n","/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n","  # that has no feature names.\n"]},{"output_type":"stream","name":"stdout","text":["    GMM with 3 components: BIC = -20370.16\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n","  # that has no feature names.\n","/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n","  # that has no feature names.\n","/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n","  # that has no feature names.\n"]},{"output_type":"stream","name":"stdout","text":["    GMM with 4 components: BIC = -26836.71\n","  Best GMM found with 4 components (BIC=-26836.71).\n","  Mean senescence_score_normalized per GMM component (for Scaled_Features):\n","gmm_scaled_features\n","1    0.316948\n","0    0.365966\n","3    0.500682\n","2    0.500958\n","Name: senescence_score_normalized, dtype: float64\n","  GMM on Scaled_Features results plotted on UMAP.\n","  GMM max probability on Scaled_Features plotted on UMAP.\n","\n","NOTE: For DBSCAN on Top DCs, using DBSCAN_EPS = 0.01, MIN_SAMPLES = 10\n","\n","--- Running DBSCAN on Top_3_DCs ---\n","  Running DBSCAN with eps=0.01, min_samples=10 on Top_3_DCs...\n","  DBSCAN on Top_3_DCs: 2 clusters, 42 noise (1.70%).\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-23-e428a6fa0497>:225: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n","  dbscan_cmap_obj = plt.cm.get_cmap('Spectral', n_actual_clusters if n_actual_clusters > 0 else 1)\n"]},{"output_type":"stream","name":"stdout","text":["  DBSCAN on Top_3_DCs plotted on UMAP.\n","\n","--- Running Gaussian Mixture Model (GMM) on Top_3_DCs ---\n","  Testing GMM with n_components in [2, 3, 4] using BIC...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n","  # that has no feature names.\n","/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n","  # that has no feature names.\n","/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n","  # that has no feature names.\n"]},{"output_type":"stream","name":"stdout","text":["    GMM with 2 components: BIC = -42744.54\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n","  # that has no feature names.\n","/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n","  # that has no feature names.\n"]},{"output_type":"stream","name":"stdout","text":["    GMM with 3 components: BIC = -43790.09\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n","  # that has no feature names.\n","/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n","  # that has no feature names.\n","/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n","  # that has no feature names.\n"]},{"output_type":"stream","name":"stdout","text":["    GMM with 4 components: BIC = -44590.14\n","  Best GMM found with 4 components (BIC=-44590.14).\n","  Mean senescence_score_normalized per GMM component (for Top_3_DCs):\n","gmm_top_3_dcs\n","0    0.319583\n","1    0.398703\n","2    0.427525\n","3    0.543944\n","Name: senescence_score_normalized, dtype: float64\n","  GMM on Top_3_DCs results plotted on UMAP.\n","  GMM max probability on Top_3_DCs plotted on UMAP.\n","\n","--- Applying Rule-Based Gating ---\n","  Applying rule: Polynucleated\n","    225 cells labeled as 'Rule_Sen_Poly'.\n","  Applying rule: Very_Large_Cell\n","    307 cells labeled as 'Rule_Sen_VeryLarge'.\n","  Applying rule: Low_Circularity\n","    3 cells labeled as 'Rule_Sen_LowCirc'.\n","  Applying rule: Low_NucToCellRatio\n","    103 cells labeled as 'Rule_Sen_LowNucRatio'.\n","  Applying rule: High_Score_Not_Otherwise_Caught\n","    0 cells labeled as 'Rule_Sen_HighScore'.\n","\n","Granular rule-based classification counts:\n","rule_based_classification_granular\n","Rule_NonSenescent       1834\n","Rule_Sen_VeryLarge       307\n","Rule_Sen_Poly            225\n","Rule_Sen_LowNucRatio     103\n","Rule_Sen_LowCirc           3\n","Name: count, dtype: int64\n","\n","Binary rule-based classification counts:\n","rule_based_binary_status\n","Non-senescent    1834\n","Senescent         638\n","Name: count, dtype: int64\n","  Granular rule-based gating results plotted on UMAP.\n","  Binary rule-based gating results plotted on UMAP.\n","\n","Exploratory analysis results saved to: /content/drive/MyDrive/knowledge/University/Master/Thesis/Analysis/flow3-x20/Exploratory_Analysis_V5_rules/exploratory_analysis_results_v5_rules.csv\n","\n","Exploratory analysis script finished.\n"]}]},{"cell_type":"code","source":["import os\n","import re\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as mpatches\n","import seaborn as sns\n","from skimage import io, measure, segmentation # Added segmentation\n","import cv2 # Added cv2\n","from scipy import ndimage # Added ndimage\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.cluster import DBSCAN\n","from sklearn.mixture import GaussianMixture\n","from sklearn.neighbors import NearestNeighbors\n","import umap\n","\n","try:\n","    import scanpy as sc\n","    SCANPY_AVAILABLE = True\n","except ImportError:\n","    print(\"Scanpy library not found. Diffusion map functionality will be skipped.\")\n","    SCANPY_AVAILABLE = False\n","\n","# --- Configuration & Parameters ---\n","INPUT_REFINED_CSV_PATH = \"/content/drive/MyDrive/knowledge/University/Master/Thesis/Analysis/flow3-x20/Senescence_Refined_V5_DiffMap/cell_classification_results_refined.csv\"\n","EXPLORATORY_OUTPUT_DIR = \"/content/drive/MyDrive/knowledge/University/Master/Thesis/Analysis/flow3-x20/Exploratory_Analysis_V5_rules_mask_viz\" # Incremented version\n","\n","# !! UPDATE THESE PATHS to your original mask image directories !!\n","CELL_MASK_DIR = \"/content/drive/MyDrive/knowledge/University/Master/Thesis/Segmented/flow3-x20/Cell_merged_conservative\"\n","NUCLEI_MASK_DIR = \"/content/drive/MyDrive/knowledge/University/Master/Thesis/Segmented/flow3-x20/Nuclei\"\n","MASK_VISUALIZATION_SUBDIR_RULES = \"mask_overlays_rule_based\"\n","\n","\n","FEATURES_FOR_ANALYSIS = [\n","    'cell_area', 'cell_perimeter', 'cell_eccentricity', 'cell_circularity',\n","    'cell_aspect_ratio', 'avg_nucleus_area', 'max_nucleus_area',\n","    'avg_nucleus_eccentricity', 'nucleus_area_std', 'nucleus_displacement',\n","    'nucleus_to_cell_area_ratio',\n","    'nuclear_enlargement', 'cell_enlargement'\n","]\n","AREA_FEATURES_TO_LOG = ['cell_area', 'avg_nucleus_area', 'max_nucleus_area', 'cell_perimeter']\n","\n","N_DIFFUSION_COMPONENTS = 10\n","N_DCS_TO_PLOT = 3\n","N_NEIGHBORS_FOR_SCANPY = 15\n","\n","DBSCAN_EPS_DEFAULT = 0.75\n","DBSCAN_MIN_SAMPLES_DEFAULT = 10\n","ESTIMATE_DBSCAN_EPS = True\n","K_FOR_EPS_ESTIMATION = 10\n","RUN_DBSCAN_ON_DIFFMAP = True\n","N_DCS_FOR_DBSCAN = 3\n","\n","GMM_N_COMPONENTS_RANGE = range(2, 5)\n","GMM_COVARIANCE_TYPE = 'full'\n","\n","RULE_BASED_GATES = [\n","    {   'name': 'Polynucleated',\n","        'conditions': [('nuclei_count', '>', 1)],\n","        'output_label': 'Rule_Sen_Poly' },\n","    {   'name': 'Very_Large_Cell',\n","        'conditions': [('cell_area', '>', 5000)],\n","        'output_label': 'Rule_Sen_VeryLarge' },\n","    {   'name': 'Low_Circularity',\n","        'conditions': [('cell_circularity', '<', 0.2)],\n","        'output_label': 'Rule_Sen_LowCirc' },\n","    {   'name': 'Low_NucToCellRatio',\n","        'conditions': [('nucleus_to_cell_area_ratio', '<', 0.1)],\n","        'output_label': 'Rule_Sen_LowNucRatio' },\n","    {   'name': 'High_Score_Not_Otherwise_Caught',\n","        'conditions': [('senescence_score_normalized', '>', 0.75)],\n","        'output_label': 'Rule_Sen_HighScore' }\n","]\n","RULE_BASED_DEFAULT_LABEL = 'Rule_NonSenescent'\n","\n","# --- Helper Functions ---\n","def extract_sample_id(filename):\n","    \"\"\"Extracts sample ID from filename (adapted from user's original notebook).\"\"\"\n","    base_name = os.path.splitext(filename)[0]\n","    if base_name.startswith('denoised_'):\n","        base_name = base_name[len('denoised_'):]\n","    pattern = re.compile(r'([\\d\\.]+Pa_[^_]+_[^_]+_[^_]+_[^_]+_[^_]+_seq\\d+)')\n","    match = pattern.search(base_name)\n","    if match:\n","        return match.group(1)\n","    parts = base_name.split('_')\n","    for i, part in enumerate(parts):\n","        if part.startswith('seq') and i >= 2:\n","            return '_'.join(parts[:i+1])\n","    common_prefix = \"_\".join(filename.split('_')[:6])\n","    return common_prefix if 'seq' in common_prefix else os.path.splitext(os.path.basename(filename))[0]\n","\n","def load_image_as_labeled_mask(filepath):\n","    \"\"\"Loads a mask image, ensuring it's a labeled integer mask.\"\"\"\n","    print(f\"    Loading mask: {os.path.basename(filepath)}\")\n","    try:\n","        img = io.imread(filepath)\n","        if img.ndim > 2: # Handle multi-channel\n","            if img.shape[-1] == 3: img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n","            elif img.shape[-1] == 4: img = cv2.cvtColor(img, cv2.COLOR_RGBA2GRAY)\n","            else: img = img[..., 0]\n","\n","        if img.dtype.kind in 'iu' and np.max(img) > 1: # Already labeled integer mask\n","            return img.astype(np.uint16)\n","\n","        # If binary or float, threshold and label\n","        if img.dtype.kind == 'f': img = (img > 0.5).astype(np.uint8)\n","        elif np.max(img) == 1: img = img.astype(np.uint8)\n","\n","        if np.max(img) <=1 : # Binary after potential conversion\n","            labeled_img, num_features = ndimage.label(img)\n","            print(f\"    Labeled binary mask {os.path.basename(filepath)}, found {num_features} features.\")\n","            return labeled_img.astype(np.uint16)\n","\n","        return img.astype(np.uint16) # Assume uint8 with labels otherwise\n","    except Exception as e:\n","        print(f\"    Error loading image {filepath}: {str(e)}\"); return None\n","\n","def load_data(csv_path):\n","    \"\"\"Loads the refined data and derives sample_id if needed.\"\"\"\n","    print(f\"Loading refined data from {csv_path}...\")\n","    try:\n","        df = pd.read_csv(csv_path)\n","        print(f\"Successfully loaded {len(df)} cells.\")\n","\n","        if 'cell_id' in df.columns:\n","            df['derived_sample_id'] = df['cell_id'].apply(lambda x: '_'.join(x.split('_')[:-1]))\n","            print(\"  Derived 'derived_sample_id' from 'cell_id' for mask matching.\")\n","        else:\n","            print(\"Error: 'cell_id' column missing. Cannot derive sample IDs for mask matching.\")\n","            return None\n","\n","        essential_cols = ['senescence_score_normalized', 'nuclei_count', 'cell_area',\n","                          'cell_circularity', 'nucleus_to_cell_area_ratio']\n","        for col_check in essential_cols:\n","            if col_check not in df.columns:\n","                print(f\"Warning: Essential column '{col_check}' for rules/scoring not found.\")\n","        return df\n","    except FileNotFoundError:\n","        print(f\"Error: CSV file not found at {csv_path}\"); return None\n","\n","def preprocess_features_for_ml(df, feature_columns, log_transform_cols):\n","    \"\"\"Prepares features specifically for ML algorithms (scaling).\"\"\"\n","    print(f\"\\nPreprocessing features for ML. Selected: {feature_columns}\")\n","    actual_features_for_ml = [col for col in feature_columns if col in df.columns]\n","    if not actual_features_for_ml: return None, None\n","    features_for_scaling_df = df[actual_features_for_ml].copy()\n","    for col in log_transform_cols:\n","        if col in features_for_scaling_df.columns:\n","            features_for_scaling_df[col] = np.log1p(features_for_scaling_df[col])\n","            print(f\"  Log-transformed for scaling: {col}\")\n","    if features_for_scaling_df.isnull().sum().any():\n","        features_for_scaling_df = features_for_scaling_df.fillna(features_for_scaling_df.mean())\n","    cols_to_drop_scaled = features_for_scaling_df.columns[features_for_scaling_df.isna().all()].tolist()\n","    if cols_to_drop_scaled:\n","        features_for_scaling_df = features_for_scaling_df.drop(columns=cols_to_drop_scaled)\n","        actual_features_for_ml = [f for f in actual_features_for_ml if f not in cols_to_drop_scaled]\n","    if features_for_scaling_df.empty or not actual_features_for_ml: return None, None\n","    scaler = StandardScaler(); features_scaled = scaler.fit_transform(features_for_scaling_df)\n","    print(\"  Features standardized for ML algorithms.\")\n","    return features_scaled, actual_features_for_ml\n","\n","def compute_and_plot_diffusion_map(df, scaled_features, feature_names_used, output_dir):\n","    \"\"\"Computes and plots diffusion map.\"\"\"\n","    if not SCANPY_AVAILABLE: print(\"Skipping diffusion map: Scanpy not available.\"); return df\n","    print(\"\\n--- Computing Diffusion Map ---\")\n","    if scaled_features is None or scaled_features.shape[0] == 0 : print(\"  No scaled features for Diffusion Map. Skipping.\"); return df\n","    adata = sc.AnnData(scaled_features, var=pd.DataFrame(index=feature_names_used))\n","    adata.obs_names = df.index.astype(str)\n","    if 'senescence_score_normalized' in df.columns: adata.obs['senescence_score_normalized'] = df['senescence_score_normalized'].values\n","    if 'cell_type_final' in df.columns: adata.obs['cell_type_final'] = df['cell_type_final'].astype('category').values\n","    actual_n_neighbors = min(N_NEIGHBORS_FOR_SCANPY, adata.n_obs - 1)\n","    if actual_n_neighbors < 2: print(f\"  Not enough samples for Scanpy neighbors. Skipping.\"); return df\n","    print(f\"  Computing neighbors (k={actual_n_neighbors})...\"); sc.pp.neighbors(adata, n_neighbors=actual_n_neighbors, use_rep='X')\n","    print(\"  Running sc.tl.diffmap...\"); sc.tl.diffmap(adata, n_comps=N_DIFFUSION_COMPONENTS)\n","    if 'X_diffmap' in adata.obsm:\n","        num_dc = min(N_DIFFUSION_COMPONENTS, adata.obsm['X_diffmap'].shape[1] - 1)\n","        for i in range(num_dc): df[f'dc_{i+1}'] = adata.obsm['X_diffmap'][:, i+1]\n","        print(f\"  Added {num_dc} DCs to DataFrame.\")\n","        pairs = [(f'dc_{i}', f'dc_{j}') for i in range(1, N_DCS_TO_PLOT + 1) for j in range(i + 1, N_DCS_TO_PLOT + 1) if f'dc_{i}' in df.columns and f'dc_{j}' in df.columns]\n","        for dcx, dcy in pairs:\n","            if df[dcx].notna().any() and df[dcy].notna().any():\n","                if 'senescence_score_normalized' in df.columns and df['senescence_score_normalized'].notna().any():\n","                    plt.figure(figsize=(10,8)); plt.scatter(df[dcx], df[dcy], c=df['senescence_score_normalized'], cmap='viridis', s=12, alpha=0.7); plt.colorbar(label='Norm. Senescence Score')\n","                    plt.title(f'DiffMap ({dcx} vs {dcy}) by Score'); plt.xlabel(dcx.upper()); plt.ylabel(dcy.upper()); plt.grid(True,alpha=0.3); plt.savefig(os.path.join(output_dir, f'diffmap_{dcx}_{dcy}_by_score.png'),dpi=300,bbox_inches='tight'); plt.close()\n","                if 'cell_type_final' in df.columns:\n","                    plt.figure(figsize=(10,8)); types=df['cell_type_final'].unique(); pal={t:('red' if t=='Senescent' else ('blue' if t=='Non-senescent' else 'grey')) for t in types}\n","                    for ct,col in pal.items(): subset=df[df['cell_type_final']==ct]; plt.scatter(subset[dcx],subset[dcy],label=ct,color=col,s=12,alpha=0.7)\n","                    plt.title(f'DiffMap ({dcx} vs {dcy}) by Prev. Classif.'); plt.xlabel(dcx.upper()); plt.ylabel(dcy.upper());\n","                    if pal: plt.legend(title='Previous Final Cell Type'); plt.grid(True,alpha=0.3); plt.savefig(os.path.join(output_dir, f'diffmap_{dcx}_{dcy}_by_prev_type.png'),dpi=300,bbox_inches='tight'); plt.close()\n","        print(f\"  DiffMap pair plots for top {N_DCS_TO_PLOT} DCs saved.\")\n","    else: print(\"  Error: 'X_diffmap' not found.\")\n","    return df\n","\n","def run_dbscan_and_plot(df, data_for_dbscan, data_desc, output_dir, umap_emb=None, current_eps_val=None, current_min_samples_val=None):\n","    \"\"\"Runs DBSCAN and plots results. Uses specific eps and min_samples if provided.\"\"\"\n","    print(f\"\\n--- Running DBSCAN on {data_desc} ---\")\n","    if data_for_dbscan is None or data_for_dbscan.shape[0] == 0:\n","        print(f\"  No data for DBSCAN on {data_desc}. Skipping.\")\n","        df[f'dbscan_{data_desc.lower().replace(\" \",\"_\")}']=-1\n","        return df\n","\n","    eps_to_use = current_eps_val if current_eps_val is not None else DBSCAN_EPS_DEFAULT\n","    min_s_to_use = current_min_samples_val if current_min_samples_val is not None else DBSCAN_MIN_SAMPLES_DEFAULT\n","\n","    if ESTIMATE_DBSCAN_EPS and current_eps_val is None :\n","        k_est = min(K_FOR_EPS_ESTIMATION, data_for_dbscan.shape[0]-1); k_est=max(1,k_est)\n","        nn=NearestNeighbors(n_neighbors=k_est); nn.fit(data_for_dbscan); dists, _ = nn.kneighbors(data_for_dbscan)\n","        actual_k_for_dists = min(k_est, dists.shape[1])\n","        if actual_k_for_dists > 0:\n","            k_dists = dists[:,actual_k_for_dists-1]\n","            k_dists_sorted = np.sort(k_dists)\n","            plt.figure(figsize=(8,6)); plt.plot(k_dists_sorted); plt.title(f'{actual_k_for_dists}-Dist Graph for Eps ({data_desc})');\n","            plt.xlabel(\"Points sorted by distance\"); plt.ylabel(f\"{actual_k_for_dists}-th NN Distance (eps candidate)\"); plt.grid(True,alpha=0.3);\n","            eps_path=os.path.join(output_dir, f'dbscan_eps_est_{data_desc.lower().replace(\" \",\"_\")}.png'); plt.savefig(eps_path,dpi=300); plt.close();\n","            print(f\"  Saved k-dist graph: {eps_path}. PLEASE INSPECT THIS PLOT TO SET appropriate DBSCAN_EPS for {data_desc}.\")\n","            if len(k_dists_sorted)>10:\n","                sug_eps=np.percentile(k_dists_sorted,90);\n","                print(f\"  A percentile-based suggestion for eps for {data_desc} is: {sug_eps:.3f}. The script will use eps={eps_to_use} (default or passed).\")\n","        else:\n","            print(f\"  Could not determine k-distances for eps estimation for {data_desc}. Using eps={eps_to_use}\")\n","\n","    print(f\"  Running DBSCAN with eps={eps_to_use}, min_samples={min_s_to_use} on {data_desc}...\")\n","    db=DBSCAN(eps=eps_to_use,min_samples=min_s_to_use).fit(data_for_dbscan)\n","    clust_col=f'dbscan_{data_desc.lower().replace(\" \",\"_\")}'; df[clust_col]=db.labels_\n","    n_clust=len(set(db.labels_))-(1 if -1 in db.labels_ else 0); n_noise=list(db.labels_).count(-1)\n","    print(f\"  DBSCAN on {data_desc}: {n_clust} clusters, {n_noise} noise ({n_noise/len(df)*100:.2f}%).\")\n","\n","    if umap_emb is not None and 'umap_x_refined' in df.columns and 'umap_y_refined' in df.columns:\n","        plt.figure(figsize=(12,10))\n","        labels_unique_dbscan=sorted(df[clust_col].unique())\n","        n_actual_clusters = len([l for l in labels_unique_dbscan if l != -1])\n","        # Ensure cmap is correctly called\n","        if n_actual_clusters > 0:\n","            dbscan_cmap_obj = plt.cm.get_cmap('Spectral', n_actual_clusters)\n","        else: # Handle case with no actual clusters (only noise)\n","            dbscan_cmap_obj = plt.cm.get_cmap('Spectral', 1)\n","\n","        cdict = {}\n","        cluster_idx = 0\n","        for lbl in labels_unique_dbscan:\n","            if lbl == -1:\n","                cdict[lbl] = (0.5, 0.5, 0.5, 1) # Grey for noise\n","            else:\n","                cdict[lbl] = dbscan_cmap_obj(cluster_idx)\n","                cluster_idx += 1\n","\n","        for k_val in labels_unique_dbscan:\n","            mask=(df[clust_col]==k_val)\n","            xy=umap_emb[mask]\n","            if xy.shape[0]>0:\n","                 # Corrected indentation for the plt.scatter call\n","                 plt.scatter(xy[:,0],xy[:,1],\n","                             s=(20 if k_val!=-1 else 10),\n","                             c=[cdict[k_val]],\n","                             marker=('o' if k_val!=-1 else 'x'),\n","                             label=('Noise' if k_val == -1 else f'Cluster {k_val}'))\n","        plt.title(f'DBSCAN on {data_desc} (UMAP proj.)\\neps={eps_to_use:.3f}, min_s={min_s_to_use}')\n","        plt.xlabel('UMAP 1'); plt.ylabel('UMAP 2')\n","        plt.legend(title='DBSCAN Cluster',bbox_to_anchor=(1.05,1),loc='upper left',markerscale=1.5)\n","        plt.grid(True,alpha=0.3); plt.tight_layout(rect=[0,0,0.85,1])\n","        plt.savefig(os.path.join(output_dir, f'dbscan_on_umap_{data_desc.lower().replace(\" \",\"_\")}.png'),dpi=300); plt.close()\n","        print(f\"  DBSCAN on {data_desc} plotted on UMAP.\")\n","    return df\n","\n","def run_gmm_and_plot(df, data_for_gmm, data_desc, output_dir, umap_embedding=None):\n","    \"\"\"Runs GMM and plots results.\"\"\"\n","    print(f\"\\n--- Running GMM on {data_desc} ---\")\n","    if data_for_gmm is None: df[f'gmm_cluster_{data_desc.lower().replace(\" \",\"_\")}']=-1; df[f'gmm_prob_max_{data_desc.lower().replace(\" \",\"_\")}']=np.nan; return df\n","    best_gmm=None; lowest_bic=np.inf\n","    for n_comp in GMM_N_COMPONENTS_RANGE:\n","        if n_comp > data_for_gmm.shape[0]: continue\n","        gmm=GaussianMixture(n_components=n_comp,covariance_type=GMM_COVARIANCE_TYPE,random_state=42,n_init=5).fit(data_for_gmm); bic=gmm.bic(data_for_gmm); print(f\"    GMM {n_comp} comps: BIC={bic:.2f}\")\n","        if bic<lowest_bic: lowest_bic=bic; best_gmm=gmm\n","    if best_gmm is None: df[f'gmm_cluster_{data_desc.lower().replace(\" \",\"_\")}']=-1; df[f'gmm_prob_max_{data_desc.lower().replace(\" \",\"_\")}']=np.nan; return df\n","    print(f\"  Best GMM: {best_gmm.n_components} components (BIC={lowest_bic:.2f}).\")\n","    clust_col,prob_col = f'gmm_{data_desc.lower().replace(\" \",\"_\")}',f'gmm_prob_max_{data_desc.lower().replace(\" \",\"_\")}'\n","    df[clust_col]=best_gmm.predict(data_for_gmm); df[prob_col]=np.max(best_gmm.predict_proba(data_for_gmm),axis=1)\n","    if 'senescence_score_normalized' in df.columns: print(f\"  Mean sen_score per GMM comp ({data_desc}):\\n{df.groupby(clust_col)['senescence_score_normalized'].mean().sort_values()}\")\n","    if umap_embedding is not None and 'umap_x_refined' in df.columns and 'umap_y_refined' in df.columns:\n","        plt.figure(figsize=(12,10)); labels=sorted(df[clust_col].unique()); pal=sns.color_palette(\"viridis\",n_colors=len(labels))\n","        for i,lbl in enumerate(labels): subset=df[df[clust_col]==lbl]; plt.scatter(subset['umap_x_refined'],subset['umap_y_refined'],label=f'GMM Comp. {lbl}',color=pal[i],s=15,alpha=0.7)\n","        plt.title(f'GMM ({best_gmm.n_components} comp.) on {data_desc} (UMAP proj.)'); plt.xlabel('UMAP 1'); plt.ylabel('UMAP 2'); plt.legend(title='GMM Comp.',bbox_to_anchor=(1.05,1),loc='upper left'); plt.grid(True,alpha=0.3); plt.tight_layout(rect=[0,0,0.85,1]); plt.savefig(os.path.join(output_dir,f'gmm_on_umap_{data_desc.lower().replace(\" \",\"_\")}.png'),dpi=300); plt.close()\n","        plt.figure(figsize=(12,10)); scatter_prob=plt.scatter(df['umap_x_refined'],df['umap_y_refined'],c=df[prob_col],cmap='magma',s=15,alpha=0.7,vmin=0,vmax=1); plt.colorbar(scatter_prob,label='Max GMM Prob.'); plt.title(f'GMM Max Prob. on {data_desc} (UMAP proj.)'); plt.xlabel('UMAP 1'); plt.ylabel('UMAP 2'); plt.grid(True,alpha=0.3); plt.tight_layout(); plt.savefig(os.path.join(output_dir,f'gmm_prob_on_umap_{data_desc.lower().replace(\" \",\"_\")}.png'),dpi=300); plt.close()\n","    return df\n","\n","def apply_rule_based_gating(df_main, rules, default_label, output_dir, umap_embedding=None):\n","    \"\"\"Applies rules to classify cells, creates granular and binary status, and plots.\"\"\"\n","    print(\"\\n--- Applying Rule-Based Gating ---\")\n","    df_main['rule_based_classification_granular'] = default_label\n","    all_rule_features = set(cond[0] for rule in rules for cond in rule['conditions'])\n","    missing_features = [feat for feat in all_rule_features if feat not in df_main.columns]\n","    if missing_features:\n","        print(f\"  Error: Features for rules missing from DataFrame: {missing_features}. Skipping.\"); return df_main\n","\n","    for rule in rules:\n","        print(f\"  Applying rule: {rule['name']}\")\n","        eligible_mask = (df_main['rule_based_classification_granular'] == default_label)\n","        if not eligible_mask.any(): print(f\"    No cells eligible for rule '{rule['name']}'.\"); continue\n","        current_condition_mask = pd.Series([True] * len(df_main), index=df_main.index)\n","        for feature, operator, value in rule['conditions']:\n","            if feature not in df_main.columns: print(f\"    Feature '{feature}' not found. Skipping rule.\"); current_condition_mask[:]=False; break\n","            try:\n","                feat_series = pd.to_numeric(df_main[feature], errors='coerce')\n","                if feat_series.isnull().any() and not df_main[feature].isnull().all() : print(f\"    Warning: Coercion to numeric for '{feature}' created NaNs.\")\n","                if   operator == '>':  current_condition_mask &= (feat_series > value)\n","                elif operator == '<':  current_condition_mask &= (feat_series < value)\n","                elif operator == '>=': current_condition_mask &= (feat_series >= value)\n","                elif operator == '<=': current_condition_mask &= (feat_series <= value)\n","                elif operator == '==': current_condition_mask &= (feat_series == value)\n","                elif operator == '!=': current_condition_mask &= (feat_series != value)\n","                else: print(f\"    Unknown operator '{operator}'.\"); current_condition_mask[:]=False; break\n","            except Exception as e: print(f\"    Error comparing '{feature}': {e}.\"); current_condition_mask[:]=False; break\n","\n","        # Check if current_condition_mask is valid before proceeding\n","        if isinstance(current_condition_mask, pd.Series) and not current_condition_mask.empty:\n","            if not current_condition_mask.any():\n","                print(f\"    No cells met conditions for rule '{rule['name']}'.\")\n","                continue\n","            cells_to_label = eligible_mask & current_condition_mask\n","            df_main.loc[cells_to_label, 'rule_based_classification_granular'] = rule['output_label']\n","            print(f\"    {cells_to_label.sum()} cells labeled as '{rule['output_label']}'.\")\n","        else: # Mask became invalid (e.g. all False due to error in condition)\n","            print(f\"    Rule '{rule['name']}' resulted in an invalid condition mask or no cells met conditions. No cells labeled by this rule.\")\n","\n","\n","    print(f\"\\nGranular rule-based counts:\\n{df_main['rule_based_classification_granular'].value_counts()}\")\n","    df_main['rule_based_binary_status'] = np.where(df_main['rule_based_classification_granular'] == default_label, 'Non-senescent', 'Senescent')\n","    print(f\"\\nBinary rule-based counts:\\n{df_main['rule_based_binary_status'].value_counts()}\")\n","\n","    if umap_embedding is not None and 'umap_x_refined' in df_main.columns and 'umap_y_refined' in df_main.columns:\n","        plt.figure(figsize=(12,10)); granular_labels = sorted(df_main['rule_based_classification_granular'].unique())\n","        if granular_labels:\n","            pal_gran = sns.color_palette(\"Paired\",n_colors=max(10,len(granular_labels)))\n","            for i,lbl in enumerate(granular_labels): subset=df_main[df_main['rule_based_classification_granular']==lbl]; plt.scatter(subset['umap_x_refined'],subset['umap_y_refined'],label=lbl,color=pal_gran[i%len(pal_gran)],s=15,alpha=0.7)\n","            plt.title('Rule-Based Gating (Granular - UMAP proj.)'); plt.xlabel('UMAP 1'); plt.ylabel('UMAP 2'); plt.legend(title='Rule Class (Granular)',bbox_to_anchor=(1.05,1),loc='upper left'); plt.grid(True,alpha=0.3); plt.tight_layout(rect=[0,0,0.80,1]); plt.savefig(os.path.join(output_dir,'rule_based_gating_granular_on_umap.png'),dpi=300); plt.close()\n","        plt.figure(figsize=(12,10)); binary_labels = sorted(df_main['rule_based_binary_status'].unique()); bin_pal={'Senescent':'red','Non-senescent':'blue','Unknown_Due_To_Missing_Features':'grey'}\n","        for lbl in binary_labels: subset=df_main[df_main['rule_based_binary_status']==lbl]; plt.scatter(subset['umap_x_refined'],subset['umap_y_refined'],label=lbl,color=bin_pal.get(lbl,'grey'),s=15,alpha=0.7)\n","        plt.title('Rule-Based Gating (Binary - UMAP proj.)'); plt.xlabel('UMAP 1'); plt.ylabel('UMAP 2'); plt.legend(title='Rule Status (Binary)',bbox_to_anchor=(1.05,1),loc='upper left'); plt.grid(True,alpha=0.3); plt.tight_layout(rect=[0,0,0.85,1]); plt.savefig(os.path.join(output_dir,'rule_based_gating_binary_on_umap.png'),dpi=300); plt.close()\n","    return df_main\n","\n","def visualize_rule_classification_on_masks(df_results, cell_mask_dir, nuclei_mask_dir, output_dir_masks, classification_column='rule_based_binary_status'):\n","    \"\"\"Visualizes a specified classification column (e.g., rule-based) on original mask images.\"\"\"\n","    print(f\"\\nGenerating classification overlays on original masks using column '{classification_column}' in: {output_dir_masks}\")\n","    if not os.path.exists(output_dir_masks): os.makedirs(output_dir_masks)\n","    sen_color, nonsen_color, nuc_color, unknown_color = [255,0,0], [0,0,255], [0,255,0], [128,128,128]\n","    if 'derived_sample_id' not in df_results.columns or classification_column not in df_results.columns:\n","        print(f\"Error: 'derived_sample_id' or '{classification_column}' not found. Cannot proceed.\"); return\n","    unique_samples = df_results['derived_sample_id'].unique()\n","    classification_lookup = pd.Series(df_results[classification_column].values, index=df_results.cell_id).to_dict()\n","    available_cell_masks = {extract_sample_id(f): f for f in os.listdir(cell_mask_dir) if f.endswith(('.tif', '.tiff'))}\n","    available_nuclei_masks = {extract_sample_id(f): f for f in os.listdir(nuclei_mask_dir) if f.endswith(('.tif', '.tiff'))}\n","\n","    for sample_id_csv in tqdm(unique_samples, desc=f\"Mask viz ({classification_column})\"):\n","        cell_mask_filename = available_cell_masks.get(sample_id_csv)\n","        nuclei_mask_filename = available_nuclei_masks.get(sample_id_csv)\n","        if not cell_mask_filename: print(f\"  Cell mask not found for {sample_id_csv}\"); continue\n","        print(f\"\\n  Overlaying sample: {sample_id_csv}\")\n","        cell_mask = load_image_as_labeled_mask(os.path.join(cell_mask_dir, cell_mask_filename))\n","        if cell_mask is None: continue\n","        overlay = np.zeros((cell_mask.shape[0], cell_mask.shape[1], 3), dtype=np.uint8)\n","        for props in measure.regionprops(cell_mask):\n","            full_cell_id = f\"{sample_id_csv}_{props.label}\"\n","            status = classification_lookup.get(full_cell_id, 'Unknown')\n","            color_to_use = unknown_color\n","            if status == 'Senescent': color_to_use = sen_color\n","            elif status == 'Non-senescent': color_to_use = nonsen_color\n","            elif status != 'Unknown' and classification_column == 'rule_based_classification_granular': # For granular, use a fallback if not Sen/NonSen\n","                 color_to_use = [np.random.randint(50,200) for _ in range(3)] # Randomish color for other granular rules\n","            overlay[cell_mask == props.label] = color_to_use\n","        if nuclei_mask_filename:\n","            nuc_mask = load_image_as_labeled_mask(os.path.join(nuclei_mask_dir, nuclei_mask_filename))\n","            if nuc_mask is not None:\n","                nuc_boundaries = segmentation.find_boundaries(nuc_mask, mode='inner', background=0)\n","                overlay[nuc_boundaries] = nuc_color\n","        fig_leg, ax_leg = plt.subplots(figsize=(max(10, overlay.shape[1]/100), max(8, overlay.shape[0]/100)), dpi=100) # Ensure min size\n","        ax_leg.imshow(overlay)\n","        handles = [mpatches.Patch(color=np.array(sen_color)/255., label='Senescent'),\n","                   mpatches.Patch(color=np.array(nonsen_color)/255., label='Non-senescent')]\n","        if 'Unknown' in df_results[classification_column].unique(): handles.append(mpatches.Patch(color=np.array(unknown_color)/255., label='Unknown'))\n","        if nuclei_mask_filename and nuc_mask is not None: handles.append(mpatches.Patch(color=np.array(nuc_color)/255., label='Nuclei Outline'))\n","        ax_leg.legend(handles=handles, loc='upper right', fontsize='small', bbox_to_anchor=(1.45, 1)); ax_leg.axis('off'); plt.tight_layout()\n","        plt.savefig(os.path.join(output_dir_masks, f\"{sample_id_csv}_{classification_column}_overlay.png\"), dpi=150); plt.close(fig_leg)\n","    print(f\"Mask overlay visualization for '{classification_column}' complete.\")\n","\n","\n","def main_exploratory_analysis():\n","    \"\"\"Main function to run exploratory analysis.\"\"\"\n","    if not os.path.exists(EXPLORATORY_OUTPUT_DIR):\n","        os.makedirs(EXPLORATORY_OUTPUT_DIR)\n","        print(f\"Created output directory: {EXPLORATORY_OUTPUT_DIR}\")\n","\n","    df = load_data(INPUT_REFINED_CSV_PATH)\n","    if df is None: return\n","\n","    scaled_features, feature_names_used_for_scaling = preprocess_features_for_ml(df, FEATURES_FOR_ANALYSIS, AREA_FEATURES_TO_LOG)\n","\n","    umap_embedding_for_plotting = None\n","    if 'umap_x_refined' in df.columns and 'umap_y_refined' in df.columns and df['umap_x_refined'].notna().all():\n","        print(\"\\nUsing existing UMAP coordinates from input CSV for visualizations.\")\n","        umap_embedding_for_plotting = df[['umap_x_refined', 'umap_y_refined']].values\n","    elif scaled_features is not None:\n","        print(\"\\nRecomputing UMAP for visualization...\")\n","        try:\n","            reducer = umap.UMAP(n_neighbors=15, min_dist=0.1, random_state=42, n_components=2)\n","            embedding = reducer.fit_transform(scaled_features)\n","            df['umap_x_refined'] = embedding[:, 0]; df['umap_y_refined'] = embedding[:, 1]\n","            umap_embedding_for_plotting = df[['umap_x_refined', 'umap_y_refined']].values\n","            print(\"  UMAP recomputed.\")\n","        except Exception as e: print(f\"  Error recomputing UMAP: {e}.\")\n","    else: print(\"\\nSkipping UMAP computation as scaled features are unavailable.\")\n","\n","    if scaled_features is not None and feature_names_used_for_scaling is not None:\n","        df = compute_and_plot_diffusion_map(df, scaled_features, feature_names_used_for_scaling, EXPLORATORY_OUTPUT_DIR)\n","\n","        # --- DBSCAN on Scaled Features ---\n","        # User should set this based on k-distance plot from previous run or set ESTIMATE_DBSCAN_EPS = True\n","        DBSCAN_EPS_FOR_SCALED_FEATURES = 2.3 # Example from your previous output\n","        DBSCAN_MIN_SAMPLES_FOR_SCALED_FEATURES = 10\n","        print(f\"\\nNOTE: For DBSCAN on Scaled Features, using EPS = {DBSCAN_EPS_FOR_SCALED_FEATURES}, MIN_SAMPLES = {DBSCAN_MIN_SAMPLES_FOR_SCALED_FEATURES}\")\n","        df = run_dbscan_and_plot(df, scaled_features, \"Scaled_Features\", EXPLORATORY_OUTPUT_DIR,\n","                                 umap_emb=umap_embedding_for_plotting,\n","                                 current_eps_val=DBSCAN_EPS_FOR_SCALED_FEATURES,\n","                                 current_min_samples_val=DBSCAN_MIN_SAMPLES_FOR_SCALED_FEATURES)\n","\n","        df = run_gmm_and_plot(df, scaled_features, \"Scaled_Features\", EXPLORATORY_OUTPUT_DIR, umap_embedding=umap_embedding_for_plotting)\n","\n","        if RUN_DBSCAN_ON_DIFFMAP and SCANPY_AVAILABLE:\n","            dc_cols = [f'dc_{i+1}' for i in range(N_DCS_FOR_DBSCAN) if f'dc_{i+1}' in df.columns and df[f'dc_{i+1}'].notna().any()]\n","            if dc_cols:\n","                data_dc = df[dc_cols].values\n","                # User should set this based on k-distance plot for DCs\n","                DBSCAN_EPS_FOR_DCS = 0.01 # Example from your previous output\n","                DBSCAN_MIN_SAMPLES_FOR_DCS = 10\n","                print(f\"\\nNOTE: For DBSCAN on Top DCs, using EPS = {DBSCAN_EPS_FOR_DCS}, MIN_SAMPLES = {DBSCAN_MIN_SAMPLES_FOR_DCS}\")\n","                df = run_dbscan_and_plot(df, data_dc, f\"Top_{len(dc_cols)}_DCs\", EXPLORATORY_OUTPUT_DIR,\n","                                         umap_emb=umap_embedding_for_plotting,\n","                                         current_eps_val=DBSCAN_EPS_FOR_DCS,\n","                                         current_min_samples_val=DBSCAN_MIN_SAMPLES_FOR_DCS)\n","            else: print(f\"\\nSkipping DBSCAN on DCs: Not enough valid DC columns.\")\n","\n","        global RUN_GMM_ON_DIFFMAP, N_DCS_FOR_GMM\n","        if RUN_GMM_ON_DIFFMAP and SCANPY_AVAILABLE:\n","            dc_cols_gmm = [f'dc_{i+1}' for i in range(N_DCS_FOR_GMM) if f'dc_{i+1}' in df.columns and df[f'dc_{i+1}'].notna().any()]\n","            if dc_cols_gmm:\n","                data_dc_gmm = df[dc_cols_gmm].values\n","                df = run_gmm_and_plot(df, data_dc_gmm, f\"Top_{len(dc_cols_gmm)}_DCs\", EXPLORATORY_OUTPUT_DIR, umap_embedding=umap_embedding_for_plotting)\n","            else: print(f\"\\nSkipping GMM on DCs: Not enough valid DC columns.\")\n","\n","    # Apply rule-based gating using the main df.\n","    df = apply_rule_based_gating(df, RULE_BASED_GATES, RULE_BASED_DEFAULT_LABEL, EXPLORATORY_OUTPUT_DIR, umap_embedding=umap_embedding_for_plotting)\n","\n","    # Visualize the rule-based classification on masks\n","    mask_overlay_output_path = os.path.join(EXPLORATORY_OUTPUT_DIR, MASK_VISUALIZATION_SUBDIR_RULES)\n","    if 'rule_based_binary_status' in df.columns: # Check if rule-based classification ran successfully\n","        visualize_rule_classification_on_masks(df, CELL_MASK_DIR, NUCLEI_MASK_DIR, mask_overlay_output_path, classification_column='rule_based_binary_status')\n","        # Optional: visualize granular rule classification on masks\n","        # visualize_rule_classification_on_masks(df, CELL_MASK_DIR, NUCLEI_MASK_DIR, mask_overlay_output_path, classification_column='rule_based_classification_granular')\n","    else:\n","        print(\"Skipping mask visualization for rule-based classification as the classification column is missing.\")\n","\n","\n","    exploratory_csv_path = os.path.join(EXPLORATORY_OUTPUT_DIR, 'exploratory_analysis_results_v5_rules_maskviz.csv')\n","    df.to_csv(exploratory_csv_path, index=False)\n","    print(f\"\\nExploratory analysis results saved to: {exploratory_csv_path}\")\n","    print(\"\\nExploratory analysis script finished.\")\n","\n","RUN_GMM_ON_DIFFMAP = True\n","N_DCS_FOR_GMM = 3\n","\n","if __name__ == '__main__':\n","    main_exploratory_analysis()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NlqO7KhK7_Nu","executionInfo":{"status":"ok","timestamp":1747212118459,"user_tz":-120,"elapsed":39248,"user":{"displayName":"Guido Putignano","userId":"13974663347531370398"}},"outputId":"b7cdca6b-de7a-4be7-e9c5-60b7b86b95ee"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Created output directory: /content/drive/MyDrive/knowledge/University/Master/Thesis/Analysis/flow3-x20/Exploratory_Analysis_V5_rules_mask_viz\n","Loading refined data from /content/drive/MyDrive/knowledge/University/Master/Thesis/Analysis/flow3-x20/Senescence_Refined_V5_DiffMap/cell_classification_results_refined.csv...\n","Successfully loaded 2472 cells.\n","  Derived 'derived_sample_id' from 'cell_id' for mask matching.\n","\n","Preprocessing features for ML. Selected: ['cell_area', 'cell_perimeter', 'cell_eccentricity', 'cell_circularity', 'cell_aspect_ratio', 'avg_nucleus_area', 'max_nucleus_area', 'avg_nucleus_eccentricity', 'nucleus_area_std', 'nucleus_displacement', 'nucleus_to_cell_area_ratio', 'nuclear_enlargement', 'cell_enlargement']\n","  Log-transformed for scaling: cell_area\n","  Log-transformed for scaling: avg_nucleus_area\n","  Log-transformed for scaling: max_nucleus_area\n","  Log-transformed for scaling: cell_perimeter\n","  Features standardized for ML algorithms.\n","\n","Using existing UMAP coordinates from input CSV for visualizations.\n","\n","--- Computing Diffusion Map ---\n","  Computing neighbors (k=15)...\n","  Running sc.tl.diffmap...\n","  Added 9 DCs to DataFrame.\n","  DiffMap pair plots for top 3 DCs saved.\n","\n","NOTE: For DBSCAN on Scaled Features, using EPS = 2.3, MIN_SAMPLES = 10\n","\n","--- Running DBSCAN on Scaled_Features ---\n","  Running DBSCAN with eps=2.3, min_samples=10 on Scaled_Features...\n","  DBSCAN on Scaled_Features: 1 clusters, 137 noise (5.54%).\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-25-56fac27223ef>:235: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n","  dbscan_cmap_obj = plt.cm.get_cmap('Spectral', n_actual_clusters)\n"]},{"output_type":"stream","name":"stdout","text":["  DBSCAN on Scaled_Features plotted on UMAP.\n","\n","--- Running GMM on Scaled_Features ---\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n","  # that has no feature names.\n","/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n","  # that has no feature names.\n","/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n","  # that has no feature names.\n"]},{"output_type":"stream","name":"stdout","text":["    GMM 2 comps: BIC=-11876.19\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n","  # that has no feature names.\n","/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n","  # that has no feature names.\n"]},{"output_type":"stream","name":"stdout","text":["    GMM 3 comps: BIC=-20370.16\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n","  # that has no feature names.\n","/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n","  # that has no feature names.\n","/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n","  # that has no feature names.\n"]},{"output_type":"stream","name":"stdout","text":["    GMM 4 comps: BIC=-26836.71\n","  Best GMM: 4 components (BIC=-26836.71).\n","  Mean sen_score per GMM comp (Scaled_Features):\n","gmm_scaled_features\n","1    0.316948\n","0    0.365966\n","3    0.500682\n","2    0.500958\n","Name: senescence_score_normalized, dtype: float64\n","\n","NOTE: For DBSCAN on Top DCs, using EPS = 0.01, MIN_SAMPLES = 10\n","\n","--- Running DBSCAN on Top_3_DCs ---\n","  Running DBSCAN with eps=0.01, min_samples=10 on Top_3_DCs...\n","  DBSCAN on Top_3_DCs: 2 clusters, 42 noise (1.70%).\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-25-56fac27223ef>:235: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n","  dbscan_cmap_obj = plt.cm.get_cmap('Spectral', n_actual_clusters)\n"]},{"output_type":"stream","name":"stdout","text":["  DBSCAN on Top_3_DCs plotted on UMAP.\n","\n","--- Running GMM on Top_3_DCs ---\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n","  # that has no feature names.\n","/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n","  # that has no feature names.\n","/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n","  # that has no feature names.\n","/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n","  # that has no feature names.\n","/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n","  # that has no feature names.\n"]},{"output_type":"stream","name":"stdout","text":["    GMM 2 comps: BIC=-42744.54\n","    GMM 3 comps: BIC=-43790.09\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n","  # that has no feature names.\n","/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n","  # that has no feature names.\n","/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n","  # that has no feature names.\n"]},{"output_type":"stream","name":"stdout","text":["    GMM 4 comps: BIC=-44590.14\n","  Best GMM: 4 components (BIC=-44590.14).\n","  Mean sen_score per GMM comp (Top_3_DCs):\n","gmm_top_3_dcs\n","0    0.319583\n","1    0.398703\n","2    0.427525\n","3    0.543944\n","Name: senescence_score_normalized, dtype: float64\n","\n","--- Applying Rule-Based Gating ---\n","  Applying rule: Polynucleated\n","    225 cells labeled as 'Rule_Sen_Poly'.\n","  Applying rule: Very_Large_Cell\n","    307 cells labeled as 'Rule_Sen_VeryLarge'.\n","  Applying rule: Low_Circularity\n","    3 cells labeled as 'Rule_Sen_LowCirc'.\n","  Applying rule: Low_NucToCellRatio\n","    103 cells labeled as 'Rule_Sen_LowNucRatio'.\n","  Applying rule: High_Score_Not_Otherwise_Caught\n","    0 cells labeled as 'Rule_Sen_HighScore'.\n","\n","Granular rule-based counts:\n","rule_based_classification_granular\n","Rule_NonSenescent       1834\n","Rule_Sen_VeryLarge       307\n","Rule_Sen_Poly            225\n","Rule_Sen_LowNucRatio     103\n","Rule_Sen_LowCirc           3\n","Name: count, dtype: int64\n","\n","Binary rule-based counts:\n","rule_based_binary_status\n","Non-senescent    1834\n","Senescent         638\n","Name: count, dtype: int64\n","\n","Generating classification overlays on original masks using column 'rule_based_binary_status' in: /content/drive/MyDrive/knowledge/University/Master/Thesis/Analysis/flow3-x20/Exploratory_Analysis_V5_rules_mask_viz/mask_overlays_rule_based\n"]},{"output_type":"stream","name":"stderr","text":["\rMask viz (rule_based_binary_status):   0%|          | 0/8 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","  Overlaying sample: 0Pa_U_05mar19_20x_L2RA_Flat_seq001\n","    Loading mask: 0Pa_U_05mar19_20x_L2RA_Flat_seq001_cell_mask_merged_conservative.tif\n","    Loading mask: denoised_0Pa_U_05mar19_20x_L2RA_Flat_seq001_Cadherins_filtered_mask.tif\n"]},{"output_type":"stream","name":"stderr","text":["\rMask viz (rule_based_binary_status):  12%|█▎        | 1/8 [00:01<00:10,  1.56s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","  Overlaying sample: 0Pa_U_05mar19_20x_L2RA_Flat_seq002\n","    Loading mask: 0Pa_U_05mar19_20x_L2RA_Flat_seq002_cell_mask_merged_conservative.tif\n","    Loading mask: denoised_0Pa_U_05mar19_20x_L2RA_Flat_seq002_Cadherins_filtered_mask.tif\n"]},{"output_type":"stream","name":"stderr","text":["\rMask viz (rule_based_binary_status):  25%|██▌       | 2/8 [00:03<00:09,  1.61s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","  Overlaying sample: 0Pa_U_05mar19_20x_L2RA_Flat_seq003\n","    Loading mask: 0Pa_U_05mar19_20x_L2RA_Flat_seq003_cell_mask_merged_conservative.tif\n","    Loading mask: denoised_0Pa_U_05mar19_20x_L2RA_Flat_seq003_Cadherins_filtered_mask.tif\n"]},{"output_type":"stream","name":"stderr","text":["\rMask viz (rule_based_binary_status):  38%|███▊      | 3/8 [00:04<00:07,  1.59s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","  Overlaying sample: 1.4Pa_U_05mar19_20x_L2R_Flat_seq001\n","    Loading mask: 1.4Pa_U_05mar19_20x_L2R_Flat_seq001_cell_mask_merged_conservative.tif\n","    Loading mask: denoised_1.4Pa_U_05mar19_20x_L2R_Flat_seq001_Cadherins_filtered_mask.tif\n"]},{"output_type":"stream","name":"stderr","text":["\rMask viz (rule_based_binary_status):  50%|█████     | 4/8 [00:06<00:05,  1.48s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","  Overlaying sample: 1.4Pa_U_05mar19_20x_L2R_Flat_seq002\n","    Loading mask: 1.4Pa_U_05mar19_20x_L2R_Flat_seq002_cell_mask_merged_conservative.tif\n","    Loading mask: denoised_1.4Pa_U_05mar19_20x_L2R_Flat_seq002_Cadherins_filtered_mask.tif\n"]},{"output_type":"stream","name":"stderr","text":["\rMask viz (rule_based_binary_status):  62%|██████▎   | 5/8 [00:07<00:03,  1.33s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","  Overlaying sample: 1.4Pa_U_05mar19_20x_L2R_Flat_seq003\n","    Loading mask: 1.4Pa_U_05mar19_20x_L2R_Flat_seq003_cell_mask_merged_conservative.tif\n","    Loading mask: denoised_1.4Pa_U_05mar19_20x_L2R_Flat_seq003_Cadherins_filtered_mask.tif\n"]},{"output_type":"stream","name":"stderr","text":["\rMask viz (rule_based_binary_status):  75%|███████▌  | 6/8 [00:08<00:02,  1.32s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","  Overlaying sample: 1.4Pa_U_05mar19_20x_L2R_Flat_seq004\n","    Loading mask: 1.4Pa_U_05mar19_20x_L2R_Flat_seq004_cell_mask_merged_conservative.tif\n","    Loading mask: denoised_1.4Pa_U_05mar19_20x_L2R_Flat_seq004_Cadherins_filtered_mask.tif\n"]},{"output_type":"stream","name":"stderr","text":["\rMask viz (rule_based_binary_status):  88%|████████▊ | 7/8 [00:10<00:01,  1.48s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","  Overlaying sample: 1.4Pa_U_05mar19_20x_L2R_Flat_seq005\n","    Loading mask: 1.4Pa_U_05mar19_20x_L2R_Flat_seq005_cell_mask_merged_conservative.tif\n","    Loading mask: denoised_1.4Pa_U_05mar19_20x_L2R_Flat_seq005_Cadherins_filtered_mask.tif\n"]},{"output_type":"stream","name":"stderr","text":["Mask viz (rule_based_binary_status): 100%|██████████| 8/8 [00:12<00:00,  1.55s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Mask overlay visualization for 'rule_based_binary_status' complete.\n","\n","Exploratory analysis results saved to: /content/drive/MyDrive/knowledge/University/Master/Thesis/Analysis/flow3-x20/Exploratory_Analysis_V5_rules_mask_viz/exploratory_analysis_results_v5_rules_maskviz.csv\n","\n","Exploratory analysis script finished.\n"]}]},{"cell_type":"code","source":["import os\n","import re\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as mpatches\n","import seaborn as sns\n","from skimage import io, measure, segmentation # Added segmentation\n","import cv2 # Added cv2\n","from scipy import ndimage # Added ndimage\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.cluster import DBSCAN\n","from sklearn.mixture import GaussianMixture\n","from sklearn.neighbors import NearestNeighbors\n","import umap\n","\n","try:\n","    import scanpy as sc\n","    SCANPY_AVAILABLE = True\n","except ImportError:\n","    print(\"Scanpy library not found. Diffusion map functionality will be skipped.\")\n","    SCANPY_AVAILABLE = False\n","\n","# --- Configuration & Parameters ---\n","INPUT_REFINED_CSV_PATH = \"/content/drive/MyDrive/knowledge/University/Master/Thesis/Analysis/flow3-x20/Senescence_Refined_V5_DiffMap/cell_classification_results_refined.csv\"\n","EXPLORATORY_OUTPUT_DIR = \"/content/drive/MyDrive/knowledge/University/Master/Thesis/Analysis/flow3-x20/Exploratory_Analysis_V5_rules_mask_viz\"\n","\n","# !! UPDATE THESE PATHS to your original mask image directories !!\n","CELL_MASK_DIR = \"/content/drive/MyDrive/knowledge/University/Master/Thesis/Segmented/flow3-x20/Cell_merged_conservative\"\n","NUCLEI_MASK_DIR = \"/content/drive/MyDrive/knowledge/University/Master/Thesis/Segmented/flow3-x20/Nuclei\"\n","MASK_VISUALIZATION_SUBDIR_RULES = \"mask_overlays_rule_based\"\n","\n","\n","FEATURES_FOR_ANALYSIS = [\n","    'cell_area', 'cell_perimeter', 'cell_eccentricity', 'cell_circularity',\n","    'cell_aspect_ratio', 'avg_nucleus_area', 'max_nucleus_area',\n","    'avg_nucleus_eccentricity', 'nucleus_area_std', 'nucleus_displacement',\n","    'nucleus_to_cell_area_ratio',\n","    'nuclear_enlargement', 'cell_enlargement'\n","]\n","AREA_FEATURES_TO_LOG = ['cell_area', 'avg_nucleus_area', 'max_nucleus_area', 'cell_perimeter']\n","\n","N_DIFFUSION_COMPONENTS = 10\n","N_DCS_TO_PLOT = 3\n","N_NEIGHBORS_FOR_SCANPY = 15\n","\n","DBSCAN_EPS_DEFAULT = 0.75\n","DBSCAN_MIN_SAMPLES_DEFAULT = 10\n","ESTIMATE_DBSCAN_EPS = True\n","K_FOR_EPS_ESTIMATION = 10\n","RUN_DBSCAN_ON_DIFFMAP = True\n","N_DCS_FOR_DBSCAN = 3\n","\n","GMM_N_COMPONENTS_RANGE = range(2, 5)\n","GMM_COVARIANCE_TYPE = 'full'\n","\n","RULE_BASED_GATES = [\n","    {   'name': 'Polynucleated',\n","        'conditions': [('nuclei_count', '>', 1)],\n","        'output_label': 'Rule_Sen_Poly' },\n","    {   'name': 'Very_Large_Cell',\n","        'conditions': [('cell_area', '>', 5000)],\n","        'output_label': 'Rule_Sen_VeryLarge' },\n","    {   'name': 'Low_Circularity',\n","        'conditions': [('cell_circularity', '<', 0.2)],\n","        'output_label': 'Rule_Sen_LowCirc' },\n","    {   'name': 'Low_NucToCellRatio',\n","        'conditions': [('nucleus_to_cell_area_ratio', '<', 0.1)],\n","        'output_label': 'Rule_Sen_LowNucRatio' },\n","    {   'name': 'High_Score_Not_Otherwise_Caught',\n","        'conditions': [('senescence_score_normalized', '>', 0.75)],\n","        'output_label': 'Rule_Sen_HighScore' }\n","]\n","RULE_BASED_DEFAULT_LABEL = 'Rule_NonSenescent'\n","\n","# --- Helper Functions ---\n","def extract_sample_id(filename):\n","    \"\"\"Extracts sample ID from filename (adapted from user's original notebook).\"\"\"\n","    base_name = os.path.splitext(filename)[0]\n","    if base_name.startswith('denoised_'):\n","        base_name = base_name[len('denoised_'):]\n","    pattern = re.compile(r'([\\d\\.]+Pa_[^_]+_[^_]+_[^_]+_[^_]+_[^_]+_seq\\d+)')\n","    match = pattern.search(base_name)\n","    if match:\n","        return match.group(1)\n","    parts = base_name.split('_')\n","    for i, part in enumerate(parts):\n","        if part.startswith('seq') and i >= 2:\n","            return '_'.join(parts[:i+1])\n","    common_prefix = \"_\".join(filename.split('_')[:6])\n","    return common_prefix if 'seq' in common_prefix else os.path.splitext(os.path.basename(filename))[0]\n","\n","def load_image_as_labeled_mask(filepath):\n","    \"\"\"Loads a mask image, ensuring it's a labeled integer mask.\"\"\"\n","    print(f\"    Loading mask: {os.path.basename(filepath)}\")\n","    try:\n","        img = io.imread(filepath)\n","        if img.ndim > 2: # Handle multi-channel\n","            if img.shape[-1] == 3: img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n","            elif img.shape[-1] == 4: img = cv2.cvtColor(img, cv2.COLOR_RGBA2GRAY)\n","            else: img = img[..., 0]\n","\n","        if img.dtype.kind in 'iu' and np.max(img) > 1: # Already labeled integer mask\n","            return img.astype(np.uint16)\n","\n","        if img.dtype.kind == 'f': img = (img > 0.5).astype(np.uint8)\n","        elif np.max(img) == 1: img = img.astype(np.uint8)\n","\n","        if np.max(img) <=1 : # Binary after potential conversion\n","            labeled_img, num_features = ndimage.label(img)\n","            print(f\"    Labeled binary mask {os.path.basename(filepath)}, found {num_features} features.\")\n","            return labeled_img.astype(np.uint16)\n","\n","        return img.astype(np.uint16)\n","    except Exception as e:\n","        print(f\"    Error loading image {filepath}: {str(e)}\"); return None\n","\n","def load_data(csv_path):\n","    \"\"\"Loads the refined data and derives sample_id if needed.\"\"\"\n","    print(f\"Loading refined data from {csv_path}...\")\n","    try:\n","        df = pd.read_csv(csv_path)\n","        print(f\"Successfully loaded {len(df)} cells.\")\n","\n","        if 'cell_id' in df.columns:\n","            df['derived_sample_id'] = df['cell_id'].apply(lambda x: '_'.join(x.split('_')[:-1]))\n","            print(\"  Derived 'derived_sample_id' from 'cell_id' for mask matching.\")\n","        else:\n","            print(\"Error: 'cell_id' column missing. Cannot derive sample IDs for mask matching.\")\n","            return None\n","\n","        essential_cols = ['senescence_score_normalized', 'nuclei_count', 'cell_area',\n","                          'cell_circularity', 'nucleus_to_cell_area_ratio']\n","        for col_check in essential_cols:\n","            if col_check not in df.columns:\n","                print(f\"Warning: Essential column '{col_check}' for rules/scoring not found.\")\n","        return df\n","    except FileNotFoundError:\n","        print(f\"Error: CSV file not found at {csv_path}\"); return None\n","\n","def preprocess_features_for_ml(df, feature_columns, log_transform_cols):\n","    \"\"\"Prepares features specifically for ML algorithms (scaling).\"\"\"\n","    print(f\"\\nPreprocessing features for ML. Selected: {feature_columns}\")\n","    actual_features_for_ml = [col for col in feature_columns if col in df.columns]\n","    if not actual_features_for_ml: return None, None\n","    features_for_scaling_df = df[actual_features_for_ml].copy()\n","    for col in log_transform_cols:\n","        if col in features_for_scaling_df.columns:\n","            features_for_scaling_df[col] = np.log1p(features_for_scaling_df[col])\n","            print(f\"  Log-transformed for scaling: {col}\")\n","    if features_for_scaling_df.isnull().sum().any():\n","        features_for_scaling_df = features_for_scaling_df.fillna(features_for_scaling_df.mean())\n","    cols_to_drop_scaled = features_for_scaling_df.columns[features_for_scaling_df.isna().all()].tolist()\n","    if cols_to_drop_scaled:\n","        features_for_scaling_df = features_for_scaling_df.drop(columns=cols_to_drop_scaled)\n","        actual_features_for_ml = [f for f in actual_features_for_ml if f not in cols_to_drop_scaled]\n","    if features_for_scaling_df.empty or not actual_features_for_ml: return None, None\n","    scaler = StandardScaler(); features_scaled = scaler.fit_transform(features_for_scaling_df)\n","    print(\"  Features standardized for ML algorithms.\")\n","    return features_scaled, actual_features_for_ml\n","\n","def compute_and_plot_diffusion_map(df, scaled_features, feature_names_used, output_dir):\n","    \"\"\"Computes and plots diffusion map.\"\"\"\n","    if not SCANPY_AVAILABLE: print(\"Skipping diffusion map: Scanpy not available.\"); return df\n","    print(\"\\n--- Computing Diffusion Map ---\")\n","    if scaled_features is None or scaled_features.shape[0] == 0 : print(\"  No scaled features for Diffusion Map. Skipping.\"); return df\n","    adata = sc.AnnData(scaled_features, var=pd.DataFrame(index=feature_names_used))\n","    adata.obs_names = df.index.astype(str)\n","    if 'senescence_score_normalized' in df.columns: adata.obs['senescence_score_normalized'] = df['senescence_score_normalized'].values\n","    if 'cell_type_final' in df.columns: adata.obs['cell_type_final'] = df['cell_type_final'].astype('category').values\n","    actual_n_neighbors = min(N_NEIGHBORS_FOR_SCANPY, adata.n_obs - 1)\n","    if actual_n_neighbors < 2: print(f\"  Not enough samples for Scanpy neighbors. Skipping.\"); return df\n","    print(f\"  Computing neighbors (k={actual_n_neighbors})...\"); sc.pp.neighbors(adata, n_neighbors=actual_n_neighbors, use_rep='X')\n","    print(\"  Running sc.tl.diffmap...\"); sc.tl.diffmap(adata, n_comps=N_DIFFUSION_COMPONENTS)\n","    if 'X_diffmap' in adata.obsm:\n","        num_dc = min(N_DIFFUSION_COMPONENTS, adata.obsm['X_diffmap'].shape[1] - 1)\n","        for i in range(num_dc): df[f'dc_{i+1}'] = adata.obsm['X_diffmap'][:, i+1]\n","        print(f\"  Added {num_dc} DCs to DataFrame.\")\n","        pairs = [(f'dc_{i}', f'dc_{j}') for i in range(1, N_DCS_TO_PLOT + 1) for j in range(i + 1, N_DCS_TO_PLOT + 1) if f'dc_{i}' in df.columns and f'dc_{j}' in df.columns]\n","        for dcx, dcy in pairs:\n","            if df[dcx].notna().any() and df[dcy].notna().any():\n","                if 'senescence_score_normalized' in df.columns and df['senescence_score_normalized'].notna().any():\n","                    plt.figure(figsize=(10,8)); plt.scatter(df[dcx], df[dcy], c=df['senescence_score_normalized'], cmap='viridis', s=12, alpha=0.7); plt.colorbar(label='Norm. Senescence Score')\n","                    plt.title(f'DiffMap ({dcx} vs {dcy}) by Score'); plt.xlabel(dcx.upper()); plt.ylabel(dcy.upper()); plt.grid(True,alpha=0.3); plt.savefig(os.path.join(output_dir, f'diffmap_{dcx}_{dcy}_by_score.png'),dpi=300,bbox_inches='tight'); plt.close()\n","                if 'cell_type_final' in df.columns:\n","                    plt.figure(figsize=(10,8)); types=df['cell_type_final'].unique(); pal={t:('red' if t=='Senescent' else ('blue' if t=='Non-senescent' else 'grey')) for t in types}\n","                    for ct,col in pal.items(): subset=df[df['cell_type_final']==ct]; plt.scatter(subset[dcx],subset[dcy],label=ct,color=col,s=12,alpha=0.7)\n","                    plt.title(f'DiffMap ({dcx} vs {dcy}) by Prev. Classif.'); plt.xlabel(dcx.upper()); plt.ylabel(dcy.upper());\n","                    if pal: plt.legend(title='Previous Final Cell Type'); plt.grid(True,alpha=0.3); plt.savefig(os.path.join(output_dir, f'diffmap_{dcx}_{dcy}_by_prev_type.png'),dpi=300,bbox_inches='tight'); plt.close()\n","        print(f\"  DiffMap pair plots for top {N_DCS_TO_PLOT} DCs saved.\")\n","    else: print(\"  Error: 'X_diffmap' not found.\")\n","    return df\n","\n","def run_dbscan_and_plot(df, data_for_dbscan, data_desc, output_dir, umap_emb=None, current_eps_val=None, current_min_samples_val=None):\n","    \"\"\"Runs DBSCAN and plots results. Uses specific eps and min_samples if provided.\"\"\"\n","    print(f\"\\n--- Running DBSCAN on {data_desc} ---\")\n","    if data_for_dbscan is None or data_for_dbscan.shape[0] == 0:\n","        print(f\"  No data for DBSCAN on {data_desc}. Skipping.\")\n","        df[f'dbscan_{data_desc.lower().replace(\" \",\"_\")}']=-1\n","        return df\n","\n","    eps_to_use = current_eps_val if current_eps_val is not None else DBSCAN_EPS_DEFAULT\n","    min_s_to_use = current_min_samples_val if current_min_samples_val is not None else DBSCAN_MIN_SAMPLES_DEFAULT\n","\n","    if ESTIMATE_DBSCAN_EPS and current_eps_val is None :\n","        k_est = min(K_FOR_EPS_ESTIMATION, data_for_dbscan.shape[0]-1); k_est=max(1,k_est)\n","        nn=NearestNeighbors(n_neighbors=k_est); nn.fit(data_for_dbscan); dists, _ = nn.kneighbors(data_for_dbscan)\n","        actual_k_for_dists = min(k_est, dists.shape[1])\n","        if actual_k_for_dists > 0:\n","            k_dists = dists[:,actual_k_for_dists-1]\n","            k_dists_sorted = np.sort(k_dists)\n","            plt.figure(figsize=(8,6)); plt.plot(k_dists_sorted); plt.title(f'{actual_k_for_dists}-Dist Graph for Eps ({data_desc})');\n","            plt.xlabel(\"Points sorted by distance\"); plt.ylabel(f\"{actual_k_for_dists}-th NN Distance (eps candidate)\"); plt.grid(True,alpha=0.3);\n","            eps_path=os.path.join(output_dir, f'dbscan_eps_est_{data_desc.lower().replace(\" \",\"_\")}.png'); plt.savefig(eps_path,dpi=300); plt.close();\n","            print(f\"  Saved k-dist graph: {eps_path}. PLEASE INSPECT THIS PLOT TO SET appropriate DBSCAN_EPS for {data_desc}.\")\n","            if len(k_dists_sorted)>10:\n","                sug_eps=np.percentile(k_dists_sorted,90);\n","                print(f\"  A percentile-based suggestion for eps for {data_desc} is: {sug_eps:.3f}. The script will use eps={eps_to_use} (default or passed).\")\n","        else:\n","            print(f\"  Could not determine k-distances for eps estimation for {data_desc}. Using eps={eps_to_use}\")\n","\n","    print(f\"  Running DBSCAN with eps={eps_to_use}, min_samples={min_s_to_use} on {data_desc}...\")\n","    db=DBSCAN(eps=eps_to_use,min_samples=min_s_to_use).fit(data_for_dbscan)\n","    clust_col=f'dbscan_{data_desc.lower().replace(\" \",\"_\")}'; df[clust_col]=db.labels_\n","    n_clust=len(set(db.labels_))-(1 if -1 in db.labels_ else 0); n_noise=list(db.labels_).count(-1)\n","    print(f\"  DBSCAN on {data_desc}: {n_clust} clusters, {n_noise} noise ({n_noise/len(df)*100:.2f}%).\")\n","\n","    if umap_emb is not None and 'umap_x_refined' in df.columns and 'umap_y_refined' in df.columns:\n","        plt.figure(figsize=(12,10))\n","        labels_unique_dbscan=sorted(df[clust_col].unique())\n","        n_actual_clusters = len([l for l in labels_unique_dbscan if l != -1])\n","        if n_actual_clusters > 0:\n","            dbscan_cmap_obj = plt.cm.get_cmap('Spectral', n_actual_clusters)\n","        else:\n","            dbscan_cmap_obj = plt.cm.get_cmap('Spectral', 1)\n","\n","        cdict = {}\n","        cluster_idx = 0\n","        for lbl in labels_unique_dbscan:\n","            if lbl == -1:\n","                cdict[lbl] = (0.5, 0.5, 0.5, 1)\n","            else:\n","                cdict[lbl] = dbscan_cmap_obj(cluster_idx)\n","                cluster_idx += 1\n","\n","        for k_val in labels_unique_dbscan:\n","            mask=(df[clust_col]==k_val)\n","            xy=umap_emb[mask]\n","            if xy.shape[0]>0:\n","                 # Corrected indentation for the plt.scatter call\n","                 plt.scatter(xy[:,0],xy[:,1],\n","                             s=(20 if k_val!=-1 else 10),\n","                             c=[cdict[k_val]],\n","                             marker=('o' if k_val!=-1 else 'x'),\n","                             label=('Noise' if k_val == -1 else f'Cluster {k_val}'))\n","        plt.title(f'DBSCAN on {data_desc} (UMAP proj.)\\neps={eps_to_use:.3f}, min_s={min_s_to_use}')\n","        plt.xlabel('UMAP 1'); plt.ylabel('UMAP 2')\n","        plt.legend(title='DBSCAN Cluster',bbox_to_anchor=(1.05,1),loc='upper left',markerscale=1.5)\n","        plt.grid(True,alpha=0.3); plt.tight_layout(rect=[0,0,0.85,1])\n","        plt.savefig(os.path.join(output_dir, f'dbscan_on_umap_{data_desc.lower().replace(\" \",\"_\")}.png'),dpi=300); plt.close()\n","        print(f\"  DBSCAN on {data_desc} plotted on UMAP.\")\n","    return df\n","\n","def run_gmm_and_plot(df, data_for_gmm, data_desc, output_dir, umap_embedding=None):\n","    \"\"\"Runs GMM and plots results.\"\"\"\n","    print(f\"\\n--- Running GMM on {data_desc} ---\")\n","    if data_for_gmm is None: df[f'gmm_cluster_{data_desc.lower().replace(\" \",\"_\")}']=-1; df[f'gmm_prob_max_{data_desc.lower().replace(\" \",\"_\")}']=np.nan; return df\n","    best_gmm=None; lowest_bic=np.inf\n","    for n_comp in GMM_N_COMPONENTS_RANGE:\n","        if n_comp > data_for_gmm.shape[0]: continue\n","        gmm=GaussianMixture(n_components=n_comp,covariance_type=GMM_COVARIANCE_TYPE,random_state=42,n_init=5).fit(data_for_gmm); bic=gmm.bic(data_for_gmm); print(f\"    GMM {n_comp} comps: BIC={bic:.2f}\")\n","        if bic<lowest_bic: lowest_bic=bic; best_gmm=gmm\n","    if best_gmm is None: df[f'gmm_cluster_{data_desc.lower().replace(\" \",\"_\")}']=-1; df[f'gmm_prob_max_{data_desc.lower().replace(\" \",\"_\")}']=np.nan; return df\n","    print(f\"  Best GMM: {best_gmm.n_components} components (BIC={lowest_bic:.2f}).\")\n","    clust_col,prob_col = f'gmm_{data_desc.lower().replace(\" \",\"_\")}',f'gmm_prob_max_{data_desc.lower().replace(\" \",\"_\")}'\n","    df[clust_col]=best_gmm.predict(data_for_gmm); df[prob_col]=np.max(best_gmm.predict_proba(data_for_gmm),axis=1)\n","    if 'senescence_score_normalized' in df.columns: print(f\"  Mean sen_score per GMM comp ({data_desc}):\\n{df.groupby(clust_col)['senescence_score_normalized'].mean().sort_values()}\")\n","    if umap_embedding is not None and 'umap_x_refined' in df.columns and 'umap_y_refined' in df.columns:\n","        plt.figure(figsize=(12,10)); labels=sorted(df[clust_col].unique()); pal=sns.color_palette(\"viridis\",n_colors=len(labels))\n","        for i,lbl in enumerate(labels): subset=df[df[clust_col]==lbl]; plt.scatter(subset['umap_x_refined'],subset['umap_y_refined'],label=f'GMM Comp. {lbl}',color=pal[i],s=15,alpha=0.7)\n","        plt.title(f'GMM ({best_gmm.n_components} comp.) on {data_desc} (UMAP proj.)'); plt.xlabel('UMAP 1'); plt.ylabel('UMAP 2'); plt.legend(title='GMM Comp.',bbox_to_anchor=(1.05,1),loc='upper left'); plt.grid(True,alpha=0.3); plt.tight_layout(rect=[0,0,0.85,1]); plt.savefig(os.path.join(output_dir,f'gmm_on_umap_{data_desc.lower().replace(\" \",\"_\")}.png'),dpi=300); plt.close()\n","        plt.figure(figsize=(12,10)); scatter_prob=plt.scatter(df['umap_x_refined'],df['umap_y_refined'],c=df[prob_col],cmap='magma',s=15,alpha=0.7,vmin=0,vmax=1); plt.colorbar(scatter_prob,label='Max GMM Prob.'); plt.title(f'GMM Max Prob. on {data_desc} (UMAP proj.)'); plt.xlabel('UMAP 1'); plt.ylabel('UMAP 2'); plt.grid(True,alpha=0.3); plt.tight_layout(); plt.savefig(os.path.join(output_dir,f'gmm_prob_on_umap_{data_desc.lower().replace(\" \",\"_\")}.png'),dpi=300); plt.close()\n","    return df\n","\n","def apply_rule_based_gating(df_main, rules, default_label, output_dir, umap_embedding=None):\n","    \"\"\"Applies rules to classify cells, creates granular and binary status, and plots.\"\"\"\n","    print(\"\\n--- Applying Rule-Based Gating ---\")\n","    df_main['rule_based_classification_granular'] = default_label\n","    all_rule_features = set(cond[0] for rule in rules for cond in rule['conditions'])\n","    missing_features = [feat for feat in all_rule_features if feat not in df_main.columns]\n","    if missing_features:\n","        print(f\"  Error: Features for rules missing from DataFrame: {missing_features}. Skipping.\"); return df_main\n","\n","    for rule in rules:\n","        print(f\"  Applying rule: {rule['name']}\")\n","        eligible_mask = (df_main['rule_based_classification_granular'] == default_label)\n","        if not eligible_mask.any(): print(f\"    No cells eligible for rule '{rule['name']}'.\"); continue\n","        current_condition_mask = pd.Series([True] * len(df_main), index=df_main.index)\n","        for feature, operator, value in rule['conditions']:\n","            if feature not in df_main.columns: print(f\"    Feature '{feature}' not found. Skipping rule.\"); current_condition_mask[:]=False; break\n","            try:\n","                feat_series = pd.to_numeric(df_main[feature], errors='coerce')\n","                if feat_series.isnull().any() and not df_main[feature].isnull().all() : print(f\"    Warning: Coercion to numeric for '{feature}' created NaNs.\")\n","                if   operator == '>':  current_condition_mask &= (feat_series > value)\n","                elif operator == '<':  current_condition_mask &= (feat_series < value)\n","                elif operator == '>=': current_condition_mask &= (feat_series >= value)\n","                elif operator == '<=': current_condition_mask &= (feat_series <= value)\n","                elif operator == '==': current_condition_mask &= (feat_series == value)\n","                elif operator == '!=': current_condition_mask &= (feat_series != value)\n","                else: print(f\"    Unknown operator '{operator}'.\"); current_condition_mask[:]=False; break\n","            except Exception as e: print(f\"    Error comparing '{feature}': {e}.\"); current_condition_mask[:]=False; break\n","\n","        if isinstance(current_condition_mask, pd.Series) and not current_condition_mask.empty:\n","            if not current_condition_mask.any():\n","                print(f\"    No cells met conditions for rule '{rule['name']}'.\")\n","                continue\n","            cells_to_label = eligible_mask & current_condition_mask\n","            df_main.loc[cells_to_label, 'rule_based_classification_granular'] = rule['output_label']\n","            print(f\"    {cells_to_label.sum()} cells labeled as '{rule['output_label']}'.\")\n","        else:\n","            print(f\"    Rule '{rule['name']}' resulted in an invalid condition mask or no cells met conditions. No cells labeled by this rule.\")\n","\n","    print(f\"\\nGranular rule-based counts:\\n{df_main['rule_based_classification_granular'].value_counts()}\")\n","    df_main['rule_based_binary_status'] = np.where(df_main['rule_based_classification_granular'] == default_label, 'Non-senescent', 'Senescent')\n","    binary_counts = df_main['rule_based_binary_status'].value_counts(normalize=True) * 100\n","    print(f\"\\nBinary rule-based classification counts:\\n{df_main['rule_based_binary_status'].value_counts()}\")\n","    print(f\"Binary rule-based classification percentages:\\n{binary_counts}\")\n","\n","\n","    if umap_embedding is not None and 'umap_x_refined' in df_main.columns and 'umap_y_refined' in df_main.columns:\n","        plt.figure(figsize=(12,10)); granular_labels = sorted(df_main['rule_based_classification_granular'].unique())\n","        if granular_labels:\n","            pal_gran = sns.color_palette(\"Paired\",n_colors=max(10,len(granular_labels)))\n","            for i,lbl in enumerate(granular_labels): subset=df_main[df_main['rule_based_classification_granular']==lbl]; plt.scatter(subset['umap_x_refined'],subset['umap_y_refined'],label=lbl,color=pal_gran[i%len(pal_gran)],s=15,alpha=0.7)\n","            plt.title('Rule-Based Gating (Granular - UMAP proj.)'); plt.xlabel('UMAP 1'); plt.ylabel('UMAP 2'); plt.legend(title='Rule Class (Granular)',bbox_to_anchor=(1.05,1),loc='upper left'); plt.grid(True,alpha=0.3); plt.tight_layout(rect=[0,0,0.80,1]); plt.savefig(os.path.join(output_dir,'rule_based_gating_granular_on_umap.png'),dpi=300); plt.close()\n","        plt.figure(figsize=(12,10)); binary_labels = sorted(df_main['rule_based_binary_status'].unique()); bin_pal={'Senescent':'red','Non-senescent':'blue','Unknown_Due_To_Missing_Features':'grey'}\n","        for lbl in binary_labels: subset=df_main[df_main['rule_based_binary_status']==lbl]; plt.scatter(subset['umap_x_refined'],subset['umap_y_refined'],label=lbl,color=bin_pal.get(lbl,'grey'),s=15,alpha=0.7)\n","        plt.title('Rule-Based Gating (Binary - UMAP proj.)'); plt.xlabel('UMAP 1'); plt.ylabel('UMAP 2'); plt.legend(title='Rule Status (Binary)',bbox_to_anchor=(1.05,1),loc='upper left'); plt.grid(True,alpha=0.3); plt.tight_layout(rect=[0,0,0.85,1]); plt.savefig(os.path.join(output_dir,'rule_based_gating_binary_on_umap.png'),dpi=300); plt.close()\n","    return df_main\n","\n","def visualize_rule_classification_on_masks(df_results, cell_mask_dir, nuclei_mask_dir, output_dir_masks, classification_column='rule_based_binary_status'):\n","    \"\"\"Visualizes a specified classification column (e.g., rule-based) on original mask images.\"\"\"\n","    print(f\"\\nGenerating classification overlays on original masks using column '{classification_column}' in: {output_dir_masks}\")\n","    if not os.path.exists(output_dir_masks): os.makedirs(output_dir_masks)\n","\n","    sen_color = [255, 0, 0]\n","    nonsen_color = [0, 0, 255]\n","    nuc_outline_color = [255, 255, 0]\n","    cell_boundary_color = [255, 255, 255]\n","    unknown_color = [128, 128, 128]\n","\n","    if 'derived_sample_id' not in df_results.columns or classification_column not in df_results.columns:\n","        print(f\"Error: 'derived_sample_id' or '{classification_column}' not found. Cannot proceed.\"); return\n","\n","    unique_samples = df_results['derived_sample_id'].unique()\n","    if 'cell_id' not in df_results.columns:\n","        print(\"Error: 'cell_id' column not found in df_results.\"); return\n","    classification_lookup = pd.Series(df_results[classification_column].values, index=df_results.cell_id).to_dict()\n","\n","    available_cell_masks = {extract_sample_id(f): f for f in os.listdir(cell_mask_dir) if f.endswith(('.tif', '.tiff'))}\n","    available_nuclei_masks = {extract_sample_id(f): f for f in os.listdir(nuclei_mask_dir) if f.endswith(('.tif', '.tiff'))}\n","\n","    for sample_id_csv in tqdm(unique_samples, desc=f\"Mask viz ({classification_column})\"):\n","        cell_mask_filename = available_cell_masks.get(sample_id_csv)\n","        nuclei_mask_filename = available_nuclei_masks.get(sample_id_csv)\n","        if not cell_mask_filename: print(f\"  Cell mask not found for {sample_id_csv}\"); continue\n","\n","        print(f\"\\n  Overlaying sample: {sample_id_csv}\")\n","        labeled_cell_mask = load_image_as_labeled_mask(os.path.join(cell_mask_dir, cell_mask_filename))\n","        if labeled_cell_mask is None: continue\n","\n","        overlay_image = np.zeros((labeled_cell_mask.shape[0], labeled_cell_mask.shape[1], 3), dtype=np.uint8)\n","\n","        for props in measure.regionprops(labeled_cell_mask):\n","            full_cell_id = f\"{sample_id_csv}_{props.label}\"\n","            status = classification_lookup.get(full_cell_id, 'Unknown')\n","\n","            current_fill_color = unknown_color\n","            if classification_column == 'rule_based_binary_status':\n","                if status == 'Senescent': current_fill_color = sen_color\n","                elif status == 'Non-senescent': current_fill_color = nonsen_color\n","            elif classification_column == 'rule_based_classification_granular':\n","                if status.startswith('Rule_Sen_'): current_fill_color = sen_color\n","                elif status == RULE_BASED_DEFAULT_LABEL : current_fill_color = nonsen_color\n","            overlay_image[labeled_cell_mask == props.label] = current_fill_color\n","\n","        all_cell_boundaries = segmentation.find_boundaries(labeled_cell_mask, mode='outer', background=0)\n","        overlay_image[all_cell_boundaries] = cell_boundary_color\n","\n","        if nuclei_mask_filename:\n","            labeled_nuclei_mask = load_image_as_labeled_mask(os.path.join(nuclei_mask_dir, nuclei_mask_filename))\n","            if labeled_nuclei_mask is not None:\n","                nuclei_boundaries = segmentation.find_boundaries(labeled_nuclei_mask, mode='inner', background=0)\n","                overlay_image[nuclei_boundaries] = nuc_outline_color\n","\n","        # Initialize fig_leg and ax_leg here to ensure they are defined\n","        fig_leg, ax_leg = None, None\n","        try:\n","            fig_leg, ax_leg = plt.subplots(figsize=(max(10, overlay_image.shape[1]/150), max(8, overlay_image.shape[0]/150)), dpi=100) # Reduced divisor for figsize\n","            ax_leg.imshow(overlay_image)\n","\n","            handles = []\n","            # Simplified legend for binary status\n","            if classification_column == 'rule_based_binary_status' or classification_column == 'rule_based_classification_granular': # Common legend items\n","                handles.append(mpatches.Patch(color=np.array(sen_color)/255., label='Senescent (by Rule)'))\n","                handles.append(mpatches.Patch(color=np.array(nonsen_color)/255., label='Non-senescent (by Rule)'))\n","\n","            # Specific legend for granular if needed (can be complex if many rule labels)\n","            # For now, the binary legend is more general.\n","\n","            if 'Unknown' in df_results[classification_column].unique() or 'Unknown' in classification_lookup.values():\n","                 handles.append(mpatches.Patch(color=np.array(unknown_color)/255., label='Unknown'))\n","            if nuclei_mask_filename and labeled_nuclei_mask is not None:\n","                handles.append(mpatches.Patch(color=np.array(nuc_outline_color)/255., label='Nuclei Outline'))\n","            handles.append(mpatches.Patch(edgecolor='white', facecolor='none', label='Cell Boundary', linewidth=1))\n","\n","            ax_leg.legend(handles=handles, loc='upper right', fontsize='xx-small', bbox_to_anchor=(1.65, 1)); # Adjusted bbox, smaller font\n","            ax_leg.axis('off');\n","            plt.tight_layout(pad=0.2)\n","            output_filename = os.path.join(output_dir_masks, f\"{sample_id_csv}_{classification_column}_overlay.png\")\n","            plt.savefig(output_filename, dpi=200); # Increased DPI for better quality\n","            print(f\"    Saved overlay for {sample_id_csv} to {output_filename}\")\n","        except Exception as e_plot:\n","            print(f\"    Error during plotting/saving mask overlay for {sample_id_csv}: {e_plot}\")\n","        finally:\n","            if fig_leg: # Ensure figure is closed even if error occurs after its creation\n","                plt.close(fig_leg)\n","\n","    print(f\"Mask overlay visualization for '{classification_column}' complete.\")\n","\n","\n","def main_exploratory_analysis():\n","    \"\"\"Main function to run exploratory analysis.\"\"\"\n","    if not os.path.exists(EXPLORATORY_OUTPUT_DIR):\n","        os.makedirs(EXPLORATORY_OUTPUT_DIR)\n","        print(f\"Created output directory: {EXPLORATORY_OUTPUT_DIR}\")\n","\n","    df = load_data(INPUT_REFINED_CSV_PATH)\n","    if df is None: return\n","\n","    scaled_features, feature_names_used_for_scaling = preprocess_features_for_ml(df, FEATURES_FOR_ANALYSIS, AREA_FEATURES_TO_LOG)\n","\n","    umap_embedding_for_plotting = None\n","    if 'umap_x_refined' in df.columns and 'umap_y_refined' in df.columns and df['umap_x_refined'].notna().all():\n","        print(\"\\nUsing existing UMAP coordinates from input CSV for visualizations.\")\n","        umap_embedding_for_plotting = df[['umap_x_refined', 'umap_y_refined']].values\n","    elif scaled_features is not None:\n","        print(\"\\nRecomputing UMAP for visualization...\")\n","        try:\n","            reducer = umap.UMAP(n_neighbors=15, min_dist=0.1, random_state=42, n_components=2)\n","            embedding = reducer.fit_transform(scaled_features)\n","            df['umap_x_refined'] = embedding[:, 0]; df['umap_y_refined'] = embedding[:, 1]\n","            umap_embedding_for_plotting = df[['umap_x_refined', 'umap_y_refined']].values\n","            print(\"  UMAP recomputed.\")\n","        except Exception as e: print(f\"  Error recomputing UMAP: {e}.\")\n","    else: print(\"\\nSkipping UMAP computation as scaled features are unavailable.\")\n","\n","    if scaled_features is not None and feature_names_used_for_scaling is not None:\n","        df = compute_and_plot_diffusion_map(df, scaled_features, feature_names_used_for_scaling, EXPLORATORY_OUTPUT_DIR)\n","\n","        DBSCAN_EPS_FOR_SCALED_FEATURES = 2.3\n","        DBSCAN_MIN_SAMPLES_FOR_SCALED_FEATURES = 10\n","        print(f\"\\nNOTE: For DBSCAN on Scaled Features, using EPS = {DBSCAN_EPS_FOR_SCALED_FEATURES}, MIN_SAMPLES = {DBSCAN_MIN_SAMPLES_FOR_SCALED_FEATURES}\")\n","        df = run_dbscan_and_plot(df, scaled_features, \"Scaled_Features\", EXPLORATORY_OUTPUT_DIR,\n","                                 umap_emb=umap_embedding_for_plotting,\n","                                 current_eps_val=DBSCAN_EPS_FOR_SCALED_FEATURES,\n","                                 current_min_samples_val=DBSCAN_MIN_SAMPLES_FOR_SCALED_FEATURES)\n","\n","        df = run_gmm_and_plot(df, scaled_features, \"Scaled_Features\", EXPLORATORY_OUTPUT_DIR, umap_embedding=umap_embedding_for_plotting)\n","\n","        if RUN_DBSCAN_ON_DIFFMAP and SCANPY_AVAILABLE:\n","            dc_cols = [f'dc_{i+1}' for i in range(N_DCS_FOR_DBSCAN) if f'dc_{i+1}' in df.columns and df[f'dc_{i+1}'].notna().any()]\n","            if dc_cols:\n","                data_dc = df[dc_cols].values\n","                DBSCAN_EPS_FOR_DCS = 0.01\n","                DBSCAN_MIN_SAMPLES_FOR_DCS = 10\n","                print(f\"\\nNOTE: For DBSCAN on Top DCs, using EPS = {DBSCAN_EPS_FOR_DCS}, MIN_SAMPLES = {DBSCAN_MIN_SAMPLES_FOR_DCS}\")\n","                df = run_dbscan_and_plot(df, data_dc, f\"Top_{len(dc_cols)}_DCs\", EXPLORATORY_OUTPUT_DIR,\n","                                         umap_emb=umap_embedding_for_plotting,\n","                                         current_eps_val=DBSCAN_EPS_FOR_DCS,\n","                                         current_min_samples_val=DBSCAN_MIN_SAMPLES_FOR_DCS)\n","            else: print(f\"\\nSkipping DBSCAN on DCs: Not enough valid DC columns.\")\n","\n","        global RUN_GMM_ON_DIFFMAP, N_DCS_FOR_GMM\n","        if RUN_GMM_ON_DIFFMAP and SCANPY_AVAILABLE:\n","            dc_cols_gmm = [f'dc_{i+1}' for i in range(N_DCS_FOR_GMM) if f'dc_{i+1}' in df.columns and df[f'dc_{i+1}'].notna().any()]\n","            if dc_cols_gmm:\n","                data_dc_gmm = df[dc_cols_gmm].values\n","                df = run_gmm_and_plot(df, data_dc_gmm, f\"Top_{len(dc_cols_gmm)}_DCs\", EXPLORATORY_OUTPUT_DIR, umap_embedding=umap_embedding_for_plotting)\n","            else: print(f\"\\nSkipping GMM on DCs: Not enough valid DC columns.\")\n","\n","    # Apply rule-based gating using the main df.\n","    df = apply_rule_based_gating(df, RULE_BASED_GATES, RULE_BASED_DEFAULT_LABEL, EXPLORATORY_OUTPUT_DIR, umap_embedding=umap_embedding_for_plotting)\n","\n","    # Visualize the rule-based classification on masks\n","    mask_overlay_output_path = os.path.join(EXPLORATORY_OUTPUT_DIR, MASK_VISUALIZATION_SUBDIR_RULES)\n","    if 'rule_based_binary_status' in df.columns:\n","        visualize_rule_classification_on_masks(df, CELL_MASK_DIR, NUCLEI_MASK_DIR, mask_overlay_output_path, classification_column='rule_based_binary_status')\n","        # visualize_rule_classification_on_masks(df, CELL_MASK_DIR, NUCLEI_MASK_DIR, mask_overlay_output_path, classification_column='rule_based_classification_granular')\n","    else:\n","        print(\"Skipping mask visualization for rule-based classification as the classification column is missing.\")\n","\n","\n","    exploratory_csv_path = os.path.join(EXPLORATORY_OUTPUT_DIR, 'exploratory_analysis_results_v5_rules_maskviz.csv')\n","    df.to_csv(exploratory_csv_path, index=False)\n","    print(f\"\\nExploratory analysis results saved to: {exploratory_csv_path}\")\n","    print(\"\\nExploratory analysis script finished.\")\n","\n","RUN_GMM_ON_DIFFMAP = True\n","N_DCS_FOR_GMM = 3\n","\n","if __name__ == '__main__':\n","    main_exploratory_analysis()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ojYh9bPVAaSP","executionInfo":{"status":"ok","timestamp":1747212989524,"user_tz":-120,"elapsed":51776,"user":{"displayName":"Guido Putignano","userId":"13974663347531370398"}},"outputId":"d869413d-6275-4634-e318-87688d1cab24"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading refined data from /content/drive/MyDrive/knowledge/University/Master/Thesis/Analysis/flow3-x20/Senescence_Refined_V5_DiffMap/cell_classification_results_refined.csv...\n","Successfully loaded 2472 cells.\n","  Derived 'derived_sample_id' from 'cell_id' for mask matching.\n","\n","Preprocessing features for ML. Selected: ['cell_area', 'cell_perimeter', 'cell_eccentricity', 'cell_circularity', 'cell_aspect_ratio', 'avg_nucleus_area', 'max_nucleus_area', 'avg_nucleus_eccentricity', 'nucleus_area_std', 'nucleus_displacement', 'nucleus_to_cell_area_ratio', 'nuclear_enlargement', 'cell_enlargement']\n","  Log-transformed for scaling: cell_area\n","  Log-transformed for scaling: avg_nucleus_area\n","  Log-transformed for scaling: max_nucleus_area\n","  Log-transformed for scaling: cell_perimeter\n","  Features standardized for ML algorithms.\n","\n","Using existing UMAP coordinates from input CSV for visualizations.\n","\n","--- Computing Diffusion Map ---\n","  Computing neighbors (k=15)...\n","  Running sc.tl.diffmap...\n","  Added 9 DCs to DataFrame.\n","  DiffMap pair plots for top 3 DCs saved.\n","\n","NOTE: For DBSCAN on Scaled Features, using EPS = 2.3, MIN_SAMPLES = 10\n","\n","--- Running DBSCAN on Scaled_Features ---\n","  Running DBSCAN with eps=2.3, min_samples=10 on Scaled_Features...\n","  DBSCAN on Scaled_Features: 1 clusters, 137 noise (5.54%).\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-27-8b71f90f7c42>:233: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n","  dbscan_cmap_obj = plt.cm.get_cmap('Spectral', n_actual_clusters)\n"]},{"output_type":"stream","name":"stdout","text":["  DBSCAN on Scaled_Features plotted on UMAP.\n","\n","--- Running GMM on Scaled_Features ---\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n","  # that has no feature names.\n","/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n","  # that has no feature names.\n","/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n","  # that has no feature names.\n"]},{"output_type":"stream","name":"stdout","text":["    GMM 2 comps: BIC=-11876.19\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n","  # that has no feature names.\n","/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n","  # that has no feature names.\n"]},{"output_type":"stream","name":"stdout","text":["    GMM 3 comps: BIC=-20370.16\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n","  # that has no feature names.\n","/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n","  # that has no feature names.\n","/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n","  # that has no feature names.\n"]},{"output_type":"stream","name":"stdout","text":["    GMM 4 comps: BIC=-26836.71\n","  Best GMM: 4 components (BIC=-26836.71).\n","  Mean sen_score per GMM comp (Scaled_Features):\n","gmm_scaled_features\n","1    0.316948\n","0    0.365966\n","3    0.500682\n","2    0.500958\n","Name: senescence_score_normalized, dtype: float64\n","\n","NOTE: For DBSCAN on Top DCs, using EPS = 0.01, MIN_SAMPLES = 10\n","\n","--- Running DBSCAN on Top_3_DCs ---\n","  Running DBSCAN with eps=0.01, min_samples=10 on Top_3_DCs...\n","  DBSCAN on Top_3_DCs: 2 clusters, 42 noise (1.70%).\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-27-8b71f90f7c42>:233: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n","  dbscan_cmap_obj = plt.cm.get_cmap('Spectral', n_actual_clusters)\n"]},{"output_type":"stream","name":"stdout","text":["  DBSCAN on Top_3_DCs plotted on UMAP.\n","\n","--- Running GMM on Top_3_DCs ---\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n","  # that has no feature names.\n","/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n","  # that has no feature names.\n","/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n","  # that has no feature names.\n","/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n","  # that has no feature names.\n","/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n","  # that has no feature names.\n"]},{"output_type":"stream","name":"stdout","text":["    GMM 2 comps: BIC=-42744.54\n","    GMM 3 comps: BIC=-43790.09\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n","  # that has no feature names.\n","/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n","  # that has no feature names.\n","/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n","  # that has no feature names.\n"]},{"output_type":"stream","name":"stdout","text":["    GMM 4 comps: BIC=-44590.14\n","  Best GMM: 4 components (BIC=-44590.14).\n","  Mean sen_score per GMM comp (Top_3_DCs):\n","gmm_top_3_dcs\n","0    0.319583\n","1    0.398703\n","2    0.427525\n","3    0.543944\n","Name: senescence_score_normalized, dtype: float64\n","\n","--- Applying Rule-Based Gating ---\n","  Applying rule: Polynucleated\n","    225 cells labeled as 'Rule_Sen_Poly'.\n","  Applying rule: Very_Large_Cell\n","    307 cells labeled as 'Rule_Sen_VeryLarge'.\n","  Applying rule: Low_Circularity\n","    3 cells labeled as 'Rule_Sen_LowCirc'.\n","  Applying rule: Low_NucToCellRatio\n","    103 cells labeled as 'Rule_Sen_LowNucRatio'.\n","  Applying rule: High_Score_Not_Otherwise_Caught\n","    0 cells labeled as 'Rule_Sen_HighScore'.\n","\n","Granular rule-based counts:\n","rule_based_classification_granular\n","Rule_NonSenescent       1834\n","Rule_Sen_VeryLarge       307\n","Rule_Sen_Poly            225\n","Rule_Sen_LowNucRatio     103\n","Rule_Sen_LowCirc           3\n","Name: count, dtype: int64\n","\n","Binary rule-based classification counts:\n","rule_based_binary_status\n","Non-senescent    1834\n","Senescent         638\n","Name: count, dtype: int64\n","Binary rule-based classification percentages:\n","rule_based_binary_status\n","Non-senescent    74.190939\n","Senescent        25.809061\n","Name: proportion, dtype: float64\n","\n","Generating classification overlays on original masks using column 'rule_based_binary_status' in: /content/drive/MyDrive/knowledge/University/Master/Thesis/Analysis/flow3-x20/Exploratory_Analysis_V5_rules_mask_viz/mask_overlays_rule_based\n"]},{"output_type":"stream","name":"stderr","text":["\rMask viz (rule_based_binary_status):   0%|          | 0/8 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","  Overlaying sample: 0Pa_U_05mar19_20x_L2RA_Flat_seq001\n","    Loading mask: 0Pa_U_05mar19_20x_L2RA_Flat_seq001_cell_mask_merged_conservative.tif\n","    Loading mask: denoised_0Pa_U_05mar19_20x_L2RA_Flat_seq001_Cadherins_filtered_mask.tif\n"]},{"output_type":"stream","name":"stderr","text":["\rMask viz (rule_based_binary_status):  12%|█▎        | 1/8 [00:01<00:12,  1.74s/it]"]},{"output_type":"stream","name":"stdout","text":["    Saved overlay for 0Pa_U_05mar19_20x_L2RA_Flat_seq001 to /content/drive/MyDrive/knowledge/University/Master/Thesis/Analysis/flow3-x20/Exploratory_Analysis_V5_rules_mask_viz/mask_overlays_rule_based/0Pa_U_05mar19_20x_L2RA_Flat_seq001_rule_based_binary_status_overlay.png\n","\n","  Overlaying sample: 0Pa_U_05mar19_20x_L2RA_Flat_seq002\n","    Loading mask: 0Pa_U_05mar19_20x_L2RA_Flat_seq002_cell_mask_merged_conservative.tif\n","    Loading mask: denoised_0Pa_U_05mar19_20x_L2RA_Flat_seq002_Cadherins_filtered_mask.tif\n"]},{"output_type":"stream","name":"stderr","text":["\rMask viz (rule_based_binary_status):  25%|██▌       | 2/8 [00:03<00:11,  1.84s/it]"]},{"output_type":"stream","name":"stdout","text":["    Saved overlay for 0Pa_U_05mar19_20x_L2RA_Flat_seq002 to /content/drive/MyDrive/knowledge/University/Master/Thesis/Analysis/flow3-x20/Exploratory_Analysis_V5_rules_mask_viz/mask_overlays_rule_based/0Pa_U_05mar19_20x_L2RA_Flat_seq002_rule_based_binary_status_overlay.png\n","\n","  Overlaying sample: 0Pa_U_05mar19_20x_L2RA_Flat_seq003\n","    Loading mask: 0Pa_U_05mar19_20x_L2RA_Flat_seq003_cell_mask_merged_conservative.tif\n","    Loading mask: denoised_0Pa_U_05mar19_20x_L2RA_Flat_seq003_Cadherins_filtered_mask.tif\n"]},{"output_type":"stream","name":"stderr","text":["\rMask viz (rule_based_binary_status):  38%|███▊      | 3/8 [00:05<00:09,  1.85s/it]"]},{"output_type":"stream","name":"stdout","text":["    Saved overlay for 0Pa_U_05mar19_20x_L2RA_Flat_seq003 to /content/drive/MyDrive/knowledge/University/Master/Thesis/Analysis/flow3-x20/Exploratory_Analysis_V5_rules_mask_viz/mask_overlays_rule_based/0Pa_U_05mar19_20x_L2RA_Flat_seq003_rule_based_binary_status_overlay.png\n","\n","  Overlaying sample: 1.4Pa_U_05mar19_20x_L2R_Flat_seq001\n","    Loading mask: 1.4Pa_U_05mar19_20x_L2R_Flat_seq001_cell_mask_merged_conservative.tif\n","    Loading mask: denoised_1.4Pa_U_05mar19_20x_L2R_Flat_seq001_Cadherins_filtered_mask.tif\n"]},{"output_type":"stream","name":"stderr","text":["\rMask viz (rule_based_binary_status):  50%|█████     | 4/8 [00:07<00:07,  1.77s/it]"]},{"output_type":"stream","name":"stdout","text":["    Saved overlay for 1.4Pa_U_05mar19_20x_L2R_Flat_seq001 to /content/drive/MyDrive/knowledge/University/Master/Thesis/Analysis/flow3-x20/Exploratory_Analysis_V5_rules_mask_viz/mask_overlays_rule_based/1.4Pa_U_05mar19_20x_L2R_Flat_seq001_rule_based_binary_status_overlay.png\n","\n","  Overlaying sample: 1.4Pa_U_05mar19_20x_L2R_Flat_seq002\n","    Loading mask: 1.4Pa_U_05mar19_20x_L2R_Flat_seq002_cell_mask_merged_conservative.tif\n","    Loading mask: denoised_1.4Pa_U_05mar19_20x_L2R_Flat_seq002_Cadherins_filtered_mask.tif\n"]},{"output_type":"stream","name":"stderr","text":["\rMask viz (rule_based_binary_status):  62%|██████▎   | 5/8 [00:08<00:04,  1.63s/it]"]},{"output_type":"stream","name":"stdout","text":["    Saved overlay for 1.4Pa_U_05mar19_20x_L2R_Flat_seq002 to /content/drive/MyDrive/knowledge/University/Master/Thesis/Analysis/flow3-x20/Exploratory_Analysis_V5_rules_mask_viz/mask_overlays_rule_based/1.4Pa_U_05mar19_20x_L2R_Flat_seq002_rule_based_binary_status_overlay.png\n","\n","  Overlaying sample: 1.4Pa_U_05mar19_20x_L2R_Flat_seq003\n","    Loading mask: 1.4Pa_U_05mar19_20x_L2R_Flat_seq003_cell_mask_merged_conservative.tif\n","    Loading mask: denoised_1.4Pa_U_05mar19_20x_L2R_Flat_seq003_Cadherins_filtered_mask.tif\n"]},{"output_type":"stream","name":"stderr","text":["\rMask viz (rule_based_binary_status):  75%|███████▌  | 6/8 [00:10<00:03,  1.65s/it]"]},{"output_type":"stream","name":"stdout","text":["    Saved overlay for 1.4Pa_U_05mar19_20x_L2R_Flat_seq003 to /content/drive/MyDrive/knowledge/University/Master/Thesis/Analysis/flow3-x20/Exploratory_Analysis_V5_rules_mask_viz/mask_overlays_rule_based/1.4Pa_U_05mar19_20x_L2R_Flat_seq003_rule_based_binary_status_overlay.png\n","\n","  Overlaying sample: 1.4Pa_U_05mar19_20x_L2R_Flat_seq004\n","    Loading mask: 1.4Pa_U_05mar19_20x_L2R_Flat_seq004_cell_mask_merged_conservative.tif\n","    Loading mask: denoised_1.4Pa_U_05mar19_20x_L2R_Flat_seq004_Cadherins_filtered_mask.tif\n"]},{"output_type":"stream","name":"stderr","text":["\rMask viz (rule_based_binary_status):  88%|████████▊ | 7/8 [00:12<00:01,  1.90s/it]"]},{"output_type":"stream","name":"stdout","text":["    Saved overlay for 1.4Pa_U_05mar19_20x_L2R_Flat_seq004 to /content/drive/MyDrive/knowledge/University/Master/Thesis/Analysis/flow3-x20/Exploratory_Analysis_V5_rules_mask_viz/mask_overlays_rule_based/1.4Pa_U_05mar19_20x_L2R_Flat_seq004_rule_based_binary_status_overlay.png\n","\n","  Overlaying sample: 1.4Pa_U_05mar19_20x_L2R_Flat_seq005\n","    Loading mask: 1.4Pa_U_05mar19_20x_L2R_Flat_seq005_cell_mask_merged_conservative.tif\n","    Loading mask: denoised_1.4Pa_U_05mar19_20x_L2R_Flat_seq005_Cadherins_filtered_mask.tif\n"]},{"output_type":"stream","name":"stderr","text":["Mask viz (rule_based_binary_status): 100%|██████████| 8/8 [00:14<00:00,  1.86s/it]"]},{"output_type":"stream","name":"stdout","text":["    Saved overlay for 1.4Pa_U_05mar19_20x_L2R_Flat_seq005 to /content/drive/MyDrive/knowledge/University/Master/Thesis/Analysis/flow3-x20/Exploratory_Analysis_V5_rules_mask_viz/mask_overlays_rule_based/1.4Pa_U_05mar19_20x_L2R_Flat_seq005_rule_based_binary_status_overlay.png\n","Mask overlay visualization for 'rule_based_binary_status' complete.\n","\n","Exploratory analysis results saved to: /content/drive/MyDrive/knowledge/University/Master/Thesis/Analysis/flow3-x20/Exploratory_Analysis_V5_rules_mask_viz/exploratory_analysis_results_v5_rules_maskviz.csv\n","\n","Exploratory analysis script finished.\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["import os\n","import re\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as mpatches\n","from skimage import io, measure, segmentation\n","import cv2\n","from scipy import ndimage\n","from tqdm import tqdm\n","\n","# --- Configuration & Parameters ---\n","# !! UPDATE THESE PATHS !!\n","# Path to the CSV file generated by the exploratory_analysis_script\n","# This CSV must contain 'derived_sample_id', 'cell_id', and 'rule_based_classification_granular'\n","INPUT_EXPLORATORY_CSV_PATH = \"/content/drive/MyDrive/knowledge/University/Master/Thesis/Analysis/flow3-x20/Exploratory_Analysis_V5_rules_mask_viz/exploratory_analysis_results_v5_rules_maskviz.csv\"\n","\n","# Output directory for these new enhanced mask visualizations\n","ENHANCED_MASK_OUTPUT_DIR = \"/content/drive/MyDrive/knowledge/University/Master/Thesis/Analysis/flow3-x20/Enhanced_Mask_Overlays_Poly_Highlight_Fix\" # Incremented\n","\n","# Paths to your original mask image directories\n","CELL_MASK_DIR = \"/content/drive/MyDrive/knowledge/University/Master/Thesis/Segmented/flow3-x20/Cell_merged_conservative\"\n","NUCLEI_MASK_DIR = \"/content/drive/MyDrive/knowledge/University/Master/Thesis/Segmented/flow3-x20/Nuclei\"\n","\n","# Label from your RULE_BASED_GATES that specifically identifies polynucleated senescent cells\n","POLYNUCLEATED_SENESCENT_RULE_LABEL = 'Rule_Sen_Poly'\n","# Default label for cells not caught by any \"Senescent\" rule\n","NON_SENESCENT_DEFAULT_RULE_LABEL = 'Rule_NonSenescent'\n","\n","\n","# --- Color Definitions ---\n","COLOR_NON_SENESCENT = [0, 0, 255]  # Blue\n","COLOR_SENESCENT_POLYNUCLEATED = [255, 165, 0]  # Orange\n","COLOR_SENESCENT_OTHER_RULES = [255, 0, 0]  # Red\n","COLOR_CELL_BOUNDARY = [255, 255, 255]  # White\n","COLOR_NUCLEI_OUTLINE = [255, 255, 0]  # Yellow\n","COLOR_UNKNOWN = [128, 128, 128] # Grey\n","\n","# --- Helper Functions ---\n","def extract_sample_id(filename):\n","    \"\"\"Extracts sample ID from filename.\"\"\"\n","    base_name = os.path.splitext(filename)[0]\n","    if base_name.startswith('denoised_'):\n","        base_name = base_name[len('denoised_'):]\n","    pattern = re.compile(r'([\\d\\.]+Pa_[^_]+_[^_]+_[^_]+_[^_]+_[^_]+_seq\\d+)')\n","    match = pattern.search(base_name)\n","    if match: return match.group(1)\n","    parts = base_name.split('_')\n","    for i, part in enumerate(parts):\n","        if part.startswith('seq') and i >= 2: return '_'.join(parts[:i+1])\n","    common_prefix = \"_\".join(filename.split('_')[:6])\n","    return common_prefix if 'seq' in common_prefix else os.path.splitext(os.path.basename(filename))[0]\n","\n","def load_image_as_labeled_mask(filepath):\n","    \"\"\"Loads a mask image, ensuring it's a labeled integer mask.\"\"\"\n","    # print(f\"    Loading mask: {os.path.basename(filepath)}\") # Reduced verbosity\n","    try:\n","        img = io.imread(filepath)\n","        if img.ndim > 2:\n","            if img.shape[-1] == 3: img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n","            elif img.shape[-1] == 4: img = cv2.cvtColor(img, cv2.COLOR_RGBA2GRAY)\n","            else: img = img[..., 0]\n","        if img.dtype.kind in 'iu' and np.max(img) > 1: return img.astype(np.uint16)\n","        if img.dtype.kind == 'f': img = (img > 0.5).astype(np.uint8)\n","        elif np.max(img) == 1: img = img.astype(np.uint8)\n","        if np.max(img) <=1 :\n","            labeled_img, num_features = ndimage.label(img)\n","            # print(f\"    Labeled binary mask {os.path.basename(filepath)}, found {num_features} features.\")\n","            return labeled_img.astype(np.uint16)\n","        return img.astype(np.uint16)\n","    except Exception as e:\n","        print(f\"    Error loading image {filepath}: {str(e)}\"); return None\n","\n","def visualize_enhanced_classification_on_masks(df_results, cell_mask_dir, nuclei_mask_dir, output_dir):\n","    \"\"\"\n","    Visualizes cell classifications on original mask images, highlighting polynucleated senescent cells.\n","    Uses 'rule_based_classification_granular' for detailed coloring.\n","    \"\"\"\n","    print(f\"\\nGenerating enhanced classification overlays in: {output_dir}\")\n","    if not os.path.exists(output_dir):\n","        os.makedirs(output_dir)\n","\n","    required_cols = ['derived_sample_id', 'cell_id', 'rule_based_classification_granular']\n","    if not all(col in df_results.columns for col in required_cols):\n","        missing = [col for col in required_cols if col not in df_results.columns]\n","        print(f\"Error: DataFrame is missing required columns: {missing}. Cannot proceed with visualization.\")\n","        return\n","\n","    classification_lookup = pd.Series(\n","        df_results.rule_based_classification_granular.values,\n","        index=df_results.cell_id\n","    ).to_dict()\n","\n","    unique_samples = df_results['derived_sample_id'].unique()\n","    available_cell_masks = {extract_sample_id(f): f for f in os.listdir(cell_mask_dir) if f.endswith(('.tif', '.tiff'))}\n","    available_nuclei_masks = {extract_sample_id(f): f for f in os.listdir(nuclei_mask_dir) if f.endswith(('.tif', '.tiff'))}\n","\n","    for sample_id_csv in tqdm(unique_samples, desc=\"Generating Enhanced Mask Overlays\"):\n","        cell_mask_filename = available_cell_masks.get(sample_id_csv)\n","        nuclei_mask_filename = available_nuclei_masks.get(sample_id_csv)\n","\n","        if not cell_mask_filename:\n","            print(f\"  Warning: Cell mask file not found for sample ID: {sample_id_csv}\")\n","            continue\n","\n","        print(f\"\\n  Processing sample for enhanced overlay: {sample_id_csv}\")\n","        labeled_cell_mask = load_image_as_labeled_mask(os.path.join(cell_mask_dir, cell_mask_filename))\n","        if labeled_cell_mask is None:\n","            continue\n","\n","        overlay_image = np.zeros((labeled_cell_mask.shape[0], labeled_cell_mask.shape[1], 3), dtype=np.uint8)\n","\n","        # 1. Fill cells based on granular rule classification\n","        for props in measure.regionprops(labeled_cell_mask):\n","            full_cell_id = f\"{sample_id_csv}_{props.label}\"\n","            granular_status = classification_lookup.get(full_cell_id, 'Unknown_Rule')\n","\n","            current_fill_color = COLOR_UNKNOWN\n","            if granular_status == POLYNUCLEATED_SENESCENT_RULE_LABEL:\n","                current_fill_color = COLOR_SENESCENT_POLYNUCLEATED\n","            elif granular_status.startswith('Rule_Sen_'):\n","                current_fill_color = COLOR_SENESCENT_OTHER_RULES\n","            elif granular_status == NON_SENESCENT_DEFAULT_RULE_LABEL:\n","                current_fill_color = COLOR_NON_SENESCENT\n","\n","            overlay_image[labeled_cell_mask == props.label] = current_fill_color\n","\n","        # 2. Draw cell boundaries\n","        all_cell_boundaries = segmentation.find_boundaries(labeled_cell_mask, mode='outer', background=0)\n","        overlay_image[all_cell_boundaries] = COLOR_CELL_BOUNDARY\n","\n","        # 3. Overlay nuclei outlines\n","        labeled_nuclei_mask = None # Initialize for the finally block\n","        if nuclei_mask_filename:\n","            labeled_nuclei_mask = load_image_as_labeled_mask(os.path.join(nuclei_mask_dir, nuclei_mask_filename))\n","            if labeled_nuclei_mask is not None:\n","                nuclei_boundaries = segmentation.find_boundaries(labeled_nuclei_mask, mode='inner', background=0)\n","                overlay_image[nuclei_boundaries] = COLOR_NUCLEI_OUTLINE\n","\n","        # Save the overlay image with legend\n","        fig_legend, ax_legend_obj = None, None # Use a different name to avoid confusion if ax_leg was a typo elsewhere\n","        try:\n","            img_h, img_w = overlay_image.shape[:2]\n","            fig_w = max(10, img_w / 100 if img_w > 0 else 10)\n","            fig_h = max(8, img_h / 100 if img_h > 0 else 8) * (fig_w / (img_w/100 if img_w > 0 else 1))\n","\n","            fig_legend, ax_legend_obj = plt.subplots(figsize=(fig_w, fig_h), dpi=100)\n","            ax_legend_obj.imshow(overlay_image)\n","\n","            handles = [\n","                mpatches.Patch(color=np.array(COLOR_NON_SENESCENT)/255., label='Non-senescent (Rule)'),\n","                mpatches.Patch(color=np.array(COLOR_SENESCENT_OTHER_RULES)/255., label='Senescent (Other Rules)'),\n","                mpatches.Patch(color=np.array(COLOR_SENESCENT_POLYNUCLEATED)/255., label=f'Senescent ({POLYNUCLEATED_SENESCENT_RULE_LABEL})')\n","            ]\n","            # Check if 'Unknown_Rule' actually occurred for this specific sample or globally in the lookup\n","            # This avoids adding 'Unknown' to legend if no cells were actually unknown.\n","            unknown_present_in_sample = any(classification_lookup.get(f\"{sample_id_csv}_{p.label}\", 'Unknown_Rule') == 'Unknown_Rule'\n","                                            for p in measure.regionprops(labeled_cell_mask))\n","            if unknown_present_in_sample:\n","                 handles.append(mpatches.Patch(color=np.array(COLOR_UNKNOWN)/255., label='Unknown/Not in CSV'))\n","\n","            if nuclei_mask_filename and labeled_nuclei_mask is not None:\n","                handles.append(mpatches.Patch(color=np.array(COLOR_NUCLEI_OUTLINE)/255., label='Nuclei Outline'))\n","            handles.append(mpatches.Patch(edgecolor=np.array(COLOR_CELL_BOUNDARY)/255., facecolor='none', label='Cell Boundary', linewidth=1))\n","\n","            # CORRECTED TYPO: ax_legend_obj instead of ax_leg\n","            ax_legend_obj.legend(handles=handles, loc='center left', bbox_to_anchor=(1.02, 0.5), fontsize='small')\n","            ax_legend_obj.axis('off')\n","            plt.tight_layout(rect=[0, 0, 0.85, 1])\n","\n","            output_filename = os.path.join(output_dir, f\"{sample_id_csv}_enhanced_overlay.png\")\n","            plt.savefig(output_filename, dpi=200)\n","            print(f\"    Saved enhanced overlay for {sample_id_csv} to {output_filename}\")\n","        except Exception as e_plot:\n","            print(f\"    Error during plotting/saving mask overlay for {sample_id_csv}: {e_plot}\")\n","        finally:\n","            if fig_legend:\n","                plt.close(fig_legend)\n","\n","    print(\"\\nEnhanced mask overlay visualization complete.\")\n","\n","\n","def main():\n","    \"\"\"Main function to run the enhanced mask visualization.\"\"\"\n","    if not os.path.exists(ENHANCED_MASK_OUTPUT_DIR):\n","        os.makedirs(ENHANCED_MASK_OUTPUT_DIR)\n","        print(f\"Created output directory: {ENHANCED_MASK_OUTPUT_DIR}\")\n","\n","    df_results = pd.read_csv(INPUT_EXPLORATORY_CSV_PATH)\n","    if df_results is None: # Should be if df_results is None, not if pd.read_csv is None\n","        print(f\"Failed to load data from {INPUT_EXPLORATORY_CSV_PATH}\")\n","        return\n","\n","    if 'derived_sample_id' not in df_results.columns and 'cell_id' in df_results.columns:\n","        df_results['derived_sample_id'] = df_results['cell_id'].apply(lambda x: '_'.join(x.split('_')[:-1]))\n","        print(\"  Derived 'derived_sample_id' from 'cell_id' for mask matching (main).\")\n","\n","\n","    visualize_enhanced_classification_on_masks(\n","        df_results,\n","        CELL_MASK_DIR,\n","        NUCLEI_MASK_DIR,\n","        ENHANCED_MASK_OUTPUT_DIR\n","    )\n","\n","    print(\"\\nScript finished.\")\n","\n","if __name__ == '__main__':\n","    main()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J4NwoFoFDSn_","executionInfo":{"status":"ok","timestamp":1747213794489,"user_tz":-120,"elapsed":15078,"user":{"displayName":"Guido Putignano","userId":"13974663347531370398"}},"outputId":"b97eafce-9621-4636-a2ef-1d66f91e7200"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["Created output directory: /content/drive/MyDrive/knowledge/University/Master/Thesis/Analysis/flow3-x20/Enhanced_Mask_Overlays_Poly_Highlight_Fix\n","\n","Generating enhanced classification overlays in: /content/drive/MyDrive/knowledge/University/Master/Thesis/Analysis/flow3-x20/Enhanced_Mask_Overlays_Poly_Highlight_Fix\n"]},{"output_type":"stream","name":"stderr","text":["\rGenerating Enhanced Mask Overlays:   0%|          | 0/8 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","  Processing sample for enhanced overlay: 0Pa_U_05mar19_20x_L2RA_Flat_seq001\n"]},{"output_type":"stream","name":"stderr","text":["\rGenerating Enhanced Mask Overlays:  12%|█▎        | 1/8 [00:01<00:12,  1.77s/it]"]},{"output_type":"stream","name":"stdout","text":["    Saved enhanced overlay for 0Pa_U_05mar19_20x_L2RA_Flat_seq001 to /content/drive/MyDrive/knowledge/University/Master/Thesis/Analysis/flow3-x20/Enhanced_Mask_Overlays_Poly_Highlight_Fix/0Pa_U_05mar19_20x_L2RA_Flat_seq001_enhanced_overlay.png\n","\n","  Processing sample for enhanced overlay: 0Pa_U_05mar19_20x_L2RA_Flat_seq002\n"]},{"output_type":"stream","name":"stderr","text":["\rGenerating Enhanced Mask Overlays:  25%|██▌       | 2/8 [00:03<00:10,  1.81s/it]"]},{"output_type":"stream","name":"stdout","text":["    Saved enhanced overlay for 0Pa_U_05mar19_20x_L2RA_Flat_seq002 to /content/drive/MyDrive/knowledge/University/Master/Thesis/Analysis/flow3-x20/Enhanced_Mask_Overlays_Poly_Highlight_Fix/0Pa_U_05mar19_20x_L2RA_Flat_seq002_enhanced_overlay.png\n","\n","  Processing sample for enhanced overlay: 0Pa_U_05mar19_20x_L2RA_Flat_seq003\n"]},{"output_type":"stream","name":"stderr","text":["\rGenerating Enhanced Mask Overlays:  38%|███▊      | 3/8 [00:05<00:09,  1.88s/it]"]},{"output_type":"stream","name":"stdout","text":["    Saved enhanced overlay for 0Pa_U_05mar19_20x_L2RA_Flat_seq003 to /content/drive/MyDrive/knowledge/University/Master/Thesis/Analysis/flow3-x20/Enhanced_Mask_Overlays_Poly_Highlight_Fix/0Pa_U_05mar19_20x_L2RA_Flat_seq003_enhanced_overlay.png\n","\n","  Processing sample for enhanced overlay: 1.4Pa_U_05mar19_20x_L2R_Flat_seq001\n"]},{"output_type":"stream","name":"stderr","text":["\rGenerating Enhanced Mask Overlays:  50%|█████     | 4/8 [00:07<00:07,  1.76s/it]"]},{"output_type":"stream","name":"stdout","text":["    Saved enhanced overlay for 1.4Pa_U_05mar19_20x_L2R_Flat_seq001 to /content/drive/MyDrive/knowledge/University/Master/Thesis/Analysis/flow3-x20/Enhanced_Mask_Overlays_Poly_Highlight_Fix/1.4Pa_U_05mar19_20x_L2R_Flat_seq001_enhanced_overlay.png\n","\n","  Processing sample for enhanced overlay: 1.4Pa_U_05mar19_20x_L2R_Flat_seq002\n"]},{"output_type":"stream","name":"stderr","text":["\rGenerating Enhanced Mask Overlays:  62%|██████▎   | 5/8 [00:09<00:05,  1.84s/it]"]},{"output_type":"stream","name":"stdout","text":["    Saved enhanced overlay for 1.4Pa_U_05mar19_20x_L2R_Flat_seq002 to /content/drive/MyDrive/knowledge/University/Master/Thesis/Analysis/flow3-x20/Enhanced_Mask_Overlays_Poly_Highlight_Fix/1.4Pa_U_05mar19_20x_L2R_Flat_seq002_enhanced_overlay.png\n","\n","  Processing sample for enhanced overlay: 1.4Pa_U_05mar19_20x_L2R_Flat_seq003\n"]},{"output_type":"stream","name":"stderr","text":["\rGenerating Enhanced Mask Overlays:  75%|███████▌  | 6/8 [00:11<00:04,  2.06s/it]"]},{"output_type":"stream","name":"stdout","text":["    Saved enhanced overlay for 1.4Pa_U_05mar19_20x_L2R_Flat_seq003 to /content/drive/MyDrive/knowledge/University/Master/Thesis/Analysis/flow3-x20/Enhanced_Mask_Overlays_Poly_Highlight_Fix/1.4Pa_U_05mar19_20x_L2R_Flat_seq003_enhanced_overlay.png\n","\n","  Processing sample for enhanced overlay: 1.4Pa_U_05mar19_20x_L2R_Flat_seq004\n"]},{"output_type":"stream","name":"stderr","text":["\rGenerating Enhanced Mask Overlays:  88%|████████▊ | 7/8 [00:13<00:01,  1.91s/it]"]},{"output_type":"stream","name":"stdout","text":["    Saved enhanced overlay for 1.4Pa_U_05mar19_20x_L2R_Flat_seq004 to /content/drive/MyDrive/knowledge/University/Master/Thesis/Analysis/flow3-x20/Enhanced_Mask_Overlays_Poly_Highlight_Fix/1.4Pa_U_05mar19_20x_L2R_Flat_seq004_enhanced_overlay.png\n","\n","  Processing sample for enhanced overlay: 1.4Pa_U_05mar19_20x_L2R_Flat_seq005\n"]},{"output_type":"stream","name":"stderr","text":["Generating Enhanced Mask Overlays: 100%|██████████| 8/8 [00:14<00:00,  1.87s/it]"]},{"output_type":"stream","name":"stdout","text":["    Saved enhanced overlay for 1.4Pa_U_05mar19_20x_L2R_Flat_seq005 to /content/drive/MyDrive/knowledge/University/Master/Thesis/Analysis/flow3-x20/Enhanced_Mask_Overlays_Poly_Highlight_Fix/1.4Pa_U_05mar19_20x_L2R_Flat_seq005_enhanced_overlay.png\n","\n","Enhanced mask overlay visualization complete.\n","\n","Script finished.\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]}]}