{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP/18qxknXvpuD9+flI/CnL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# Hole Analysis Code - Optimized for Binary Masks\n","# This code analyzes hole TIFF images that are binary masks (0s and 1s)\n","# Follows the same structure as the original cell analysis code\n","# Enhanced with proper binary mask handling and additional hole shape metrics\n","\n","import pandas as pd\n","import numpy as np\n","import os\n","import cv2\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from google.colab import drive\n","import re\n","from skimage import measure, filters\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","# Processing parameters (adjustable)\n","MIN_HOLE_SIZE = 3          # Minimum hole size in pixels (changed from 10 to capture smaller holes)\n","MAX_HOLE_FRACTION = 0.9    # Maximum hole size as fraction of total image\n","GAUSSIAN_KERNEL = (3, 3)   # Gaussian blur kernel size\n","GAUSSIAN_SIGMA = 0.5       # Gaussian blur standard deviation\n","MORPH_KERNEL_SIZE = 3      # Morphological operations kernel size\n","BRIDGE_KERNEL_SIZE = 2     # Small kernel for bridging nearby pixels\n","\n","# Mount Google Drive - This will require authorization\n","try:\n","    drive.mount('/content/drive')\n","    print(\"Google Drive mounted successfully.\")\n","except Exception as e:\n","    print(f\"Error mounting Google Drive: {e}\")\n","    print(\"Please ensure you are running this in a Google Colab environment and authorize access.\")\n","    # Exit if drive mounting fails, as further operations will fail\n","    exit()\n","\n","# Define the base path and folder names\n","# IMPORTANT: Verify this base_path is correct after mounting your drive!\n","base_path = \"/content/drive/MyDrive/knowledge/University/Master/Thesis/Segmented/\"\n","folders = [\"Static-x40\", \"Static-x20\", \"1.4Pa-x40\", \"1.4Pa-x20\"]\n","subfolder_name = \"Holes\"\n","\n","# List to store individual hole data\n","all_data = []\n","\n","print(\"\\nStarting hole analysis process...\")\n","\n","def extract_metadata_from_filename(filename):\n","    \"\"\"\n","    Extract pressure and magnification from filename.\n","    Expected format: denoised_0Pa_A1_20dec21_40x_L2RA_FlatA_seq007_Cadherins_regional_segmented.tif\n","    \"\"\"\n","    # Extract pressure (0Pa, 1.4Pa, etc.)\n","    pressure_match = re.search(r'(\\d+\\.?\\d*)Pa', filename)\n","    pressure = f\"{pressure_match.group(1)}Pa\" if pressure_match else \"Unknown\"\n","\n","    # Extract magnification (20x, 40x, etc.)\n","    mag_match = re.search(r'(\\d+)x', filename)\n","    magnification = f\"x{mag_match.group(1)}\" if mag_match else \"unknown\"\n","\n","    return pressure, magnification\n","\n","def analyze_holes_in_image(image_path):\n","    \"\"\"\n","    Analyze holes in a binary mask TIFF image (0s and 1s).\n","    Applies preprocessing to connect nearby pixels and improve hole detection.\n","    Returns list of hole measurements.\n","    \"\"\"\n","    try:\n","        # Read image as grayscale\n","        img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n","        if img is None:\n","            print(f\"Warning: Could not read image {image_path}\")\n","            return []\n","\n","        # Verify this is a binary mask\n","        unique_vals = np.unique(img)\n","        print(f\"      Unique pixel values: {unique_vals}\")\n","\n","        # Handle binary masks (0s and 1s)\n","        if img.max() <= 1:\n","            # Already 0/1 binary mask\n","            binary_mask = (img * 255).astype(np.uint8)\n","        elif set(unique_vals).issubset({0, 255}):\n","            # Already 0/255 binary mask\n","            binary_mask = img\n","        elif len(unique_vals) <= 3:\n","            # Likely binary with possible different values\n","            # Assume max value represents holes\n","            binary_mask = (img == img.max()).astype(np.uint8) * 255\n","        else:\n","            print(f\"      Warning: Image doesn't appear to be a binary mask. Found {len(unique_vals)} unique values.\")\n","            # Try to threshold anyway\n","            _, binary_mask = cv2.threshold(img, img.max()//2, 255, cv2.THRESH_BINARY)\n","\n","        # --- PREPROCESSING TO CONNECT NEARBY PIXELS ---\n","        print(f\"      Applying preprocessing to connect nearby pixels...\")\n","\n","        # 1. Gaussian blur to smooth and connect nearby regions\n","        # Use small kernel to avoid over-smoothing\n","        blurred = cv2.GaussianBlur(binary_mask, GAUSSIAN_KERNEL, GAUSSIAN_SIGMA)\n","\n","        # 2. Re-threshold after blurring to get back to binary\n","        _, smoothed_mask = cv2.threshold(blurred, 127, 255, cv2.THRESH_BINARY)\n","\n","        # 3. Morphological closing to connect nearby pixels and fill small gaps\n","        # Closing = dilation followed by erosion, fills holes and connects nearby objects\n","        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (MORPH_KERNEL_SIZE, MORPH_KERNEL_SIZE))\n","        closed_mask = cv2.morphologyEx(smoothed_mask, cv2.MORPH_CLOSE, kernel)\n","\n","        # 4. Additional step: Small dilation followed by erosion to bridge 1-2 pixel gaps\n","        # This is more aggressive connection for very close pixels\n","        kernel_small = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (BRIDGE_KERNEL_SIZE, BRIDGE_KERNEL_SIZE))\n","        dilated = cv2.dilate(closed_mask, kernel_small, iterations=1)\n","        final_mask = cv2.erode(dilated, kernel_small, iterations=1)\n","\n","        # Count connected components before and after processing for comparison\n","        _, labels_original = cv2.connectedComponents(binary_mask)\n","        original_components = np.max(labels_original)\n","\n","        print(f\"      Preprocessing complete. Original components: {original_components}\")\n","\n","        # Find connected components in processed mask (holes are white pixels = 255)\n","        num_labels, labels = cv2.connectedComponents(final_mask)\n","\n","        print(f\"      Found {num_labels-1} connected components (potential holes)\")\n","\n","        hole_data = []\n","        total_image_pixels = img.shape[0] * img.shape[1]\n","\n","        for label_id in range(1, num_labels):  # Skip background (label 0)\n","            # Create mask for this hole\n","            hole_mask = (labels == label_id)\n","\n","            # Calculate area (number of pixels)\n","            area = np.sum(hole_mask)\n","\n","            # Quality filters for binary masks:\n","            # Skip very small holes (likely noise or artifacts) - using adjustable parameter\n","            if area < MIN_HOLE_SIZE:\n","                continue\n","\n","            # Skip extremely large holes (likely inverted background) - using adjustable parameter\n","            if area > total_image_pixels * MAX_HOLE_FRACTION:\n","                continue\n","\n","            # Calculate perimeter using contour detection\n","            hole_mask_uint8 = hole_mask.astype(np.uint8)\n","            contours, _ = cv2.findContours(hole_mask_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","\n","            if not contours:\n","                continue\n","\n","            # Use the largest contour if multiple exist\n","            contour = max(contours, key=cv2.contourArea)\n","            perimeter = cv2.arcLength(contour, True)\n","\n","            if perimeter == 0:\n","                continue\n","\n","            # Calculate shape metrics\n","            circularity = 4 * np.pi * area / (perimeter ** 2)\n","            equivalent_diameter = np.sqrt(4 * area / np.pi)\n","\n","            # Calculate additional shape metrics for holes\n","            # Bounding box for aspect ratio\n","            x, y, w, h = cv2.boundingRect(contour)\n","            aspect_ratio = max(w, h) / min(w, h) if min(w, h) > 0 else 1\n","\n","            # Solidity (area/convex hull area)\n","            hull = cv2.convexHull(contour)\n","            hull_area = cv2.contourArea(hull)\n","            solidity = area / hull_area if hull_area > 0 else 0\n","\n","            # Extent (area/bounding box area)\n","            extent = area / (w * h) if (w * h) > 0 else 0\n","\n","            hole_data.append({\n","                'hole_id': label_id,\n","                'area': area,\n","                'perimeter': perimeter,\n","                'circularity': circularity,\n","                'equivalent_diameter': equivalent_diameter,\n","                'aspect_ratio': aspect_ratio,\n","                'solidity': solidity,\n","                'extent': extent,\n","                'bounding_width': w,\n","                'bounding_height': h\n","            })\n","\n","        print(f\"      âœ… Found {len(hole_data)} valid holes after filtering (min size: {MIN_HOLE_SIZE} pixels)\")\n","        print(f\"      ðŸ“Š Processed components: {original_components} â†’ {num_labels-1} â†’ {len(hole_data)} final holes\")\n","        return hole_data\n","\n","    except Exception as e:\n","        print(f\"Error analyzing image {image_path}: {e}\")\n","        return []\n","\n","# Loop through each folder and process the hole images\n","for folder in folders:\n","    folder_path = os.path.join(base_path, folder, subfolder_name)\n","    print(f\"Attempting to load data from: {folder_path}\")\n","\n","    if not os.path.exists(os.path.join(base_path, folder)):\n","        print(f\"Warning: Folder '{folder}' not found at '{os.path.join(base_path, folder)}'. Skipping.\")\n","        continue\n","\n","    # Check if the Holes subfolder exists\n","    if not os.path.exists(folder_path):\n","        print(f\"Warning: Holes subfolder not found at '{folder_path}'. Skipping.\")\n","        continue\n","\n","    try:\n","        # Get all TIFF files in the Holes folder\n","        tiff_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.tif', '.tiff'))]\n","\n","        if not tiff_files:\n","            print(f\"Warning: No TIFF files found in '{folder_path}'. Skipping.\")\n","            continue\n","\n","        print(f\"Found {len(tiff_files)} TIFF files in {folder}\")\n","\n","        # Process each TIFF file\n","        for filename in tiff_files:\n","            file_path = os.path.join(folder_path, filename)\n","\n","            # Analyze holes in this image\n","            holes = analyze_holes_in_image(file_path)\n","\n","            # Extract pressure and magnification from folder name\n","            if \"Static\" in folder or \"flow3\" in folder:\n","                pressure = '0Pa'\n","            elif \"1.4Pa\" in folder:\n","                pressure = '1.4Pa'\n","            else:\n","                # Try to extract from filename as fallback\n","                file_pressure, _ = extract_metadata_from_filename(filename)\n","                pressure = file_pressure if file_pressure != \"Unknown\" else 'Unknown'\n","\n","            # Extract magnification source\n","            if \"x40\" in folder:\n","                magnification_source = 'x40'\n","            elif \"x20\" in folder:\n","                magnification_source = 'x20'\n","            else:\n","                # Try to extract from filename as fallback\n","                _, file_magnification = extract_metadata_from_filename(filename)\n","                magnification_source = file_magnification if file_magnification != \"unknown\" else 'unknown'\n","\n","            # Add metadata to each hole\n","            for hole in holes:\n","                hole.update({\n","                    'filename': filename,\n","                    'folder': folder,\n","                    'pressure': pressure,\n","                    'magnification_source': magnification_source,\n","                    'file_path': file_path\n","                })\n","                all_data.append(hole)\n","\n","        print(f\"Successfully processed {len(tiff_files)} images from: {folder}\")\n","        total_holes = sum(1 for item in all_data if item['folder'] == folder)\n","        print(f\"  Folder: {folder} -> Pressure: {pressure}, Magnification: {magnification_source}, Total holes: {total_holes}\")\n","\n","    except Exception as e:\n","        print(f\"Error processing folder {folder_path}: {e}\")\n","\n","# Create DataFrame from all hole data\n","if all_data:\n","    combined_df = pd.DataFrame(all_data)\n","    print(\"\\nCombined DataFrame Info (before adjustments):\")\n","    combined_df.info(verbose=True, show_counts=True)\n","\n","    # --- Apply magnification adjustments ---\n","    print(\"\\nApplying magnification adjustments to hole measurements...\")\n","\n","    # Ensure columns exist and are numeric before adjustment\n","    numeric_columns = ['area', 'perimeter', 'equivalent_diameter']\n","    for col in numeric_columns:\n","        if col in combined_df.columns:\n","            combined_df[col] = pd.to_numeric(combined_df[col], errors='coerce')\n","        else:\n","            print(f\"Warning: '{col}' column not found. Cannot apply adjustment.\")\n","\n","    # Identify rows from x40 magnification\n","    is_x40 = combined_df['magnification_source'] == 'x40'\n","    num_x40_rows = is_x40.sum()\n","    print(f\"Found {num_x40_rows} holes from x40 magnification datasets for adjustment.\")\n","\n","    if num_x40_rows > 0:\n","        if 'area' in combined_df.columns:\n","            original_area_sum_x40 = combined_df.loc[is_x40, 'area'].sum()\n","            combined_df.loc[is_x40, 'area'] = combined_df.loc[is_x40, 'area'] / 4.0\n","            adjusted_area_sum_x40 = combined_df.loc[is_x40, 'area'].sum()\n","            print(f\"  Hole area for x40 data adjusted (divided by 4). Original sum: {original_area_sum_x40}, Adjusted sum: {adjusted_area_sum_x40}\")\n","\n","        # Adjust linear measurements (divide by 2 for x40 vs x20)\n","        linear_measurements = ['perimeter', 'equivalent_diameter', 'bounding_width', 'bounding_height']\n","        for measurement in linear_measurements:\n","            if measurement in combined_df.columns:\n","                original_sum = combined_df.loc[is_x40, measurement].sum()\n","                combined_df.loc[is_x40, measurement] = combined_df.loc[is_x40, measurement] / 2.0\n","                adjusted_sum = combined_df.loc[is_x40, measurement].sum()\n","                print(f\"  {measurement.capitalize()} for x40 data adjusted (divided by 2). Original sum: {original_sum:.1f}, Adjusted sum: {adjusted_sum:.1f}\")\n","\n","        print(f\"  Shape metrics (circularity, aspect_ratio, solidity, extent) remain unchanged as they are dimensionless.\")\n","    # ---------------------------------------\n","\n","    print(\"\\nCombined DataFrame Head (first 5 rows after adjustments):\")\n","    print(combined_df[['filename', 'folder', 'pressure', 'magnification_source', 'area', 'perimeter']].head())\n","\n","    print(\"\\nUnique values in 'pressure' column after combining:\")\n","    print(combined_df['pressure'].unique())\n","    print(\"\\nValue counts for 'pressure':\")\n","    print(combined_df['pressure'].value_counts())\n","\n","    # Define the columns for analysis (enhanced for hole analysis)\n","    analysis_columns = [\n","        'area',  # Now adjusted\n","        'perimeter',  # Now adjusted\n","        'equivalent_diameter',  # Now adjusted\n","        'circularity',\n","        'aspect_ratio',\n","        'solidity',\n","        'extent',\n","        'bounding_width',  # Now adjusted\n","        'bounding_height'  # Now adjusted\n","    ]\n","\n","    if 'pressure' not in combined_df.columns:\n","        print(\"Error: 'pressure' column not found in the combined data. Cannot proceed with analysis.\")\n","        exit()\n","\n","    combined_df_filtered = combined_df[\n","        combined_df['pressure'].isin(['0Pa', '1.4Pa'])\n","    ].copy()\n","\n","    print(f\"\\nShape of combined_df: {combined_df.shape}\")\n","    print(f\"Shape of combined_df_filtered: {combined_df_filtered.shape}\")\n","\n","    if combined_df_filtered.empty:\n","        print(\"DataFrame is empty after filtering for pressure. Check your data.\")\n","    else:\n","        print(\"\\nValue counts for 'pressure' in filtered data:\")\n","        print(combined_df_filtered['pressure'].value_counts())\n","\n","        print(\"\\nConverting analysis columns to numeric type (if not already)...\")\n","        for col in analysis_columns:\n","            if col in combined_df_filtered.columns:\n","                # If already numeric due to earlier conversion, this won't harm\n","                combined_df_filtered[col] = pd.to_numeric(combined_df_filtered[col], errors='coerce')\n","            else:\n","                print(f\"  Warning: Analysis column '{col}' not found in the filtered DataFrame. It will be skipped.\")\n","                if col in analysis_columns:\n","                    analysis_columns.remove(col)  # remove if truly missing\n","\n","        valid_analysis_columns = [col for col in analysis_columns if col in combined_df_filtered.columns and pd.api.types.is_numeric_dtype(combined_df_filtered[col])]\n","\n","        if not valid_analysis_columns:\n","            print(\"\\nNo valid numeric columns found for analysis after filtering and type conversion. Cannot generate statistics.\")\n","        else:\n","            print(f\"\\nPerforming descriptive analysis on (adjusted) columns: {valid_analysis_columns}\")\n","            try:\n","                descriptive_stats = combined_df_filtered.groupby(['pressure'])[valid_analysis_columns].agg(['mean', 'median', 'std', 'min', 'max', 'count'])\n","                print(\"\\n--- Descriptive Statistics by Pressure (with x40 adjustments) ---\")\n","                print(descriptive_stats)\n","\n","                output_stats_path = os.path.join(base_path, \"../Analysis/Holes/descriptive_stats_by_pressure_holes_adjusted.csv\")\n","                os.makedirs(os.path.dirname(output_stats_path), exist_ok=True)\n","                descriptive_stats.to_csv(output_stats_path)\n","                print(f\"\\nDescriptive statistics (with adjustments) saved to: {output_stats_path}\")\n","\n","            except Exception as e:\n","                print(f\"Error during groupby or aggregation: {e}\")\n","\n","    output_combined_file_path = os.path.join(base_path, \"../Analysis/Holes/combined_hole_data_adjusted.csv\")\n","    os.makedirs(os.path.dirname(output_combined_file_path), exist_ok=True)\n","    combined_df.to_csv(output_combined_file_path, index=False)\n","    print(f\"\\nCombined hole data (with adjustments and new columns) saved to: {output_combined_file_path}\")\n","\n","else:\n","    print(\"\\nNo hole data was successfully loaded. Please check file paths and ensure Google Drive is mounted correctly.\")\n","    print(f\"  Expected base path for your files: {base_path}\")\n","    print(f\"  Expected subfolders: {folders}\")\n","    print(f\"  Expected subfolder name within each: {subfolder_name}\")\n","    print(\"  Expected file types: .tif, .tiff\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yG3ef-U6xvLP","executionInfo":{"status":"ok","timestamp":1750499943821,"user_tz":-120,"elapsed":4873,"user":{"displayName":"Guido Putignano","userId":"13974663347531370398"}},"outputId":"61cf6c3d-412c-41d8-f29e-757768560f43"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Google Drive mounted successfully.\n","\n","Starting hole analysis process...\n","Attempting to load data from: /content/drive/MyDrive/knowledge/University/Master/Thesis/Segmented/Static-x40/Holes\n","Warning: No TIFF files found in '/content/drive/MyDrive/knowledge/University/Master/Thesis/Segmented/Static-x40/Holes'. Skipping.\n","Attempting to load data from: /content/drive/MyDrive/knowledge/University/Master/Thesis/Segmented/Static-x20/Holes\n","Warning: No TIFF files found in '/content/drive/MyDrive/knowledge/University/Master/Thesis/Segmented/Static-x20/Holes'. Skipping.\n","Attempting to load data from: /content/drive/MyDrive/knowledge/University/Master/Thesis/Segmented/1.4Pa-x40/Holes\n","Found 13 TIFF files in 1.4Pa-x40\n","      Unique pixel values: [0 1]\n","      Applying preprocessing to connect nearby pixels...\n","      Preprocessing complete. Original components: 1\n","      Found 1 connected components (potential holes)\n","      âœ… Found 1 valid holes after filtering (min size: 3 pixels)\n","      ðŸ“Š Processed components: 1 â†’ 1 â†’ 1 final holes\n","      Unique pixel values: [0 1]\n","      Applying preprocessing to connect nearby pixels...\n","      Preprocessing complete. Original components: 2\n","      Found 1 connected components (potential holes)\n","      âœ… Found 0 valid holes after filtering (min size: 3 pixels)\n","      ðŸ“Š Processed components: 2 â†’ 1 â†’ 0 final holes\n","      Unique pixel values: [0 1]\n","      Applying preprocessing to connect nearby pixels...\n","      Preprocessing complete. Original components: 12\n","      Found 1 connected components (potential holes)\n","      âœ… Found 0 valid holes after filtering (min size: 3 pixels)\n","      ðŸ“Š Processed components: 12 â†’ 1 â†’ 0 final holes\n","      Unique pixel values: [0 1]\n","      Applying preprocessing to connect nearby pixels...\n","      Preprocessing complete. Original components: 6\n","      Found 0 connected components (potential holes)\n","      âœ… Found 0 valid holes after filtering (min size: 3 pixels)\n","      ðŸ“Š Processed components: 6 â†’ 0 â†’ 0 final holes\n","      Unique pixel values: [0 1]\n","      Applying preprocessing to connect nearby pixels...\n","      Preprocessing complete. Original components: 1\n","      Found 0 connected components (potential holes)\n","      âœ… Found 0 valid holes after filtering (min size: 3 pixels)\n","      ðŸ“Š Processed components: 1 â†’ 0 â†’ 0 final holes\n","      Unique pixel values: [0 1]\n","      Applying preprocessing to connect nearby pixels...\n","      Preprocessing complete. Original components: 1\n","      Found 0 connected components (potential holes)\n","      âœ… Found 0 valid holes after filtering (min size: 3 pixels)\n","      ðŸ“Š Processed components: 1 â†’ 0 â†’ 0 final holes\n","      Unique pixel values: [0 1]\n","      Applying preprocessing to connect nearby pixels...\n","      Preprocessing complete. Original components: 227\n","      Found 129 connected components (potential holes)\n","      âœ… Found 106 valid holes after filtering (min size: 3 pixels)\n","      ðŸ“Š Processed components: 227 â†’ 129 â†’ 106 final holes\n","      Unique pixel values: [0 1]\n","      Applying preprocessing to connect nearby pixels...\n","      Preprocessing complete. Original components: 210\n","      Found 122 connected components (potential holes)\n","      âœ… Found 100 valid holes after filtering (min size: 3 pixels)\n","      ðŸ“Š Processed components: 210 â†’ 122 â†’ 100 final holes\n","      Unique pixel values: [0 1]\n","      Applying preprocessing to connect nearby pixels...\n","      Preprocessing complete. Original components: 321\n","      Found 142 connected components (potential holes)\n","      âœ… Found 85 valid holes after filtering (min size: 3 pixels)\n","      ðŸ“Š Processed components: 321 â†’ 142 â†’ 85 final holes\n","      Unique pixel values: [0 1]\n","      Applying preprocessing to connect nearby pixels...\n","      Preprocessing complete. Original components: 1\n","      Found 0 connected components (potential holes)\n","      âœ… Found 0 valid holes after filtering (min size: 3 pixels)\n","      ðŸ“Š Processed components: 1 â†’ 0 â†’ 0 final holes\n","      Unique pixel values: [0 1]\n","      Applying preprocessing to connect nearby pixels...\n","      Preprocessing complete. Original components: 1\n","      Found 0 connected components (potential holes)\n","      âœ… Found 0 valid holes after filtering (min size: 3 pixels)\n","      ðŸ“Š Processed components: 1 â†’ 0 â†’ 0 final holes\n","      Unique pixel values: [0 1]\n","      Applying preprocessing to connect nearby pixels...\n","      Preprocessing complete. Original components: 218\n","      Found 131 connected components (potential holes)\n","      âœ… Found 105 valid holes after filtering (min size: 3 pixels)\n","      ðŸ“Š Processed components: 218 â†’ 131 â†’ 105 final holes\n","      Unique pixel values: [0 1]\n","      Applying preprocessing to connect nearby pixels...\n","      Preprocessing complete. Original components: 237\n","      Found 150 connected components (potential holes)\n","      âœ… Found 123 valid holes after filtering (min size: 3 pixels)\n","      ðŸ“Š Processed components: 237 â†’ 150 â†’ 123 final holes\n","Successfully processed 13 images from: 1.4Pa-x40\n","  Folder: 1.4Pa-x40 -> Pressure: 1.4Pa, Magnification: x40, Total holes: 520\n","Attempting to load data from: /content/drive/MyDrive/knowledge/University/Master/Thesis/Segmented/1.4Pa-x20/Holes\n","Warning: Holes subfolder not found at '/content/drive/MyDrive/knowledge/University/Master/Thesis/Segmented/1.4Pa-x20/Holes'. Skipping.\n","\n","Combined DataFrame Info (before adjustments):\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 520 entries, 0 to 519\n","Data columns (total 15 columns):\n"," #   Column                Non-Null Count  Dtype  \n","---  ------                --------------  -----  \n"," 0   hole_id               520 non-null    int64  \n"," 1   area                  520 non-null    int64  \n"," 2   perimeter             520 non-null    float64\n"," 3   circularity           520 non-null    float64\n"," 4   equivalent_diameter   520 non-null    float64\n"," 5   aspect_ratio          520 non-null    float64\n"," 6   solidity              520 non-null    float64\n"," 7   extent                520 non-null    float64\n"," 8   bounding_width        520 non-null    int64  \n"," 9   bounding_height       520 non-null    int64  \n"," 10  filename              520 non-null    object \n"," 11  folder                520 non-null    object \n"," 12  pressure              520 non-null    object \n"," 13  magnification_source  520 non-null    object \n"," 14  file_path             520 non-null    object \n","dtypes: float64(6), int64(4), object(5)\n","memory usage: 61.1+ KB\n","\n","Applying magnification adjustments to hole measurements...\n","Found 520 holes from x40 magnification datasets for adjustment.\n","  Hole area for x40 data adjusted (divided by 4). Original sum: 173753, Adjusted sum: 43438.25\n","  Perimeter for x40 data adjusted (divided by 2). Original sum: 31852.8, Adjusted sum: 15926.4\n","  Equivalent_diameter for x40 data adjusted (divided by 2). Original sum: 6220.8, Adjusted sum: 3110.4\n","  Bounding_width for x40 data adjusted (divided by 2). Original sum: 8569.0, Adjusted sum: 4284.5\n","  Bounding_height for x40 data adjusted (divided by 2). Original sum: 7937.0, Adjusted sum: 3968.5\n","  Shape metrics (circularity, aspect_ratio, solidity, extent) remain unchanged as they are dimensionless.\n","\n","Combined DataFrame Head (first 5 rows after adjustments):\n","                                            filename     folder pressure  \\\n","0  denoised_1.4Pa_A1_19dec21_40x_L2RA_FlatA_seq00...  1.4Pa-x40    1.4Pa   \n","1  denoised_1.4Pa_A1_20dec21_40x_L2RA_FlatA_seq00...  1.4Pa-x40    1.4Pa   \n","2  denoised_1.4Pa_A1_20dec21_40x_L2RA_FlatA_seq00...  1.4Pa-x40    1.4Pa   \n","3  denoised_1.4Pa_A1_20dec21_40x_L2RA_FlatA_seq00...  1.4Pa-x40    1.4Pa   \n","4  denoised_1.4Pa_A1_20dec21_40x_L2RA_FlatA_seq00...  1.4Pa-x40    1.4Pa   \n","\n","  magnification_source   area  perimeter  \n","0                  x40   1.00   2.707107  \n","1                  x40   0.75   1.707107  \n","2                  x40   3.00   6.000000  \n","3                  x40  35.25  39.627417  \n","4                  x40  79.75  76.970562  \n","\n","Unique values in 'pressure' column after combining:\n","['1.4Pa']\n","\n","Value counts for 'pressure':\n","pressure\n","1.4Pa    520\n","Name: count, dtype: int64\n","\n","Shape of combined_df: (520, 15)\n","Shape of combined_df_filtered: (520, 15)\n","\n","Value counts for 'pressure' in filtered data:\n","pressure\n","1.4Pa    520\n","Name: count, dtype: int64\n","\n","Converting analysis columns to numeric type (if not already)...\n","\n","Performing descriptive analysis on (adjusted) columns: ['area', 'perimeter', 'equivalent_diameter', 'circularity', 'aspect_ratio', 'solidity', 'extent', 'bounding_width', 'bounding_height']\n","\n","--- Descriptive Statistics by Pressure (with x40 adjustments) ---\n","               area                                         perimeter  \\\n","               mean median         std   min     max count       mean   \n","pressure                                                                \n","1.4Pa     83.535096    7.0  306.200584  0.75  3077.5   520  30.627735   \n","\n","                                         ... bounding_width                    \\\n","             median       std       min  ...            std  min    max count   \n","pressure                                 ...                                    \n","1.4Pa     11.010407  59.10873  1.707107  ...      13.936405  0.5  135.5   520   \n","\n","         bounding_height                                     \n","                    mean median        std  min   max count  \n","pressure                                                     \n","1.4Pa           7.631731    4.0  11.022811  0.5  92.5   520  \n","\n","[1 rows x 54 columns]\n","\n","Descriptive statistics (with adjustments) saved to: /content/drive/MyDrive/knowledge/University/Master/Thesis/Segmented/../Analysis/Holes/descriptive_stats_by_pressure_holes_adjusted.csv\n","\n","Combined hole data (with adjustments and new columns) saved to: /content/drive/MyDrive/knowledge/University/Master/Thesis/Segmented/../Analysis/Holes/combined_hole_data_adjusted.csv\n"]}]}]}