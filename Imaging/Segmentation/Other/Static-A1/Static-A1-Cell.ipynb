{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPdiC6lo4XtYktDffnvX5Nn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"590260242a7840a581289abca14c2452":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_763118b8823c4cd0b5dbf1cdc656a0cf","IPY_MODEL_ea1f8fe36a494cd5af4b07ba27f8954b","IPY_MODEL_616a333a67584c76a1a469ed168c82c8"],"layout":"IPY_MODEL_69b76f390d9a46a8ac234adf64c2f9ce"}},"763118b8823c4cd0b5dbf1cdc656a0cf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_07d493be5ed44e9fba6eedd327d8781e","placeholder":"​","style":"IPY_MODEL_30b2287c8e6c4ca1aab891aac621e2d8","value":"100%"}},"ea1f8fe36a494cd5af4b07ba27f8954b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8bbb7988ab344369954da3fece21695c","max":16,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8508e62e8bdb46a19aba23dd4e983447","value":16}},"616a333a67584c76a1a469ed168c82c8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6cbe36b05e444d948f1173a896a62a84","placeholder":"​","style":"IPY_MODEL_eaef0e37167e4d59ba9dd68e81b81b81","value":" 16/16 [00:36&lt;00:00,  1.76s/it]"}},"69b76f390d9a46a8ac234adf64c2f9ce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"07d493be5ed44e9fba6eedd327d8781e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"30b2287c8e6c4ca1aab891aac621e2d8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8bbb7988ab344369954da3fece21695c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8508e62e8bdb46a19aba23dd4e983447":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6cbe36b05e444d948f1173a896a62a84":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eaef0e37167e4d59ba9dd68e81b81b81":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["590260242a7840a581289abca14c2452","763118b8823c4cd0b5dbf1cdc656a0cf","ea1f8fe36a494cd5af4b07ba27f8954b","616a333a67584c76a1a469ed168c82c8","69b76f390d9a46a8ac234adf64c2f9ce","07d493be5ed44e9fba6eedd327d8781e","30b2287c8e6c4ca1aab891aac621e2d8","8bbb7988ab344369954da3fece21695c","8508e62e8bdb46a19aba23dd4e983447","6cbe36b05e444d948f1173a896a62a84","eaef0e37167e4d59ba9dd68e81b81b81"]},"id":"PtOSjbV-YB52","executionInfo":{"status":"ok","timestamp":1742470890999,"user_tz":-60,"elapsed":69566,"user":{"displayName":"Guido Putignano","userId":"13974663347531370398"}},"outputId":"009ef0ef-9f34-4def-e518-e60c52c38e9a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Found 16 Cadherin files to process\n","Found 16 fused cell mask files\n","Mapped prefix 'denoised_0Pa_A1_19dec21_20xA_L2RA_FlatA_seq011' to file: denoised_0Pa_A1_19dec21_20xA_L2RA_FlatA_seq011_segmented_cells.tif\n","Mapped prefix 'denoised_0Pa_A1_19dec21_40x_L2RA_FlatA_seq005' to file: denoised_0Pa_A1_19dec21_40x_L2RA_FlatA_seq005_segmented_cells.tif\n","Mapped prefix 'denoised_0Pa_A1_19dec21_20xA_L2RA_FlatA_seq007' to file: denoised_0Pa_A1_19dec21_20xA_L2RA_FlatA_seq007_segmented_cells.tif\n","Mapped prefix 'denoised_0Pa_A1_19dec21_40x_L2RA_FlatA_seq002' to file: denoised_0Pa_A1_19dec21_40x_L2RA_FlatA_seq002_segmented_cells.tif\n","Mapped prefix 'denoised_0Pa_A1_19dec21_20xA_L2RA_FlatA_seq006' to file: denoised_0Pa_A1_19dec21_20xA_L2RA_FlatA_seq006_segmented_cells.tif\n","Mapped prefix 'denoised_0Pa_A1_19dec21_20xA_L2RA_FlatA_seq009' to file: denoised_0Pa_A1_19dec21_20xA_L2RA_FlatA_seq009_segmented_cells.tif\n","Mapped prefix 'denoised_0Pa_A1_19dec21_40x_L2RA_FlatA_seq004' to file: denoised_0Pa_A1_19dec21_40x_L2RA_FlatA_seq004_segmented_cells.tif\n","Mapped prefix 'denoised_0Pa_A1_19dec21_20xA_L2RA_FlatA_seq001' to file: denoised_0Pa_A1_19dec21_20xA_L2RA_FlatA_seq001_segmented_cells.tif\n","Mapped prefix 'denoised_0Pa_A1_19dec21_20xA_L2RA_FlatA_seq004' to file: denoised_0Pa_A1_19dec21_20xA_L2RA_FlatA_seq004_segmented_cells.tif\n","Mapped prefix 'denoised_0Pa_A1_19dec21_20xA_L2RA_FlatA_seq010' to file: denoised_0Pa_A1_19dec21_20xA_L2RA_FlatA_seq010_segmented_cells.tif\n","Mapped prefix 'denoised_0Pa_A1_19dec21_20xA_L2RA_FlatA_seq008' to file: denoised_0Pa_A1_19dec21_20xA_L2RA_FlatA_seq008_segmented_cells.tif\n","Mapped prefix 'denoised_0Pa_A1_19dec21_20xA_L2RA_FlatA_seq003' to file: denoised_0Pa_A1_19dec21_20xA_L2RA_FlatA_seq003_segmented_cells.tif\n","Mapped prefix 'denoised_0Pa_A1_19dec21_20xA_L2RA_FlatA_seq005' to file: denoised_0Pa_A1_19dec21_20xA_L2RA_FlatA_seq005_segmented_cells.tif\n","Mapped prefix 'denoised_0Pa_A1_19dec21_20xA_L2RA_FlatA_seq002' to file: denoised_0Pa_A1_19dec21_20xA_L2RA_FlatA_seq002_segmented_cells.tif\n","Mapped prefix 'denoised_0Pa_A1_19dec21_40x_L2RA_FlatA_seq001' to file: denoised_0Pa_A1_19dec21_40x_L2RA_FlatA_seq001_segmented_cells.tif\n","Mapped prefix 'denoised_0Pa_A1_19dec21_40x_L2RA_FlatA_seq003' to file: denoised_0Pa_A1_19dec21_40x_L2RA_FlatA_seq003_segmented_cells.tif\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/16 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"590260242a7840a581289abca14c2452"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Processing: denoised_0Pa_A1_19dec21_20xA_L2RA_FlatA_seq001_Cadherins_contrast_bg_tophat.tif\n","Using fused cell mask: denoised_0Pa_A1_19dec21_20xA_L2RA_FlatA_seq001_segmented_cells.tif\n","  Cadherin image shape: (1024, 1024)\n","  Fused cell mask shape: (1024, 1024)\n","  Detected single-channel Cadherin image\n","  Applying Gaussian blur...\n","  Calculating morphological gradient...\n","  Performing watershed segmentation...\n","  Saved cell mask to /content/drive/MyDrive/knowledge/University/Master/Thesis/Segmented/Static-A-1/Cell/denoised_0Pa_A1_19dec21_20xA_L2RA_FlatA_seq001_cell_mask.tif\n","  Number of fused cell seeds: 320\n","  Number of segmented cells: 320\n","  Processing complete for denoised_0Pa_A1_19dec21_20xA_L2RA_FlatA_seq001_Cadherins_contrast_bg_tophat.tif\n","\n","Processing: denoised_0Pa_A1_19dec21_20xA_L2RA_FlatA_seq002_Cadherins_contrast_bg_tophat.tif\n","Using fused cell mask: denoised_0Pa_A1_19dec21_20xA_L2RA_FlatA_seq002_segmented_cells.tif\n","  Cadherin image shape: (1024, 1024)\n","  Fused cell mask shape: (1024, 1024)\n","  Detected single-channel Cadherin image\n","  Applying Gaussian blur...\n","  Calculating morphological gradient...\n","  Performing watershed segmentation...\n","  Saved cell mask to /content/drive/MyDrive/knowledge/University/Master/Thesis/Segmented/Static-A-1/Cell/denoised_0Pa_A1_19dec21_20xA_L2RA_FlatA_seq002_cell_mask.tif\n","  Number of fused cell seeds: 247\n","  Number of segmented cells: 247\n","  Processing complete for denoised_0Pa_A1_19dec21_20xA_L2RA_FlatA_seq002_Cadherins_contrast_bg_tophat.tif\n","\n","Processing: denoised_0Pa_A1_19dec21_20xA_L2RA_FlatA_seq003_Cadherins_contrast_bg_tophat.tif\n","Using fused cell mask: denoised_0Pa_A1_19dec21_20xA_L2RA_FlatA_seq003_segmented_cells.tif\n","  Cadherin image shape: (1024, 1024)\n","  Fused cell mask shape: (1024, 1024)\n","  Detected single-channel Cadherin image\n","  Applying Gaussian blur...\n","  Calculating morphological gradient...\n","  Performing watershed segmentation...\n","  Saved cell mask to /content/drive/MyDrive/knowledge/University/Master/Thesis/Segmented/Static-A-1/Cell/denoised_0Pa_A1_19dec21_20xA_L2RA_FlatA_seq003_cell_mask.tif\n","  Number of fused cell seeds: 335\n","  Number of segmented cells: 335\n","  Processing complete for denoised_0Pa_A1_19dec21_20xA_L2RA_FlatA_seq003_Cadherins_contrast_bg_tophat.tif\n","\n","Processing: denoised_0Pa_A1_19dec21_20xA_L2RA_FlatA_seq004_Cadherins_contrast_bg_tophat.tif\n","Using fused cell mask: denoised_0Pa_A1_19dec21_20xA_L2RA_FlatA_seq004_segmented_cells.tif\n","  Cadherin image shape: (1024, 1024)\n","  Fused cell mask shape: (1024, 1024)\n","  Detected single-channel Cadherin image\n","  Applying Gaussian blur...\n","  Calculating morphological gradient...\n","  Performing watershed segmentation...\n","  Saved cell mask to /content/drive/MyDrive/knowledge/University/Master/Thesis/Segmented/Static-A-1/Cell/denoised_0Pa_A1_19dec21_20xA_L2RA_FlatA_seq004_cell_mask.tif\n","  Number of fused cell seeds: 323\n","  Number of segmented cells: 323\n","  Processing complete for denoised_0Pa_A1_19dec21_20xA_L2RA_FlatA_seq004_Cadherins_contrast_bg_tophat.tif\n","\n","Processing: denoised_0Pa_A1_19dec21_20xA_L2RA_FlatA_seq005_Cadherins_contrast_bg_tophat.tif\n","Using fused cell mask: denoised_0Pa_A1_19dec21_20xA_L2RA_FlatA_seq005_segmented_cells.tif\n","  Cadherin image shape: (1024, 1024)\n","  Fused cell mask shape: (1024, 1024)\n","  Detected single-channel Cadherin image\n","  Applying Gaussian blur...\n","  Calculating morphological gradient...\n","  Performing watershed segmentation...\n","  Saved cell mask to /content/drive/MyDrive/knowledge/University/Master/Thesis/Segmented/Static-A-1/Cell/denoised_0Pa_A1_19dec21_20xA_L2RA_FlatA_seq005_cell_mask.tif\n","  Number of fused cell seeds: 257\n","  Number of segmented cells: 257\n","  Processing complete for denoised_0Pa_A1_19dec21_20xA_L2RA_FlatA_seq005_Cadherins_contrast_bg_tophat.tif\n","\n","Processing: denoised_0Pa_A1_19dec21_20xA_L2RA_FlatA_seq006_Cadherins_contrast_bg_tophat.tif\n","Using fused cell mask: denoised_0Pa_A1_19dec21_20xA_L2RA_FlatA_seq006_segmented_cells.tif\n","  Cadherin image shape: (1024, 1024)\n","  Fused cell mask shape: (1024, 1024)\n","  Detected single-channel Cadherin image\n","  Applying Gaussian blur...\n","  Calculating morphological gradient...\n","  Performing watershed segmentation...\n","  Saved cell mask to /content/drive/MyDrive/knowledge/University/Master/Thesis/Segmented/Static-A-1/Cell/denoised_0Pa_A1_19dec21_20xA_L2RA_FlatA_seq006_cell_mask.tif\n","  Number of fused cell seeds: 292\n","  Number of segmented cells: 292\n","  Processing complete for denoised_0Pa_A1_19dec21_20xA_L2RA_FlatA_seq006_Cadherins_contrast_bg_tophat.tif\n","\n","Processing: denoised_0Pa_A1_19dec21_20xA_L2RA_FlatA_seq007_Cadherins_contrast_bg_tophat.tif\n","Using fused cell mask: denoised_0Pa_A1_19dec21_20xA_L2RA_FlatA_seq007_segmented_cells.tif\n","  Cadherin image shape: (1024, 1024)\n","  Fused cell mask shape: (1024, 1024)\n","  Detected single-channel Cadherin image\n","  Applying Gaussian blur...\n","  Calculating morphological gradient...\n","  Performing watershed segmentation...\n","  Saved cell mask to /content/drive/MyDrive/knowledge/University/Master/Thesis/Segmented/Static-A-1/Cell/denoised_0Pa_A1_19dec21_20xA_L2RA_FlatA_seq007_cell_mask.tif\n","  Number of fused cell seeds: 254\n","  Number of segmented cells: 254\n","  Processing complete for denoised_0Pa_A1_19dec21_20xA_L2RA_FlatA_seq007_Cadherins_contrast_bg_tophat.tif\n","\n","Processing: denoised_0Pa_A1_19dec21_20xA_L2RA_FlatA_seq008_Cadherins_contrast_bg_tophat.tif\n","Using fused cell mask: denoised_0Pa_A1_19dec21_20xA_L2RA_FlatA_seq008_segmented_cells.tif\n","  Cadherin image shape: (1024, 1024)\n","  Fused cell mask shape: (1024, 1024)\n","  Detected single-channel Cadherin image\n","  Applying Gaussian blur...\n","  Calculating morphological gradient...\n","  Performing watershed segmentation...\n","  Saved cell mask to /content/drive/MyDrive/knowledge/University/Master/Thesis/Segmented/Static-A-1/Cell/denoised_0Pa_A1_19dec21_20xA_L2RA_FlatA_seq008_cell_mask.tif\n","  Number of fused cell seeds: 254\n","  Number of segmented cells: 254\n","  Processing complete for denoised_0Pa_A1_19dec21_20xA_L2RA_FlatA_seq008_Cadherins_contrast_bg_tophat.tif\n","\n","Processing: denoised_0Pa_A1_19dec21_20xA_L2RA_FlatA_seq009_Cadherins_contrast_bg_tophat.tif\n","Using fused cell mask: denoised_0Pa_A1_19dec21_20xA_L2RA_FlatA_seq009_segmented_cells.tif\n","  Cadherin image shape: (1024, 1024)\n","  Fused cell mask shape: (1024, 1024)\n","  Detected single-channel Cadherin image\n","  Applying Gaussian blur...\n","  Calculating morphological gradient...\n","  Performing watershed segmentation...\n","  Saved cell mask to /content/drive/MyDrive/knowledge/University/Master/Thesis/Segmented/Static-A-1/Cell/denoised_0Pa_A1_19dec21_20xA_L2RA_FlatA_seq009_cell_mask.tif\n","  Number of fused cell seeds: 288\n","  Number of segmented cells: 288\n","  Processing complete for denoised_0Pa_A1_19dec21_20xA_L2RA_FlatA_seq009_Cadherins_contrast_bg_tophat.tif\n","\n","Processing: denoised_0Pa_A1_19dec21_20xA_L2RA_FlatA_seq010_Cadherins_contrast_bg_tophat.tif\n","Using fused cell mask: denoised_0Pa_A1_19dec21_20xA_L2RA_FlatA_seq010_segmented_cells.tif\n","  Cadherin image shape: (1024, 1024)\n","  Fused cell mask shape: (1024, 1024)\n","  Detected single-channel Cadherin image\n","  Applying Gaussian blur...\n","  Calculating morphological gradient...\n","  Performing watershed segmentation...\n","  Saved cell mask to /content/drive/MyDrive/knowledge/University/Master/Thesis/Segmented/Static-A-1/Cell/denoised_0Pa_A1_19dec21_20xA_L2RA_FlatA_seq010_cell_mask.tif\n","  Number of fused cell seeds: 233\n","  Number of segmented cells: 233\n","  Processing complete for denoised_0Pa_A1_19dec21_20xA_L2RA_FlatA_seq010_Cadherins_contrast_bg_tophat.tif\n","\n","Processing: denoised_0Pa_A1_19dec21_20xA_L2RA_FlatA_seq011_Cadherins_contrast_bg_tophat.tif\n","Using fused cell mask: denoised_0Pa_A1_19dec21_20xA_L2RA_FlatA_seq011_segmented_cells.tif\n","  Cadherin image shape: (1024, 1024)\n","  Fused cell mask shape: (1024, 1024)\n","  Detected single-channel Cadherin image\n","  Applying Gaussian blur...\n","  Calculating morphological gradient...\n","  Performing watershed segmentation...\n","  Saved cell mask to /content/drive/MyDrive/knowledge/University/Master/Thesis/Segmented/Static-A-1/Cell/denoised_0Pa_A1_19dec21_20xA_L2RA_FlatA_seq011_cell_mask.tif\n","  Number of fused cell seeds: 289\n","  Number of segmented cells: 289\n","  Processing complete for denoised_0Pa_A1_19dec21_20xA_L2RA_FlatA_seq011_Cadherins_contrast_bg_tophat.tif\n","\n","Processing: denoised_0Pa_A1_19dec21_40x_L2RA_FlatA_seq001_Cadherins_contrast_bg_tophat.tif\n","Using fused cell mask: denoised_0Pa_A1_19dec21_40x_L2RA_FlatA_seq001_segmented_cells.tif\n","  Cadherin image shape: (1024, 1024)\n","  Fused cell mask shape: (1024, 1024)\n","  Detected single-channel Cadherin image\n","  Applying Gaussian blur...\n","  Calculating morphological gradient...\n","  Performing watershed segmentation...\n","  Saved cell mask to /content/drive/MyDrive/knowledge/University/Master/Thesis/Segmented/Static-A-1/Cell/denoised_0Pa_A1_19dec21_40x_L2RA_FlatA_seq001_cell_mask.tif\n","  Number of fused cell seeds: 91\n","  Number of segmented cells: 91\n","  Processing complete for denoised_0Pa_A1_19dec21_40x_L2RA_FlatA_seq001_Cadherins_contrast_bg_tophat.tif\n","\n","Processing: denoised_0Pa_A1_19dec21_40x_L2RA_FlatA_seq002_Cadherins_contrast_bg_tophat.tif\n","Using fused cell mask: denoised_0Pa_A1_19dec21_40x_L2RA_FlatA_seq002_segmented_cells.tif\n","  Cadherin image shape: (1024, 1024)\n","  Fused cell mask shape: (1024, 1024)\n","  Detected single-channel Cadherin image\n","  Applying Gaussian blur...\n","  Calculating morphological gradient...\n","  Performing watershed segmentation...\n","  Saved cell mask to /content/drive/MyDrive/knowledge/University/Master/Thesis/Segmented/Static-A-1/Cell/denoised_0Pa_A1_19dec21_40x_L2RA_FlatA_seq002_cell_mask.tif\n","  Number of fused cell seeds: 111\n","  Number of segmented cells: 111\n","  Processing complete for denoised_0Pa_A1_19dec21_40x_L2RA_FlatA_seq002_Cadherins_contrast_bg_tophat.tif\n","\n","Processing: denoised_0Pa_A1_19dec21_40x_L2RA_FlatA_seq003_Cadherins_contrast_bg_tophat.tif\n","Using fused cell mask: denoised_0Pa_A1_19dec21_40x_L2RA_FlatA_seq003_segmented_cells.tif\n","  Cadherin image shape: (1024, 1024)\n","  Fused cell mask shape: (1024, 1024)\n","  Detected single-channel Cadherin image\n","  Applying Gaussian blur...\n","  Calculating morphological gradient...\n","  Performing watershed segmentation...\n","  Saved cell mask to /content/drive/MyDrive/knowledge/University/Master/Thesis/Segmented/Static-A-1/Cell/denoised_0Pa_A1_19dec21_40x_L2RA_FlatA_seq003_cell_mask.tif\n","  Number of fused cell seeds: 76\n","  Number of segmented cells: 76\n","  Processing complete for denoised_0Pa_A1_19dec21_40x_L2RA_FlatA_seq003_Cadherins_contrast_bg_tophat.tif\n","\n","Processing: denoised_0Pa_A1_19dec21_40x_L2RA_FlatA_seq004_Cadherins_contrast_bg_tophat.tif\n","Using fused cell mask: denoised_0Pa_A1_19dec21_40x_L2RA_FlatA_seq004_segmented_cells.tif\n","  Cadherin image shape: (1024, 1024)\n","  Fused cell mask shape: (1024, 1024)\n","  Detected single-channel Cadherin image\n","  Applying Gaussian blur...\n","  Calculating morphological gradient...\n","  Performing watershed segmentation...\n","  Saved cell mask to /content/drive/MyDrive/knowledge/University/Master/Thesis/Segmented/Static-A-1/Cell/denoised_0Pa_A1_19dec21_40x_L2RA_FlatA_seq004_cell_mask.tif\n","  Number of fused cell seeds: 84\n","  Number of segmented cells: 84\n","  Processing complete for denoised_0Pa_A1_19dec21_40x_L2RA_FlatA_seq004_Cadherins_contrast_bg_tophat.tif\n","\n","Processing: denoised_0Pa_A1_19dec21_40x_L2RA_FlatA_seq005_Cadherins_contrast_bg_tophat.tif\n","Using fused cell mask: denoised_0Pa_A1_19dec21_40x_L2RA_FlatA_seq005_segmented_cells.tif\n","  Cadherin image shape: (1024, 1024)\n","  Fused cell mask shape: (1024, 1024)\n","  Detected single-channel Cadherin image\n","  Applying Gaussian blur...\n","  Calculating morphological gradient...\n","  Performing watershed segmentation...\n","  Saved cell mask to /content/drive/MyDrive/knowledge/University/Master/Thesis/Segmented/Static-A-1/Cell/denoised_0Pa_A1_19dec21_40x_L2RA_FlatA_seq005_cell_mask.tif\n","  Number of fused cell seeds: 95\n","  Number of segmented cells: 95\n","  Processing complete for denoised_0Pa_A1_19dec21_40x_L2RA_FlatA_seq005_Cadherins_contrast_bg_tophat.tif\n","All processing complete!\n"]}],"source":["import numpy as np\n","import tifffile\n","from scipy import ndimage\n","from skimage.filters import gaussian\n","from skimage.segmentation import watershed\n","from skimage.morphology import disk, dilation, erosion\n","import os\n","import glob\n","import re\n","from google.colab import drive\n","from tqdm.notebook import tqdm\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# Define input and output paths\n","cadherin_dir = '/content/drive/MyDrive/knowledge/University/Master/Thesis/Projected/Static-A-1/Cadherins'\n","fused_dir = '/content/drive/MyDrive/knowledge/University/Master/Thesis/Segmented/Static-A-1/Fused'\n","output_dir = '/content/drive/MyDrive/knowledge/University/Master/Thesis/Segmented/Static-A-1/Cell'\n","\n","# Create output directory if it doesn't exist\n","os.makedirs(output_dir, exist_ok=True)\n","\n","# Find all Cadherin .tif files - adjust pattern to match actual filenames\n","cadherin_files = glob.glob(os.path.join(cadherin_dir, '*Cadherins_contrast_bg_tophat.tif'))\n","print(f\"Found {len(cadherin_files)} Cadherin files to process\")\n","\n","# Function to extract the sequence prefix from filenames\n","def extract_sequence_prefix(filename):\n","    # The pattern matches the sequence identifier (e.g., denoised_0Pa_A1_19dec21_40x_L2RA_FlatA_seq005)\n","    match = re.match(r\"(denoised_.*?seq\\d+)\", os.path.basename(filename))\n","    if match:\n","        return match.group(1)\n","    return None\n","\n","# Recursively search for all fused cell mask files (including in subfolders)\n","fused_files = []\n","for root, dirs, files in os.walk(fused_dir):\n","    for file in files:\n","        if file.endswith('_segmented_cells.tif'):\n","            fused_files.append(os.path.join(root, file))\n","\n","print(f\"Found {len(fused_files)} fused cell mask files\")\n","\n","# Create a dictionary mapping sequence prefixes to fused file paths\n","fused_prefix_to_file = {}\n","for fused_file in fused_files:\n","    prefix = extract_sequence_prefix(fused_file)\n","    if prefix:\n","        fused_prefix_to_file[prefix] = fused_file\n","        print(f\"Mapped prefix '{prefix}' to file: {os.path.basename(fused_file)}\")\n","\n","# Process each Cadherin file\n","for cadherin_file in tqdm(cadherin_files):\n","    # Get base filename\n","    filename = os.path.basename(cadherin_file)\n","\n","    # Extract sequence prefix from the cadherin filename\n","    prefix = extract_sequence_prefix(cadherin_file)\n","    if not prefix:\n","        print(f\"WARNING: Could not extract sequence prefix from {filename}, skipping\")\n","        continue\n","\n","    # Find corresponding fused cell mask file\n","    if prefix not in fused_prefix_to_file:\n","        print(f\"WARNING: No matching fused cell mask found for {prefix}, skipping\")\n","        continue\n","\n","    fused_mask_file = fused_prefix_to_file[prefix]\n","    base_name = prefix\n","\n","    print(f\"\\nProcessing: {filename}\")\n","    print(f\"Using fused cell mask: {os.path.basename(fused_mask_file)}\")\n","\n","    try:\n","        # Load the images\n","        cadherin_img = tifffile.imread(cadherin_file)\n","        fused_cell_masks = tifffile.imread(fused_mask_file)\n","\n","        print(f\"  Cadherin image shape: {cadherin_img.shape}\")\n","        print(f\"  Fused cell mask shape: {fused_cell_masks.shape}\")\n","\n","        # Extract Cadherin channel if needed\n","        if len(cadherin_img.shape) == 2:\n","            # Single channel image (already Cadherin)\n","            print(\"  Detected single-channel Cadherin image\")\n","            membrane_channel = cadherin_img\n","        elif len(cadherin_img.shape) == 3 and cadherin_img.shape[0] == 3:\n","            # Format is (C, H, W)\n","            print(\"  Detected format: (C, H, W)\")\n","            membrane_channel = cadherin_img[0]  # First channel\n","        elif len(cadherin_img.shape) == 3 and cadherin_img.shape[2] == 3:\n","            # Format is (H, W, C)\n","            print(\"  Detected format: (H, W, C)\")\n","            membrane_channel = cadherin_img[:, :, 0]  # First channel\n","        else:\n","            print(f\"  Unexpected image shape: {cadherin_img.shape}. Using first channel/plane.\")\n","            if len(cadherin_img.shape) == 3:\n","                membrane_channel = cadherin_img[0] if cadherin_img.shape[0] < cadherin_img.shape[1] else cadherin_img[:, :, 0]\n","            else:\n","                membrane_channel = cadherin_img\n","\n","        # Apply Gaussian blur to reduce noise\n","        print(\"  Applying Gaussian blur...\")\n","        membrane_smoothed = gaussian(membrane_channel, sigma=1)\n","\n","        # Calculate morphological gradient\n","        print(\"  Calculating morphological gradient...\")\n","        selem = disk(1)  # Adjust radius if needed\n","        dilated = dilation(membrane_smoothed, selem)\n","        eroded = erosion(membrane_smoothed, selem)\n","        membrane_gradient = dilated - eroded\n","\n","        # Normalize gradient to 0-1 range\n","        membrane_gradient_norm = (membrane_gradient - membrane_gradient.min()) / (\n","                    membrane_gradient.max() - membrane_gradient.min())\n","\n","        # Apply watershed segmentation using fused cell masks as seeds\n","        print(\"  Performing watershed segmentation...\")\n","        watershed_output = watershed(membrane_gradient_norm, fused_cell_masks, mask=membrane_gradient_norm > 0)\n","\n","        # Save the cell mask result\n","        cell_mask_path = os.path.join(output_dir, f\"{base_name}_cell_mask.tif\")\n","        tifffile.imwrite(cell_mask_path, watershed_output.astype(np.uint32))\n","        print(f\"  Saved cell mask to {cell_mask_path}\")\n","\n","        # Print statistics\n","        print(f\"  Number of fused cell seeds: {len(np.unique(fused_cell_masks)) - 1}\")\n","        print(f\"  Number of segmented cells: {len(np.unique(watershed_output)) - 1}\")\n","        print(f\"  Processing complete for {filename}\")\n","\n","    except Exception as e:\n","        print(f\"ERROR processing {filename}: {str(e)}\")\n","        continue\n","\n","print(\"All processing complete!\")"]}]}